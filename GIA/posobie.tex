\documentclass[12pt]{extarticle}
%\documentclass[12pt,oneside,final]{book}
\usepackage[utf8]{inputenc}
\usepackage[T1,T2A]{fontenc}
\usepackage[margin=2cm]{geometry}

\usepackage{type1ec}
%\usepackage[mathlit]{newliterat}
\usepackage[russian,english]{babel}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[sumlimits,intlimits,namelimits]{amsmath}
\usepackage{indentfirst} 
\usepackage{verse}
%\usepackage[a5paper,width=130mm,height=175mm, %
%includefoot,ignorehead]{geometry}
\usepackage{ccaption}
\captiondelim{. }
\captionnamefont{\small}
\captiontitlefont{\small}
\captionstyle{\centering}
\usepackage[dvipsnames]{xcolor}
\usepackage{graphicx}
\usepackage{lettrine}
\usepackage{fancyvrb}
\pagestyle{plain}
\usepackage{tikz}

\usepackage{titlesec}
\titlelabel{\thetitle.\ }
\titlespacing{\section}{\parindent}{2\baselineskip}{\baselineskip}
\titlespacing{\chapter}{\parindent}{0pt}{2\baselineskip}
%\contentsmargin{0pt}


\pdfcompresslevel=9

%
% про усечение заголовка главы в хедере
% http://tex.stackexchange.com/questions/41277/how-to-cut-a-section-title-in-the-header
%

\usepackage{cmap}
\usepackage{xcolor}
\usepackage[pdftex,unicode]{hyperref}
\definecolor{dark-red}{rgb}{0.4,0.15,0.15}
\definecolor{dark-blue}{rgb}{0.15,0.15,0.4}
\definecolor{medium-blue}{rgb}{0,0,0.5}
\hypersetup{
    colorlinks, linkcolor={dark-red},
    citecolor={dark-blue}, urlcolor={medium-blue}
}

\renewcommand{\Pr}{{\mathbf P}}
\renewcommand{\le}{\leqslant}
\renewcommand{\leq}{\leqslant}
\renewcommand{\ge}{\geqslant}
\renewcommand{\geq}{\geqslant}
\newcommand{\M}{{\mathbf M}}
\newcommand{\D}{{\mathbf D}}
\newcommand{\bQ}{{\boldsymbol Q}}
%\newcommand{\ctg}{\mathrm{ctg}\,}
\newcommand*{\hm}[1]{#1\nobreak\discretionary{}%
  {\hbox{$\mathsurround=0pt #1$}}{}} 
\newcommand*{\htimes}{{}\nobreak%
  \discretionary{\hbox{$\mathsurround=0pt \times$}}%
  {\hbox{$\mathsurround=0pt \times$}}{}} 
\newtheorem{theorem}{\color{CadetBlue}Теорема}
\newtheorem{lemma}{\color{CadetBlue}Лемма}
\newtheorem{definition}{\color{CadetBlue}Определение}
%\newtheorem{zadacha}{}[chapter]

\makeatletter



\makeindex

\begin{document}
\selectlanguage{russian}

\begin{titlepage}

  \begin{center}
    \textbf{МИНИСТЕРСТВО ОБРАЗОВАНИЯ И НАУКИ РОССИЙСКОЙ \\ ФЕДЕРАЦИИ\\
    федеральное государственное автономное образовательное учреждение\\
    высшего образования <<Национальный исследовательский Нижегородский\\ государственный университет им.~Н.И.~Лобачевского>>  \\(ННГУ)}
    
    \vfill 
    
    Кочеганов Виктор Михайлович
    \bigskip
    \bigskip
    \bigskip

    
     \textbf{ЧИСЛЕННЫЙ АНАЛИЗ МАРКОВСКИХ ПРОЦЕССОВ ГИБЕЛИ И \\
     РАЗМНОЖЕНИЯ С ПОМОЩЬЮ ПРЕОБРАЗОВАНИЯ ЛАПЛАСА\\
    (Учебно-методическое пособие)}
    
    \bigskip
    \bigskip
    Направление подготовки:\underline{\hspace{1cm}} \\
    Направленность подготовки:\underline{\hspace{1cm}}\\
    
 \vfill 
    \textbf{Учебно-методическая разработка\\
    (в рамках государственного экзамена)}
        \vfill 

        \begin{flushright}
    Тема утверждена на заседании кафедры\\
    \underline{\hspace{6.5cm}} \\
    от << \ \ \ >>\underline{\hspace{2cm}} 2018 г. \\
    Протокол №\underline{\hspace{0.5cm}} \\
   \medskip
    Зав. кафедрой \underline{\hspace{3cm}} /ФИО/\\
    \bigskip
    \end{flushright}


    Нижний Новгород \\ 2018
  \end{center}
  
\end{titlepage}

\section{Цели и задачи учебно-методической разработки}
\
\thispagestyle{empty}



Пособие предназначено для студентов магистратуры, обучающихся по
направлению <<Прикладная математика и информатика>> и
может быть использовано при чтении  курса по выбору <<Аналитические и численные методы в теории очередей>>. При освоении материала данной учебно-методической разработки у студентов формируются следующие компетенции:
\begin{itemize}
\item ОК-1, способность к абстрактному мышлению;
\item ОПК-4, способность использовать и применять углубленные знания в области прикладной математики;
\item ПК-2, способность разрабатывать и анализировать концептуальные и теоретические модели решаемых научных проблем и задач;
\item ПК-3, способность разрабатывать и применять математические методы, системное и прикладное программное обеспечение для решения задач научной и проектно-технологической деятельности.
\end{itemize}
Целью изучения пособия является знакомство с методами теории массового обслуживания студентов, не имевших спецкурса по теории массового обслуживания в бакалавриате.

Данное методическое пособие рекомендовано кафедрой для внедрения в дисциплину <<Аналитические и численные методы в теории очередей>>.


\newpage


% \chapter*{Предисловие}
% \addcontentsline{toc}{chapter}{Предисловие}


\newpage
\section{Первая глава. Введение}

Пусть есть кафе с $N=10$ местами (индивидуальными столиками). Очереди нет,
столики обслуживаются официантами. Клиент в среднем
проводит в кафе полчаса. Среднее число поступающих клиентов в час изменяется. В
момент открытия, в 9:00, в кафе приходят 6 клиентов в час; с~9 до 15 интенсивность
линейно растёт до 10 клиентов в час; с 15 до 18 часов она линейно убывает до 8
клиентов в час. В 18:00 кафе закрывается. В момент открытия кафе пустует. Как
изменяется в течение дня число занятых мест?

Мы понимаем, что в работе такого кафе есть большая доля влияния случая: моменты,
когда входят посетители, их заказы, их темп еды --- всё заранее предвидеть и
распланировать невозможно. Поэтому мы будем рассматривать эту задачу методами
теории вероятностей. Итак, мы принимаем, что число занятых мест в каждый
отдельно взятый момент времени есть случайная величина. Тогда вопрос можно
переформулировать так: как изменяется среднее число клиентов? как изменяется
дисперсия среднего числа клиентов?

Рассмотрим поподробнее входные данные задачи, поймём их вероятностный
смысл. Во-первых, запишем выражение для мгновенной интенсивности прихода
клиентов (то, что мы ранее назвали <<число клиентов в час>>) для произвольного
момента времени $t$. Выберем в качестве начального момента отсчёта времени $t=0$
время 9:00 утра, тогда будем считать, что $0\leq t\leq 9$. Обозначим эту
интенсивность через $\lambda(t)$. Физический смысл этой характеристики такой: за
интервал времени вида $(t, t+h)$ в среднем поступает $\lambda(t)\cdot h+o(h)$
требований.  Имеем:
\[
\lambda(t)=\begin{cases}
  6+2t/3,& 0\leq t\leq 6\\
  14-2t/3,& 6< t \leq 9.
\end{cases}
\]
Понятно, что такое
условие не определяет полностью вероятностный закон поступления
клиентов. Сформулируем следующие постулаты \emph{нестационарного ординарного
  потока без последействия}: независимо от того, как приходили клиенты прежде
момента $t$, за промежуток времени $(t, t+h)$ приходит ровно один новый клиент с
вероятностью $\lambda(t)h+o(h)$, поступает более одного клиента с
вероятностью $o(h)$ и не поступает ни одного клиента с вероятностью
$1-\lambda(t)h+o(h)$. 

Дифференциальные уравнения Колмогорова: 
\begin{align*}
  p_0'(t) & = -\lambda(t)p_0(t)+\mu p_1(t);\\
  p_i'(t) & = \lambda(t)p_{i-1}(t)-(\lambda(t)+i\mu)p_i(t)+(i+1)\mu
  p_{i+1}(t),\\ & \qquad \qquad i=1, 2, \ldots, N-1;\\
  p_N'(t) & = \lambda(t)p_{N-1}(t)-N\mu p_N(t)
\end{align*}
задают закон изменения распределения длины очереди.

Среднее число клиентов задается формулой
\[
m(t)=\sum_{i=0}^N i p_i(t).
\]

Приведем программу на языке Octave, вычисляющая распределения  $p_i(t)$, $i=\overline{0,N}$, и выводящая их на экран. Кроме того, выводом программы является среднее число требований в очереди с течением времени.
\begin{Verbatim}[frame=single,xleftmargin=2em,numbers=left]
function pdot = kolm(p,t)
  m=2;
  if (t<6) l=6+2/3*t; else l=14-2/3*t; endif;
  sz = length(p);
  A = zeros(sz,sz);
  A(1:sz+1:sz^2) = -l-m*(0:sz-1);
  A(2:sz+1:sz^2) = l;
  A(sz+1:sz+1:sz^2) = m*(1:sz-1);
  A(sz^2) = -(sz-1)*m;
  pdot = A*p;
endfunction;

N=10;
tt = 0:0.1:9;
pp0 = [1, zeros(1,N)];
pp = lsode("kolm", pp0, tt);
plot(tt,pp); ## распределение вероятностей
plot(tt,pp*(0:N)'); ## среднее число клиентов
\end{Verbatim}


% \begin{figure}[h!]
%   \includegraphics[scale=0.2]{distribution_tables.pdf}
%   \caption{Сравнение точного решения (сплошная линия) и приближённого решения
%     \label{fig:bes}}
% \end{figure}

% \begin{figure}[thb]
%   \centering
%   \includegraphics[width=10cm]{plot_bessel}
%   \caption{Сравнение точного решения (сплошная линия) и приближённого решения
%     (крестики)
%     \label{fig:bes}}
% \end{figure}

Как мы можем проверить этот результат и, главное, объяснить его <<заказчику>>? 
Ключевой момент здесь --- связать вероятность с частотой и заодно увидеть
собственными глазами, как выглядят \emph{траектории случайного процесса}.

Итак, в оставшейся части Введения мы продемонстрируем один важный метод анализа
процессов обслуживания: метод имитационного моделирования --- и больше про него
не будем вспоминать, так как это отдельная большая наука. В качестве рабочего
определения примем, что имитационное моделирование состоит в выделении некоторых
существенных событий, происходящих в сложной системе, и в <<розыгрыше>>
возможной последовательности наступления этих событий с учётом известных
распределений вероятностей для <<входных управляющих событий>>. 

Во-первых, давайте разберёмся в том, как же всё-таки разворачивается поступление
клиентов во времени.

Надо определить моменты поступления требований в систему. Введём вспомогательную
функцию $\Lambda(t)=\int\limits_0^t \lambda(s)\,ds$. Она равна
\[
\Lambda(t)=\begin{cases}
  6t+t^2/3,& 0\leq t\leq 6\\
  14t-t^2/3-24,& 6< t \leq 9.
\end{cases}
\]
Пусть $T_0=0$, а величины $T_1$, $T_2$, \ldots~--- независимые случайные
величины с экспоненциальным распределением с параметром $1$, $\Lambda(t)$ ---
вспомогательная функция, определённая выше. Для момента $t\ge0$ введём величину
\[
\eta(t)=\sup\{n\colon T_0+T_1+\ldots+T_n<\Lambda(t)\}.
\]
Можно показать, что как функция от $t$, семейство случайных величин $\{\eta(t);
t\ge0\}$ ведёт себя как \emph{счётчик числа пришедших клиентов} в нестационарном
ординарном потоке без последействия с мгновенной интенсивностью $\lambda(t)$,
$t\ge0$. Пусть $V(t)$~--- функция, обратная к $\Lambda(t)$. Тогда моменты
поступления клиентов (моменты скачков считающей функции $\eta(t)$) суть 
\[
\tau_1=V(T_1), \; \tau_2=V(T_1+T_2),\; \tau_3=V(T_1+T_2+T_3),\; \ldots
\]
В нашем случае:
\[
V(t)=
\begin{cases}
  \sqrt{3(t+27)}-9,& 0\le t\le 48,\\
  \sqrt{21-3(123-t)},& 48< t\leq 75.
\end{cases}
\]
Теперь определим моменты поступления клиентов на всём промежутке наблюдения $[0,
9]$ и нарисуем вид функции $\eta(t)$ (а точнее, её \emph{выборчную реализацию}).
\begin{Verbatim}[frame=single,xleftmargin=2em,numbers=left]
function v = Vfunc(tt)
	 whr = (tt>48);
	 v = zeros(size(tt));
	 v = sqrt(3*(tt+27))-9;
	 v(whr) = 21-sqrt(3*(123-tt(whr)));
endfunction;

function taus = ClientsIn()
  taus = [];
  Tn = -log( rand() );
  y = Vfunc(Tn);
  while(y<=9)
    taus(end+1)=y;
    Tn = Tn - log( rand() );
    y = Vfunc(Tn);
  endwhile
endfunction

taus = ClientsIn();
stairs( taus, 0:(length(taus)-1) );
\end{Verbatim}

Обозначим $W_{j,i}$ время, через которое в кафе освободится не менее $j$ мест в
момент прихода $i$-го клиента (мы следуем классической работе Кифера и
Вольфовица, в которой число мест в кафе было не ограничено). Объединим эти
величины с одинаковым индексом $i$ в вектор $W_i=(W_{1,i}, \ldots, W_{N,i})$. Из
определения устанавливаем справедливость неравенств $0\le W_{1,i}\le W_{2,i}\le
\ldots \le W_{N,i}$. Этот вектор несёт в себе много интересной
информации. Например, если ровно $k$ его первых элементов равны нулю, это
означает, что в момент прихода $i$-го клиента есть $k$ свободных мест. В
частности, первый клиент за день застаёт все места свободными, так что $W_1=(0,
0, \ldots, 0)$. Пусть теперь для $i$-го клиента вектор
$0=W_{k,i}<W_{k+1,i}$. Этот клиент, очевидно, сразу займёт свободное
место. Каким тогда будет вектор $W_{i+1}$? Следующий клиент придёт через
промежуток $\alpha_{i+1}=\tau_{i+1}-\tau_i$, время обслуживания $i$-го клиента обозначим
$S_i$. Значит, в момент прихода $(i+1)$-го клиента оставшееся время до
ухода $i$-го клиента равно $(S_i-\alpha_{i+1})^+=\max\{0, S_i-\alpha_{i+1}\}$. Обозначим через
$R(\cdot)$ оператор упорядочивания по возрастанию элементов вектора,
подставленного на место точки в качестве его аргумента. Тогда будем иметь,
очевидно,
\[
W_{i+1}=
R\bigl(0, \ldots, 0,
(S_i-\alpha_i)^+,
(W_{k+1,i}-\alpha_{i+1})^+,\ldots,
(W_{N,i}-\alpha_{i+1})^+\bigr).
\]
Здесь на первых местах стоят $(k-1)$ нуль. Если же в момент прихода $i$-клиента
все места заняты, $W_{1,i}>0$, то этот клиент просто теряется, и 
\[
W_{i+1}=\bigl((W_{1,i}-\alpha_{i+1})^+, \ldots, (W_{N,i}-\alpha_{i+1})^+\bigr).
\]
Алгоритм имитации будет следующий: 1) определить моменты прихода клиентов; 2)
для каждого клиента вычислить его вектор остаточных длительностей; 3) если
клиент не видит свободных мест, помещаем его в поток потерянных клиентов; если
места есть, то определяем момент выхода этого клиента и помещаем в выходящий
поток; 4) соединяем с сортировкой список моментов начала обслуживания и моментов
выхода клиентов с учётом изменения числа клиентов ($+1$, $-1$); 5) вычисляем
актуальное число клиентов в каждый момент скачка.

\begin{Verbatim}[frame=single,xleftmargin=2em,numbers=left]
function [jmps qs taus lost srvd] = RunSim(mu, NN)
	 taus = ClientsIn;
	 jmps_temp = [];
	 lost = [];
	 W = zeros(1, NN);
	 tprev=0;
	 for tau = taus
	     if W(1)>0 
		lost(end+1)=tau;
		W = W+tprev-tau;
		W( W<0 ) = 0;
	     else
		 jmps_temp(end+1)=tau;
		 W = W+tprev-tau;
		 S = -log(rand())/mu;
		 srvd(end+1) = tau+S;
		 W(1) = max([0, W(1)-log(rand())/mu]);
		 W = sort(W);
	     endif
	     tprev=tau;
	 endfor
	 [jmps idx] = sort([0 jmps_temp srvd]);
	 qs = cumsum([0 ones(1, length(jmps_temp)), ...
               -ones(1, length(srvd))](idx));
endfunction
\end{Verbatim}


\section[Вторая глава. Марковские процессы гибели и размножения с непрерывным 
  временем]%
  {\raggedright Вторая глава. Марковские процессы гибели и размножения с непрерывным 
  временем}


\subsection{Период занятости. Преобразование Лапласа}
В рамках спецкурсов <<Вероятностные модели в теории очередей>> и <<Теория
массового обслуживания>> разбирались конкретные примеры простейших систем
массового обслуживания в предположении о простейшем входящем потоке и
экспоненциальном распределении длительности обслуживания произвольного
требования. В качестве математической модели выбирался процесс $\{\varkappa(t);
t\geqslant0\}$, описывающие изменение длины очереди или числа требований в
системе $\varkappa(t)$ в момент $t\geqslant0$. Во всех рассмотренных там случаях
(задачи Эрланга для конечного и бесконечного пуска, задача Пальма для $n$ линий
с потерями, система с ожиданием и $n$ приборами) процесс $\{\varkappa(t);
t\geqslant0\}$ оказывался марковским, а система дифференциальных уравнений
Чепмена--Колмогорова имела трёхдиагональную матрицу. Все рассмотренные тогда
процессы являются частными случаями важного класса марковских процессов,
носящего название процессов гибели и размножения. Введём обозначения для
переходных вероятностей
$$
p_{i,j}(t)=\Pr(\{\omega\colon \varkappa(s+t)=j\}\mid \{\omega\colon
\varkappa(s)=i\}), \quad s, t\leqslant0.
$$
Для марковского процесса доказывается существование пределов
\begin{gather*}
  a_{i,j}=p_{i,j}'(0)=\lim\limits_{t\to0}\dfrac{p_{i,j}(t)}{t}\,, \quad i\neq j,\\
  -a_i=a_{i,i}=p_{i,i}'(0)=\lim\limits_{t\to0}\dfrac{p_{i,i}(t)-1}{t}\,.
\end{gather*}
Величины $a_{i,j}$, $i$, $j\in\{0, 1, \ldots\}$ называются мгновенными
интенсивностями перехода данного марковского процесса.

\begin{definition}
  Случайный марковский процесс с конечным или бесконечным счётным числом
  состояний называется процессом гибели и размножения, если для некоторых
  неотрицательных величин $\lambda_0$, $\lambda_1$, \ldots{} и $\mu_1$, $\mu_2$,
  \ldots{} его мгновенные интенсивности перехода имеют вид:
  \[
  a_0=\lambda_0, \quad a_i=\lambda_i+\mu_i, \quad
  a_{i, i-1}=\mu_i, \quad a_{i-1,i}=\lambda_{i-1}, \quad i=1, 2, \ldots.
  \]
\end{definition}
Величины $\lambda_i$, $i\geqslant0$ называют интенсивностями рождений, а
величины $\mu_i$, $i\geqslant1$~--- интенсивностями гибели. Рассмотрим
конкретные примеры. Студенту предлагается самостоятельно проверить приведённые
ниже формулы.

В задаче Эрланга для \emph{ограниченного} пучка из $n$ идентичных линий имеем:
$\lambda_i=\lambda$, $i=0$, $1$, \ldots, $n-1$; $\lambda_i=0$ для $i\geqslant
n$; $\mu_i=i\mu$, $i=1$, $2$, \ldots, $n$; $\mu_i=0$ для $i\geqslant n+1$.  В
задаче Эрланга для \emph{бесконечного} пучка из идентичных линий имеем:
$\lambda_i=\lambda$, $i=0$, $1$, \ldots; $\mu_i=i\mu$, $i=1$, $2$, \ldots.  В
системе с ожиданием и $n$ приборами имеем: $\lambda_i=\lambda$, $i=0$, $1$,
\ldots;  $\mu_i=i\mu$, $i=1$, $2$,
\ldots, $n$; $\mu_i=n\mu$ для $i\geqslant n+1$.

Стационарное распределение $p_i$, $i=0$, $1$, \ldots{} для процесса гибели и
размножения удовлетворяет \emph{разностным} уравнениям
\[
  \left\{
    \begin{aligned}
      0&= -\lambda_0 p_0+\mu_1 p_1,\\
      0&= \lambda_{i-1}p_{i-1}-(\lambda_i+\mu_i)p_i+\mu_{i+1}p_{i+1}, \qquad
      i=1, 2, \ldots{}
    \end{aligned}
  \right.
\]
и условию нормировки
\[
p_0+p_1+p_2+\ldots=1.
\]
Из разностных уравнений находим:
\[
\lambda_{i}p_{i}-\mu_{i+1}p_{i+1}=\lambda_{i-1}p_{i-1}-\mu_{i}p_{i}=\ldots =
\lambda_0 p_0-\mu_i p_1=0.
\]
Отсюда
\[
p_i=\dfrac{\lambda_{i-1}\lambda_{i-2}\times\ldots\times\lambda_0}{\mu_i\mu_{i-1}\times\ldots\times
\mu_1}\cdot p_0.
\]
Подстановка в условие нормировки даёт уравнение для вероятности $p_0$:
\[
p_0 \Bigl(1+\dfrac{\lambda_0}{\mu_1}+\dfrac{\lambda_1\lambda_0}{\mu_2\mu_1}+\ldots
\Bigr)=1.
\]
Следовательно, \emph{стационарное} распределение существует тогда и только тогда, когда
\[
\sum_{i=1}^\infty \prod_{l=0}^{i-1} \dfrac{\lambda_l}{\mu_{l+1}}<\infty.
\]
Чтобы найти допредельное распределение вероятностей
\[
p_i(t)=\Pr(\{\omega\colon \varkappa(t)=i\}), \quad i=0, 1, \ldots
\]
надо решить (бесконечную) систему линейных дифференциальных уравнений
\[
\left\{
  \begin{aligned}
  p_0'(t)&=-\lambda_0 p_0(t)+\mu_1p_1(t),\\
  p_i'(t)&=\lambda_{i-1}p_{i-1}(t)-(\lambda_i+\mu_i)
  p_i(t)+\mu_{i+1}p_{i+1}(t),\quad
   i=1, 2, \ldots
 \end{aligned}
\right.
\]
с начальным условием $p_i(0)=\tilde{p}_i$, $i=0$, $1$, \ldots. Если число
состояние системы конечно, для решения дифференциальных уравнений естественно
воспользоваться тем или иным приближённым методом.

Рассмотрим теперь новую характеристику функционирования системы массового
обслуживания, которая не рассматривалась на спецкурсах бакалавриата:
\emph{период занятости} система. Будем называть \emph{периодом занятости} $\Pi$
системы обслуживания промежуток времени с началом в момент поступления в пустую
систему первого требования и с окончанием в момент первого затем освобождения
системы от вновь поступивших требований. Для изучения вероятностных свойств
периода занятости можно применять различные методы.

Пусть в однолинейной системе с простейшим входящим потоком и экспоненциальным
обслуживанием имеется неограниченное число мест ожидания. В нотации Кендалла это
система M/M/1/$\infty$. Соответствующий процесс гибели и размножения задаётся
параметрами: $\lambda_i=\lambda$, $\mu_{i+1}=\mu$, $i=0$, $1$, \ldots. С целью
изучить период занятости сделаем состояние $0$ поглощающим: положим
$\lambda_0=0$. Тогда событие <<период занятости закончился до момента $t$>>,
$\Pi<t$, эквивалентно событию <<вспомогательный процесс в момент $t$ находится в
состоянии $0$>>. Система дифференциальных уравнений для состояний
модифицированного процесса примет вид:
\[
\left\{
  \begin{aligned}
  \tilde p_0'(t)&=\mu \tilde p_1(t),\\
  \tilde p_1'(t)&=-(\lambda+\mu) \tilde p_1(t)+\mu \tilde p_2(t),\\
  \tilde p_i'(t)&=\lambda \tilde p_{i-1}(t)-(\lambda+\mu)
  \tilde p_i(t)+\mu \tilde p_{i+1}(t),\quad
   i=2, 3, \ldots
 \end{aligned}
\right.
\]
с начальными условиями: $\tilde p_0(0)=\tilde p_2(0)=\tilde p_3(0)=\ldots=0$,
$\tilde p_1(0)=1$. 
Введём производящие функции 
\[
F(z,t)=\sum_{i=0}^\infty \tilde p_i(t) z^i, \quad |z|\leqslant 1,\; t\geqslant 0.
\]
Так же, как и при изучении входящего потока в спецкурсе по вероятностным моделям
ТМО, получаем дифференциальное уравнение для производящей функции:
\[
\dfrac{\partial F}{\partial t}(z,t)=
\Bigl(\lambda( z-1)-\mu\Bigl(1-\dfrac1z\Bigr)\!\Bigr) F(z,t)+
\Bigl(\lambda(z-1)+\mu-\dfrac{\mu}{z}\Bigr)\tilde p_0(t).
\]
Перейдём к преобразованиям Лапласа:
\[
\hat F(z,s)=\int_0^\infty e^{-st} F(z,t)\,dt,\qquad
\hat p_0(s)=\int_0^\infty e^{-st} \tilde p_0(t)\,dt.
\]
Дифференцирование фун\-к\-ции-ори\-гинала эквивалентно умножению её
преобразования Лапласа на $s$ с последующим вычитанием значения функции в нуле.
Поскольку $F(z,0)=z$, получим:
\begin{gather*}
s\hat F(z,s)-z= \Bigl(\lambda( z-1)-\mu\Bigl(1-\dfrac1z\Bigr)\!\Bigr) \hat F(z,s)+
\Bigl(\lambda(z-1)+\mu-\dfrac{\mu}{z}\Bigr)\hat p_0(s),
\intertext{откуда}
 \hat F(z,s)=
\dfrac{z^2+(\lambda z^2-(\lambda -\mu) z-\mu)\hat p_0(s)}%
{z(s+\lambda+\mu)-\lambda z^2-\mu}\,.
\end{gather*}
Пусть 
\begin{gather*}
  z_1(s)=\dfrac{\lambda+\mu+s-\sqrt{(\lambda+\mu+s)^2-4\lambda\mu}}{2\lambda},\\
  z_2(s)=\dfrac{\lambda+\mu+s+\sqrt{(\lambda+\mu+s)^2-4\lambda\mu}}{2\lambda},
\end{gather*}
где ветвь корня задана условием $\sqrt{1}=1$. Тогде $|z_1(s)|<|z_2(s)|$. По
теореме Руше, ровно один из двух корней лежит в круге $|z|<1$, следовательно,
это именно $z_1(s)$. Значит, он же должен обращать числитель в ноль. Отсюда
находим $\hat p_0(s)$:
\[
%\hat F(z,s)=\dfrac{z^2-(\mu-\lambda
%  z)(1-z)(z_1(s)/s)}{\lambda(z-z_1(s))(z_2(s)-z)}\,.
\hat
p_0(s)=\dfrac{2\mu}{s(\lambda+\mu+s+\sqrt{(\lambda+\mu+s)^2-4\lambda\mu})}\,. 
\]
Функция $s \hat p_0(s)$ есть преобразование Лапласа для $g(t)=p_0'(t)$, т.е. для
плотности распределения $g(t)$ периода занятости~$\Pi$. Представляет интерес
вопрос о численном обращении данного преобразования Лапласа. Результат работы
численного алгоритма можно сравнить в данном случае с точным решением, которое
может быть найдено из таблиц:
\[
p_0'(t)=\dfrac{\sqrt{\mu/\lambda} e^{-(\lambda+\mu)t}
  I_1(2\sqrt{\lambda\mu}t)}{t}\,,
\]
где $I_1(\cdot)$~--- (модифицированная) функция Бесселя первого рода. Один из
способов численного обращения описан в статье: \foreignlanguage{english}{J.~Abate and
P.~Valk\'o. Multi-precision Laplce transform inversion~// International journal
for numerical methods in engineering, 2004, v.~60, p.~979--993.}

В основе численных методов обращения преобразования Лапласа лежит следующая
формула из теории комплексного переменного:
\[
f(t) = \dfrac{1}{2\pi i} \int_{c-i\cdot\infty}^{c+i\cdot\infty} F(s) e^{st}\,ds,
\]
в отечественной литературе известная под названием преобразования Меллина, а в
англоязычных публикациях называемая также интегралом Бромвича
(\foreignlanguage{english}{Bromwich}). Интегрирование производится вдоль
вертикальной прямой $s=c+i y$, $-\infty<y<\infty$, а константа $c$ может
выбираться произвольно, но проваее абсциссы абсолютной сходимости преобразования
Лапласа. А.~Тальбот (A.~Talbot) в~1979 году предложил производить интегрирование
вдоль другого контура, охватывающего отрицательную действительную полуось и
содержащего все особые точки функции $F(s)$. Равенство интеграла Меллина --
Бромвича и интеграла Тальбота устанавливается по теореме Коши. Тальбот предложил
семейство контуров, из которых выберем один с параметрическим заданием 
\[
s(y)=cy(\ctg y+i),\qquad -\pi<y<\pi.
\]
Тогда 
\(s'(y)=i c (1+i \sigma(y))\), где 
$$
\sigma(y)=y+(y\ctg y-1)\ctg y.
$$
Тогда
\begin{align*}
  f(t)&=\dfrac{1}{2\pi i} \int_{-\pi}^\pi e^{ts(y)} F(s(y)) s'(y)\, dy=
  \\ &=
  \dfrac{r}{\pi} \int_0^\pi \mathfrak{Re}\bigl(
  e^{ts(y)} F(s(y)(1+i \sigma(y)) \bigr)\,dy.
\end{align*}
Применяя к определённому интегралу формулу трапеций с узлами $y_j\hm=k\pi/N$, получим:
\[
f(t)\approx\dfrac{c}{N}
\biggl\{
\dfrac12 F(c) e^{ct}+
\sum_{k=1}^{N-1} \mathfrak{Re}\bigl(
  e^{ts(y_k)} F(s(y_k)(1+i \sigma(y_k)) \bigr)
\biggr\}.
\]
Авторы цитированной выше статьи рекомендуют брать $c=2N/(5t)$. Число интервалов
$N$ можно брать порядка нескольких десятков. Программный код на языке
\foreignlanguage{english}{Octave} 
приведён ниже.
\begin{Verbatim}[frame=single,xleftmargin=2em,numbers=left]
function ans = talbot(F, t,  N)
  r = 2*N./(5*mean(t));
  h = pi / N;
  k=1:(N-1);
  [xt, xk] = meshgrid(t,k);
  thk = xk*pi/N;
  s = r*thk.*(i+cot(thk));
  sgm = thk + (thk.*cot(thk)-1).*cot(thk);
  ans = r/N*( feval(F,r)*exp(r*t)/2+sum( real( ...
       (feval(F,s).* (1+i*sgm)).*exp(xt.*s)), 1 ) );
endfunction
\end{Verbatim}
На вход функции \texttt{talbot} подаётся функция, вычисляющая преобразование
Лапласа. Она может быть указана либо по имени, либо с помощью конструкции
<<дескриптора функции>>, либо в виде <<анонимной функции>>. Второй аргумент ---
одно значение $t$ или вектор значений $(t_1, t_2, \ldots, t_m)$, в которых
требуется вычислить значение исходной функции $t(t)$. Третий параметр задаёт
число параметр аппроксимации интеграла по методу трапеций. Обратим с помощью этой
функции преобразование Лапласа для плотности $g(t)$ периода занятости~$\Pi$. Пусть
$\lambda=0{,}3$, $\mu=0{,}6$. 
\begin{Verbatim}[frame=single,xleftmargin=2em,numbers=left]
function y = F(s)
  mu = 0.6;
  lmb = 0.3;
  y = 2*mu./(lmb+mu+s+sqrt((sqrt(lmb)-sqrt(mu))^2+s) ...
      .*sqrt((sqrt(lmb)+sqrt(mu))^2+s));
endfunction

mu = 0.6;
lmb = 0.3;
tt = 0.01:0.2:5;
xtrue = sqrt(mu/lmb)*exp(-(lmb+mu)*tt) ...
        .*besseli(1,2*sqrt(lmb*mu)*tt)./tt;
xx = talbot(@F,tt,16);
plot(tt,xtrue,'-',tt,xx,'+')
\end{Verbatim}

В строках 1--6 определяется функция, задающая преобразование Лапласа. Следует
отметить, что при вычислениях с комплексными числами возникает проблема перехода
между ветвями многозначных функций. В данном случае при работе с
функцией вычисления квадратного корня (строки~4--5) пришлось использовать
тождество
\begin{multline*}
\sqrt{(\lambda+\mu+s)^2-4\lambda\mu}=
\\ =
\sqrt{\lambda+\mu+s+2\sqrt{\lambda\mu}} \cdot
\sqrt{\lambda+\mu+s-2\sqrt{\lambda\mu}}=
\\ =
\sqrt{(\sqrt\lambda-\sqrt\mu)^2+s} \cdot
\sqrt{(\sqrt\lambda+\sqrt\mu)^2+s}.
\end{multline*}


Наряду с применениями преобразования Лапласа для аналитического решения задач,
следует отметить огромную его полезность для решения \emph{вероятностных}
задач. Интеграл преобразования Лапласа
\[
\varphi(s)=\int_0^\infty e^{-st}g(t)\,dt
\]
есть в то же время и \emph{математическое ожидание} непрерывной случайной
величины $\exp\{-s\Pi\}$:
\[
\varphi(s)=\M( e^{-s\Pi}).
\] 
В нашем случае значение случайной величины $\Pi$
однозначно определяется реализацией $\varkappa(\cdot, \omega)$ марковского
процесса. 

Используя понятие математического ожидания можно теперь определить
преобразование Лапласа (называемое более точно преобразованием
Лапласа--Стилтьеса) произвольной неотрицательной случайной величины.
\begin{definition}
  Преобразованием Лапласа неотрицательной случайной величины $\boldsymbol{X}$
  (возможно, принимающей значение $\infty$) называется функция действительного
  переменного $s\geqslant0$ или комплексного переменного $s$, 
  $\mathfrak{Re}\,s\geqslant c_0$, определяемая равенством
  \[
  \varphi(s)=\M\,(e^{-\boldsymbol{X}}).
  \]
\end{definition}

В частности, если $\boldsymbol{X}$~--- дискретная случайная величина,
принимающая значение $x_k\geqslant0$ с вероятностью $p_k$, $k=1$, $2$, \ldots{},
то её преобразование Лапласа вычисляется с помощью ряда
\[
\varphi(s)=\sum_{k=1}^\infty e^{-s x_k} p_k.
\]
Также в теории массового обслуживания встречается случай \emph{смешанной}
случайной величины, имеющей как дискретную, так и непрерывную компоненту в законе
распределения. Пусть функция распределения случайной величина $\boldsymbol{X}$
равна
\enlargethispage{3ex}
\[
G(u)=\begin{cases}
  0 & \text{при $u\leqslant0$,}\\
\displaystyle  \sum_{x_k<u} p_k + \int_{0}^u f(t)\,dt  & \text{при $u>0$,}
\end{cases}
\]
где $p_k>0$, $f(t)\geqslant0$, $\sum\limits_{k}p_k+\int\limits_{-0}^\infty
f(t)\,dt=1$. Тогда 
\[
\M(e^{-s\boldsymbol{X}})=\sum_{k}p_ke^{-s x_k}+\int_{-\infty}^\infty e^{-st}
f(t)\,dt.
\]
Важными свойствами преобразования Лапласа являются следующие: если
неотрицательные случайные величины $\boldsymbol{X}$ и $\boldsymbol Y$
независимы, то преобразование Лапласа
$\varphi_{\boldsymbol{X}+\boldsymbol{Y}}(s)$ их суммы равно
$\varphi_{\boldsymbol{X}}(s)\cdot\varphi_{\boldsymbol{Y}}(s)$, где
$\varphi_{\boldsymbol{X}}(s)$ есть преобразование Лапласа для $\boldsymbol{X}$,
а $\varphi_{\boldsymbol{Y}}(s)$ есть преобразование Лапласа для
$\boldsymbol{Y}$. Если существует $\M(\boldsymbol{X}^k)$, то $\M(\boldsymbol{X}^k)=(-1)^k\varphi_{\boldsymbol{X}}^{(k)}(0)$.

Покажем теперь другое решение задачи о распределении периода занятости системы
M/M/1/$\infty$. Его можно получить, рассмотрев траекторию процесса
$\{\varkappa(t); t\geqslant0\}$. Пусть марковский процесс $\{\varkappa(t);
t\geqslant0\}$ имеет непрерывные справа траектории и пусть $\tau_1$, $\tau_2$,
\ldots{}~--- его моменты скачков. Последовательность $\varkappa_0=\varkappa(0)$,
$\varkappa_1=\varkappa(\tau_1)$, $\varkappa_2=\varkappa(\tau_2)$, \ldots{}
называется \emph{цепью скачков}. Введём величины $\xi_k=\tau_k-\tau_{k-1}$
интервалов между скачками, $k=1$, $2$, \ldots{}. Из теории марковских процессов
известно, что
\begin{multline*}
  \Pr\bigl( \mathop{\cap}\limits_{k=1}^n \{\omega\colon
  \varkappa_k=i_k, \xi_k<u_k
  \}\mid\{\omega\colon \varkappa_0=i_0\}\bigr)=
  \\ =
  \dfrac{a_{i_0,i_1}}{a_{i_0}}\times (1-e^{-a_{i_0} u_1})\times
  \dfrac{a_{i_1,i_2}}{a_{i_1}} (1-e^{-a_{i_1} u_2}) \times \ldots\times
  \dfrac{a_{i_{n-1},i_n}}{a_{i_{n-1}}} \times(1-e^{-a_{i_{n-1}} u_n}).
\end{multline*}
Другими словами, последовательность $\{\varkappa_k; k=0, 1, \ldots\}$ является
цепью Маркова, вероятность её перехода  из состояния $i$ в состояние $j$ равна
$a_{i,j}(a_i)^{-1}$, а при фиксированной траектории $i_0$, $i_1$, \ldots, $i_n$
величины интервалов условно независимы и интервал $\xi_k$ имеет экспоненциальное
распределение с параметром~$a_{i_{k-1}}$. Таким образом, после того, как
определены интенсивности перехода марковского процесса $\{\varkappa(t);
t\geqslant0\}$ по содержательной постановке задачи, можно мыслить этот процесс
как последовательность проходимых состояний и длительностей пребывания в них. На
рисунке~\ref{fig:birth-death} приводится пример реализации процесса гибели и
размножения. 

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}
    \draw[->] (0,0)--(0,3.5);
    \draw[->] (0,0)--(8.5,0);
    \draw
    (0.5,1)--(2,1)--(2,2)--(4,2)--(4,3)--(5.5,3)--(5.5,2)--(7,2)--(7,1)--(7.5,1);
    \draw[red] (2,2)--(4,2)
               (4,3)--(5.5,3)
               (5.5,2)--(7,2);
    \draw (0,0) node[anchor=north] {$O$}
          (0,3.5) node[anchor=west] {$\varkappa(t)$}     
          (8.5,0) node[anchor=south] {$t$}
          (0, 1) node[anchor=east] {$i-1$}
          (0, 2) node[anchor=east] {$i$}
          (0, 3) node[anchor=east] {$i+1$}
          (2,0) node[anchor=north] {$\tau_{k-1}$}
          (4,0) node[anchor=north] {$\tau_{k}$}
          (5.5,0) node[anchor=north] {$\tau_{k+1}$}
          (7,0) node[anchor=north] {$\tau_{k+2}$}
          (3,2) node[red,anchor=south] {$\xi_k$}
          (4.75,3) node[red,anchor=south] {$\xi_{k+1}$}
          (6.25,2) node[red,anchor=south] {$\xi_{k+2}$};
    \filldraw (0,1) circle (1pt)
         (0,2) circle (1pt)
         (0,3) circle (1pt)
         (2,0) circle (1pt)
         (4,0) circle (1pt)
         (5.5,0) circle (1pt)
         (7,0) circle (1pt);
    \draw[->,blue] (2,2) to[bend left] (3.9,3);
    \draw[->,blue] (2,2) to[bend right] (3.9,1);    
    \draw[blue] (3.1,3) node[anchor=south] {$\dfrac{\lambda_{i}}{\lambda_i+\mu_i}$}
          (3.3,1) node[anchor=north] {$\dfrac{\mu_{i}}{\lambda_i+\mu_i}$};
  \end{tikzpicture}
  \caption{Реализация процесса гибели и размножения \label{fig:birth-death}}
\end{figure}

Вернёмся к изучению периода занятости системы, описываемой процессом гибели и
размножения. Пусть $\tilde\Pi$ есть время достижения процессом $\{\varkappa(t);
t\geqslant0\}$ состояния $0$ и рассмотрим различные начальные состояния. Введём
соответствующее преобразование Лапласа
\[
\varphi_i(s)=\M(e^{-s\tilde\Pi}\mid\{\omega\colon \varkappa(0)=i\}), \qquad i=1,
2, \ldots.
\]
Очевидно, всё время достижения нуля состоит из двух частей: из интервала $\xi_1$
прибывания в начальном состоянии и из времени $\tilde\Pi_1$ достижения нуля из нового
состояния $\varkappa_1$. По формуле полного математического ожидания,
\begin{align*}
  \varphi_1(s)&= \dfrac{\mu_1}{\lambda_1+\mu_1}
  \M(e^{-s(\xi_1+\tilde\Pi_1)}\mid\{\omega\colon \varkappa_0=1, \varkappa_1=0\})
  +
  \\ & \quad 
  +\dfrac{\lambda_1}{\lambda_1+\mu_1}
  \M(e^{-s(\xi_1+\tilde\Pi_1)}\mid\{\omega\colon \varkappa_0=1,
  \varkappa_1=2\})=
  \\ & =
  \dfrac{\mu_1}{\lambda_1+\mu_1}\cdot
  \dfrac{\lambda_1+\mu_1}{\lambda_1+\mu_1+s}+
  \dfrac{\lambda_1}{\lambda_1+\mu_1}\cdot
  \dfrac{\lambda_1+\mu_1}{\lambda_1+\mu_1+s} \cdot \varphi_2(s)=
  \\ & =
  \dfrac{\mu_1}{\lambda_1+\mu_1+s}+
  \dfrac{\lambda_1}{\lambda_1+\mu_1+s} \cdot \varphi_2(s)\,. 
\end{align*}
Здесь мы использовали тот факт, что при достижении состояния $0$ величина
$\tilde\Pi_1$ равна нулю. Далее, аналогичные рассуждения дают:
\[
\varphi_i(s)=\dfrac{\mu_i}{\lambda_i+\mu_i+s} \cdot \varphi_{i-1}(s)+
\dfrac{\lambda_i}{\lambda_i+\mu_i+s} \cdot \varphi_{i+1}(s),\quad i=2, 3, \ldots{}.
\]

В частности, для системы M/M/1/$\infty$ полный период занятости совпадает с
временем достижения процессом состояния $i-1$ из состояния $i$. Следовательно,
время достижения нуля из состояния $i$ складывается из $i$ независимых и
одинаково распределенных величин. Значит,
$\varphi_i(s)=(\varphi_1(s))^i$. Возьмём первое из написанных выше равенств и
подставим $\varphi_2(s)=\varphi_1(s)^2$. Найдём:
\[
(\lambda+\mu+s)\varphi_1(s)= \mu + \lambda (\varphi_1(s))^2.
\]
Отсюда,
\[
\varphi_1(s)=\dfrac{\lambda+\mu+s-\sqrt{(\lambda+\mu+s)^2-4\lambda\mu}}{2\lambda}\,,
\]
поскольку именно эта из двух ветвей стремится к нулю при действительных $s$,
стремящихся к $\infty$. Легко видеть, что это решение фактически совпадает с
найденным ранее выражением для $s\tilde p_0(s)$. 

Хотя проблема обращения преобразования Лапласа требует изощрённых методов,
польза от преобразования Лапласа от законов распределений в том, что легко
находить числовые характеристики случайынх величин. Формальное дифференцирование
даёт:
\begin{gather*}
  -\dfrac{d}{ds}\M(e^{-s\Pi})
  \Big|_{s=0}=\M(\Pi)=\dfrac{1}{\mu-\lambda}\,,\\
  \dfrac{d^2}{ds^2}\M(e^{-s\Pi})
  \Big|_{s=0}=\M(\Pi^2)=\dfrac{2\mu}{(\mu-\lambda)^3}\,\\
  \D(\Pi)=\dfrac{\lambda+\mu}{(\mu-\lambda)^3}\,.
\end{gather*}

\subsection{Задачи}
\addtocontents{toc}{\protect\setcounter{tocdepth}{2}}
\subsubsection{}
  Найдите преобразование Лапласа случайной величины $X$, если она имеет\par
  \textit{i})~экспоненциальное распределение с параметром $\lambda$;\par
  \textit{ii)}~распределение Эрланга порядка $m$ с параметром $\lambda$;\par
  % \textit{iii})~распределение Пуассона с параметром $\lambda$;\par
  Обратите численно данные преобразования и сравните результат с точным решением.

\subsubsection{}
  \label{z:MM1-PS} Пусть в вычислительную систему поступает простейший
  поток заданий с интенсивностью~$\lambda$. Обработкой заданий занимается один
  процессор, работающий в режиме <<разделения процессора>>: если в системе
  присутствуют~$i$, то за промежуток времени $\Delta t$ каждое из требований
  получает порцию времени $\Delta t/i$. Из-за ограниченности ресурсом
  максимальное число заданий в системе конечно и равно $N$. Задания,
  заставшие все ресурсы занятыми, теряются. \par
  \textit{i})~Выпишите и решите численным методом дифференциальные уравнения для
  распределения вероятностей для числа требований в системе. \par
  \textit{ii})~Найдите с помощью численных методов линейной алгебры стационарное
  распределение для числа требований в системе. Сравните стационарное
  распределение с предельным распределением. Вспомните теорему Маркова.\par
  \textit{iii})~Найдите характеристики периода занятости в системе.


% \begin{zadacha}
%   Покажите, что преобразование Лапласа для времени ожидания начала обслуживания
%   произвольного не потерянного требования в стационарном режиме в системе
%   M/M/$n$/$r$ равно
%   \[
%   \dfrac{1}{1-p_{n+r}}\biggl( \sum_{k=0}^n p_k+n\mu
%   p_n\dfrac{1-\bigl(\frac{\lambda}{s+n\mu}\bigr)^r}{s+n\mu-\lambda}\biggr).
%   \]
%   Получите выражения для среднего значения этой величины и найдите численно
%   плотность абсолютно-непрерывной компоненты этого распределения при различных
%   значениях параметров.
% \end{zadacha}

\subsubsection{}
  Система $M^X/M/1/n$, группа содержит 1 или 2 требования. Численно изучить
  переходный режим.

\subsubsection{}
  В колл-центре имеется 32 телефонные линии и 3 специалиста-консультанта. Если в
  момент звонка есть свободный консультант, звонок направляется ему. Если все
  консультанты заняты, то поступивший звонок переводится в режим ожидания. Если
  все линии заняты ожидающими, то звонок теряется. Обслуживание в порядке
  поступления. При интенсивности 100 звонков в час, средней длительности
  разговора 4 минуты, изучите вероятность потери звонка и распределение времени
  ожидания клиентом обслуживания.
\newpage
\tableofcontents

\end{document}
