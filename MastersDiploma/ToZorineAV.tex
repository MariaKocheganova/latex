\documentclass[a4paper,14pt,russian]{article}
\usepackage{../MyPackages/commands}
\newcommand{\Pn}[3]{P^{(#1)} \br{#2,#3}}
\newcommand{\G}{\Gamma}
\newcommand{\e}{\eta_i^{(1)}}
\newcommand{\ee}{\eta_i^{(2)}}
\renewcommand{\b}{b^{(1)}}
\newcommand{\bb}{b^{(2)}}
\renewcommand{\P}[2]{P\br{\left. #1 \right| #2}}
\newcommand{\iakt}{[\tau_{i},\tau_{i+1})}
\newcommand{\Gr}[1]{\Gamma^{(#1)}}
\newcommand{\Mark}[0]{\brrr{\br{\G_i, \vk_i}, i \geqslant 0}}
\newcommand{\Markk}[0]{\brrr{ \vk_i, i \geqslant 0}}
\newcommand{\Markkhat}[0]{\brrr{ \hat{\vk}_i, i \geqslant 1}}
\newcommand{\Markkhata}[0]{\brrr{ \hat{\vk}_i\br{a}, i \geqslant 1}}
\newcommand{\Markkhato}[0]{\brrr{ \hat{\vk}_i\br{0}, i \geqslant 1}}
\newcommand{\Markkhatoa}[0]{\brrr{ \hat{\hat{\vk}}_i\br{a}, i \geqslant 1}}
\usepackage[Magistr]{../MyPackages/ptvstyle}
\title{Моделирование и анализ системы обслуживания конфликтных потоков в классе приоритетных алгоритмов}
\author{студент группы 85М1\\ Кочеганов В.~М.}
\advisor{к.ф.-м.н., доцент \\ Зорин А.~В.}
\chief{д.ф.-м.н., профессор \\ Федоткин М.~А.}
\date{2013}

\newcommand{\p}{\hat{p}}

\begin{document}

\maketitle
%\numberwithin{equation}{subsection}
\tableofcontents
%\addcontentsline{toc}{section}{Аннотация}

\newpage
\section*{Введение}
% Не удаляйте следующую строчку!
\addcontentsline{toc}{section}{Введение}
% Не удаляйте следующую строчку!

Исследование систем массового обслуживания --- специального класса математических моделей --- существенно при анализе функционирвоания 
таких сложных систем, как автоматические телефонные станции, автоматизированные информационные системы, системы связи, 
ЭВМ, различные диспетчерские службы, системы снабжения, медицинского обслуживания, транспортные системы, поточные линии и т.п. 
Во всех этих случаях имеют дело с массовой <<обработкой>> (<<обслуживанием>>) некоторых объектов при учете влияния случайных факторов.

Для повышения эффективности работы реальных систем бывает необходимо определять такие характеристики системы массового обслуживания,
 которые учитывают наличие очередей, ожидание начала обслуживания, простои системы и др. Эти характеристики описываются случайными прицессами и случайными величинами.

При решении вопроса о выборе алгоритма обслуживания требований, важным показателем является существование стационарного распределения 
и сам  вид этого распределения, в случае его существования. В настоящий момент эти вопросы не решены в том общем виде, который позволял 
бы найти с необходимой точностью требуемые вероятности. Предлагаемые методы доказательства существования стационарного распределения 
рассматриваемых в системе марковских цепей остаются <<творческими>>, и применение их в каждом конкретном случае приводит к качественно 
новым проблемам. Методы нахождения стационарных вероятностей имеют слишком большую вычислительную погрешность и их применение в следствие этого факта на практике затруднено.

В связи со сформулированными выше проблемами в работе рассматривается иной подход к решению вопроса о существовании стационарного распределения 
и его нахождении: метод, основанный на цензурировании марковских цепей.

\newpage
\section{Постановка задачи об обслуживании с относительным приоритетом}
%\addcontentsline{toc}{section}{Постановка задачи об обслуживании с относительным приоритетом}
\textit{Общее описание системы.}

В систему поступают $m<\infty$ входных потоков $\Pi_1$, $\Pi_2$, \ldots, $\Pi_m$. Потоки предполагаются неординарными, стационарными, без последействия и независимыми между собой. При этом требования по каждому потоку поступают группами, которые в свою очередь образуют простейшие потоки с интенсивностями $\la_1$, $\la_2$, $\ldots$, $\la_m$ соответственно. Распределение числа заявок в группе по потоку $\Pi_j$ имеет производящую функцию 
\begin{equation}
f_j(z)=\sum_{\nu=1}^{\infty}{p_{\nu}^{(j)} z^{\nu}}
\label{proizvod_func_one}
\end{equation}
для $ \abs{z} < \br{1 +\varepsilon}$, $\varepsilon >0$, и $p_{\nu}^{(j)} > 0$; величина $p_{\nu}^{(j)}$ определяет вероятность того, что по потоку $\Pi_j$ число требований в группе равно $\nu$.
Количества требований в различных группах также предполагаются независимыми случайными величинами. 
Индекс $j$ здесь и далее, если не будет особых оговорок, пробегает множество $\brrr{1, 2, \ldots, m}$.

Требования каждого потока становятся в соответствующие очереди $O_1$, $O_2$, $\ldots$, $O_m$ с неограниченными объемами. Дисциплина каждой очереди имеет тип FIFO (First In First Out), то есть для обслуживания из очереди выбирается то требование, которое пришло раньше.

Обслуживающий прибор только один и обслуживает одновременно одно требование. У обслуживающего устройства имеются $m$ состояний, которые объединим в одно множество 
$$\Gamma = \brrr{\Gamma^{(1)}, \Gamma^{(2)}, \ldots, \Gamma^{(m)}};$$
будем считать, что в состоянии $\Gamma^{(j)}$ обслуживается требование из очереди $O_j$. Длительность обслуживания требования из очереди $O_j$ задается функцией распределения $B_j(t)$. Обслуживание осуществляется в классе алгоритмов с относительными приоритетами: прерывания не допускаются и на обслуживание выбирается требование из непустой очереди с наивысшим приоритетом. Причем требование, находящееся в очереди $O_j$, является тем приоритетнее для прибора, чем ниже номер $j$. В случае отсутствия требований в очередях, на облуживание направляется первое поступившее в систему требование. 

Обслуженное требование сразу покидает систему.

\textit{Основные обозначения.}

Под рабочим актом будем понимать промежуток времени обслуживания одного требования. Наблюдение за системой будем осуществлять в моменты $\tau_i$ --- момент окончания $i$-го рабочего акта; будем считать $\tau_0 = 0$; $i \geqslant 0$.

Нам понадобятся следующие случайные величины и элементы системы:

$\eta_{j,i}^{(1)} \in \brrr{0,1}$ --- количество поступивших требований в очередь $O_j$ от момента $\tau_i$ до начала $(i+1)$-го рабочего акта 
(т.е. на протяжении времени отсутствия требований в очередях); $\eta_{j,i}^{(2)} \in \brrr{0,1,\ldots}$ --- число требований, пришедших в очередь $O_j$ за $(i+1)$-ый рабочий акт; $ \eta_{j,i} = \eta_{j,i}^{(1)}+\eta_{j,i}^{(2)}$ --- общее число требований, пришедших в очередь $O_j$ за промежуток $(\tau_i,\tau_{i+1}]$; $i \geqslant 0$;

$\xi_{j,i}$ и $\overline{\xi}_{j,i}$ определяют для очереди $O_j$ на промежутке $(\tau_i,\tau_{i+1}]$ соответственно  максимально возможное число обслуженных заявок (в случае бесконечной очереди) и число фактически обслуженных требований; $i \geqslant 0$;

положим  
\begin{equation*}
\eta_i^{(1)} = \br{\eta_{1,i}^{(1)}, \eta_{2,i}^{(1)}, \ldots, \eta_{m,i}^{(1)}}, \quad
\eta_i^{(2)} = \br{\eta_{1,i}^{(2)}, \eta_{2,i}^{(2)}, \ldots, \eta_{m,i}^{(2)}}, \quad
\eta_i = \br{\eta_{1,i}, \eta_{2,i}, \ldots, \eta_{m,i}}
\end{equation*}
и
\begin{equation*}
\xi_i = \br{\xi_{1,i}, \xi_{2,i}, \ldots, \xi_{m,i}}, \quad \overline{\xi}_i = \br{\overline{\xi}_{1,i}, \overline{\xi}_{2,i}, \ldots, \overline{\xi}_{m,i}}.
\end{equation*}

$\vk_{j,i}$ --- величина очереди $O_j$ в момент $\tau_i$; данная величина учитывает в себе требование, которое будет обслуживаться в следующем рабочем акте, если он начинается сразу с момента $\tau_i$ (т.е. считается, что это требование еще не покинуло очередь), и не учитывает требования, пришедшие в систему в момент $\tau_i$, если таковые имеются; объединим величины $\vk_{j,i}$ также в вектора $\vk_{i} = \br{\vk_{1,i}, \vk_{2,i}, \ldots, \vk_{m,i}}$; $i \geqslant 0$;

обозначим через $y^{(j)}\in R^m$ вектор, только $j$-ая координата которого отлична от нуля и равна $1$; положим для однообразия $y^{(0)}\in R^m$ нулевым вектором; обозначим множество $\brrr{y^{(r)} \colon 0 \leqslant r \leqslant m} = Y$; пусть также уравнения $f(y^{(r)}) = r$ ($r=0$, $1$, $\ldots$, $m$) задают биективную функцию $f(\cdot)$, определенную только в точках множества $Y$;

величина $\vartheta_i$ равна номеру очереди, в которую пришло первое требование начиная с момента $\tau_i$ до начала $(i+1)$-го рабочего акта, при $\vk_i = y^{(0)}$, и равна $0$ при $\vk_i \neq y^{(0)}$; в соответствии с определением функции $f(\cdot)$, можно определить $\vartheta_i$ равенством $\vartheta_i = f(\eta_{i}^{(1)})$; $i \geqslant 0$; 

$\Gamma_{i+1} \in \Gamma $ --- состояние обслуживающего прибора на промежутке $(\tau_i,\tau_{i+1}]$, причем $\Gamma_i = \Gamma^{(j)}$, если система на протяжении $i+1$ акта обслуживала требование из очереди $O_j$; $i \geqslant 1$;

$X = Z_{+}^m$ --- целочисленная неотрицательная решетка на множестве $R^m$; $\Delta_i$ --- продолжительность $(i+1)$-го рабочего акта; $i \geqslant 0$.

\textit{Описание системы в виде маркированного точечного процесса.}

В соответствии с введенными обозначениями, можно ввести следующие процессы, описывающие данную систему массового обслуживания.

Нелокальное описание системы можно представить в виде маркированного точечного процесса $\brrr{\br{\tau_i,\nu_i}, i\geqslant 0}$, где $\nu_i= \br{\Delta_i,\Gamma_i,\vk_i,\vartheta_i}$  --- метка процесса и элементы $\G_0$ и $\vk_0$ заданы.
	
Для исследования вероятностных свойств входного потока, потока насыщения и процесса обслуживания выделим из процесса $\brrr{\br{\tau_i,\nu_i}, i\geqslant 0}$ дискретные компоненты $\eta_i$, $\xi_i$ и $\br{\G_i,\vk_i}$ соответственно.

\textit{Формализация принципа работы СМО.}

В соответствии с описанной схемой действия СМО и введенными понятиями, работу обслуживающего устройства удобнее задать следующим образом. 

На протяжении времени  $(\tau_i,\tau_{i+1}]$ обслуживающее устройство находится в состоянии $\G_{i+1} \in \G$; закон изменения этого состояния задается следующим приоритетным правилом:
\begin{equation}
\G_{i+1} = u\br{\G_i, \vk_i, \vartheta_i} = u\br{\vk_i, \vartheta_i},
\label{gamma_func}
\end{equation}
где $ u\br{\vk_i, \vartheta_i}= \Gr{j}$, $j = \mathrm{arg}\max_{1\leqslant r\leqslant m} \vk_{r,i} $ при $\vk_i \neq y^{(0)}$ и $j=\vartheta_i$, если $\vk_i = y^{(0)}$.

Далее, функциональная зависимость 
\begin{equation*}
\overline{\xi}_{j,i} = g_{j,i} \br{\vk_{j,i}, \eta_{j,i}, \xi_{j,i}}, \quad  i \geqslant 0,
\end{equation*}
реализует некоторую стратегию механизма обслуживания требований, причем с очевидностью должны выполняться неравенства
\begin{equation*}
0 \leqslant \overline{\xi}_{j,i}  \leqslant \min\brrr{\vk_{j,i} + \eta_{j,i},  \xi_{j,i}} = \xi_{j,i}, \quad i \geqslant 0,
\end{equation*}
поскольку для данного вида систем имеет место одно из двух положений:

а) обслуживающее устройство на промежутке $(\tau_i, \tau_{i+1}]$ находится в состоянии $\G_{i+1} \hm= \Gr{j}$, и поэтому $\vk_{j,i} + \eta_{j,i} \geqslant 1$, $\xi_{j,i} = 1$;

б) обслуживающее устройство на этом промежутке находится в состоянии $\G_{i+1} \neq \Gr{j}$ и, следовательно, одновременно $\vk_{j,i} + \eta_{j,i} \geqslant 0$, $\xi_{j,i} = 0$.

Поэтому естественно положить $\overline{\xi}_{j,i} = \xi_{j,i}$; в противном случае может случиться так, что в системе будут возникать простои даже при наличии требований в очередях.

Закон формирования очереди по потоку $\Pi_j$ задается рекуррентными по $i \geqslant 0$ соотношениями
\begin{equation}
\vk_{j,i+1} = \vk_{j,i} + \eta_{j,i} - \overline{\xi}_{j,i} = \vk_{j,i} + \eta_{j,i} - \xi_{j,i}
\label{queue_func}
\end{equation}


\textit{Свойства условных распределений.}

Для описанных особенностей СМО проведем вероятностную интерпретацию, заканчивающую математическую формализацию задачи. Но для этого нам понадобится вспомогательная лемма.
\lemma{ Пусть поток $\Pi$ является простейшим потоком групп требований с параметром $\la$, причем количества требований в разных группах потока независимы между собой,  и производящая функция количества требований в одной группе равна $f(z)$, $\abs{z} < (1 + \varepsilon)$. Тогда производящая функция $F(t,z)$ числа требований $\zeta (t)$ за промежуток времени длины $t$ по потоку $\Pi$ будет вычисляться по формуле 
$$F(z) = e^{\la t\br{f(z)-1}}$$ для $\abs{z} < (1 + \varepsilon)$.
\label{proizvod_func_two}
}
\begin{proof}
Обозначая число поступивших групп за промежуток времени длины $t$ через $\mathcal{N}(t)$, по обобщенной формуле полной вероятности имеем 
\begin{equation*}
F(t, z) = M\brr{z^{\zeta(t)}} = M\brr{ M\brr{\left.z^{\zeta(t)}\right|\mathcal{N}(t)}};
\end{equation*}
раскладывая $\zeta(t)$ при известном $\mathcal{N}(t)$ на сумму количеств требований в каждой группе $\zeta(t) = \zeta_1(t) + \zeta_2(t) + \ldots + \zeta_{\mathcal{N}(t)}{}(t)$, получим
\mll
{
F(t,z) = \sum_{ k = 0}^ {\infty} P\br{\mathcal{N}(t) = k} M\brr{ \left. z^{\zeta(t)}\right|\mathcal{N}(t) = k} = \\ 
= \sum_{ k = 0}^ {\infty} P\br{\mathcal{N}(t) = k} M\brr{ \left. z^{\zeta_1(t)} \times z^{\zeta_2(t)} \times  \ldots \times  z^{\zeta_{\mathcal{N}(t)}(t)} \right|\mathcal{N}(t) = k} = \\ 
= \sum_{ k = 0}^ {\infty} P\br{\mathcal{N}(t) = k} M\brr{ \left. z^{\zeta_1(t)} \times z^{\zeta_2(t)} \times  \ldots \times z^{\zeta_{k}(t)} \right|\mathcal{N}(t) = k} = \\ 
= \sum_{ k = 0}^ {\infty} P\br{\mathcal{N}(t) = k} M\brr{  z^{\zeta_1(t)} \times z^{\zeta_2(t)} \times  \ldots z^{\zeta_{k}(t)}}  = \\ = \sum_{ k = 0}^ {\infty} P\br{\mathcal{N}(t) = k} \times M \brr{z^{\zeta_1(t)}} \times M \brr{z^{\zeta_1(t)}} \times \ldots \times  M \brr{z^{\zeta_k(t)}} = \\ 
= \sum_{ k = 0}^ {\infty} P\br{\mathcal{N}(t) = k} \br{M \brr{z^{\zeta_1(t)}}}^k =  \sum_{ k = 0}^ {\infty} P\br{\mathcal{N}(t) = k}  \br{f(z)}^k =  \sum_{ k = 0}^ {\infty} e^{-\la t}\frac{\br{\la t}^k}{k!}  \br{f(z)}^k
}

Утверждение леммы завершает тот факт, что ряд $ \sum_{ k = 0}^ {\infty} e^{-\la t}\frac{\br{\la t}^k}{k!}  \br{f(z)}^k$  сходится к $e^{\la t (f(z) - 1)}$ при любом $z$, для которого определена функция $f(z)$.
\end{proof}

 Из определения величины $\e$, $i \geqslant 0$, и того факта, что вероятность поступления в пустую систему требования из потока $\Pi_j$ раньше других равна 
 \begin{equation}
p_j = \la_j/\sum_{i = 1}^{m}\la_i,
\label{p_definition}
\end{equation}
 следуют равенства
\begin{equation}
\P{\e = b}{\G_i = \gamma, \vk_i = x} = \P{\e = b}{ \vk_i = x} =
\begin{cases}
p_j ,& \text{при $b = y^{(j)}$, $x = y^{(0)}$}\\
1 ,& \text{при $ b = y^{(0)}$, $x \neq y^{(0)}$}\\
0 ,& \text{иначе }\\
\end{cases}
\label{eta1_func}
\end{equation}
и, учитывая определение $\eta_i^{(2)}$, имеем
\ml
{
\P{\ee = b}{\G_i = \gamma, \vk_i = x, \e = \b} = \P{\ee = b}{\vk_i = x, \e = \b} =\\=
\int_{0}^{\infty} \prod_{s=1}^m \alpha_{s,b_s} (t) dB_j(t) =  \vp_j(b)
 \label{eta2_func}
}
где $\alpha_{s,b_s} (t)$ определяется из разложения в ряд Тейлора функции 
\begin{equation}
F_s (t, z) = e^{\la_s t (f_s(z)-1)}=\sum_{k=0}^{\infty} \alpha_{s,k}(t) z^k,
\end{equation}
и $b = \br{b_1, b_2, \ldots, b_m} \in X$, $x \in X$, $\gamma \in \G$, $\b \in Y$ и $j$ таково, что $\G^{(j)} = u\br{x,f(\b)}$.

Далее, учитывая определение $\xi_i$ и формулу \eqref{gamma_func}, можно заключить, что
\begin{equation}
\P{\xi_i = y^{(j)}}{\G_i = \gamma, \vk_i = x, \e = \b, \ee=\bb} = 1,
\label{xi_func}
\end{equation}
если $u\br{x,f\br{\b}} = \Gr{j}$, и эта же вероятность равна $0$ во всех других случаях. Заметим также, что вероятность не зависит от $\G_i$.

В соответствии с  \eqref{gamma_func} и \eqref{queue_func} можно провести следующие выкладки для $i \geqslant 0$:
\mll
{
\P{\G_{i+1} = \G^{(j)},\vk_{i+1} = x_{i+1}}{\G_{i_1} = \gamma_{i_1},\vk_{i_1}=x_{i_1},0\leqslant i_1 \leqslant i,\e = \b, \ee = \bb, \xi_i = y^{\br{j}}} =\\=
P\left(u\br{\vk_i,\vartheta_i} = \G^{(j)},\vk_{i} + \eta_i - \xi_i = x_{i+1}\right|\\ \left|\G_{i_1} = \gamma_{i_1},\vk_{i_1}=x_{i_1},0\leqslant i_1 \leqslant i,\e = \b, \ee = \bb, \xi_i = y^{\br{j}}\right) =\\
=P\br{u\br{x_{i},f\br{\b}} = \G^{(j)},x_{i+1} =x_{i}+\b+\bb - y^{\br{j}} },
} откуда 
\ml
{
\P{\G_{i+1} = \G^{(j)},\vk_{i+1} = x_{i+1}}{\G_{i_1} = \gamma_{i_1},\vk_{i_1}=x_{i_1},0\leqslant i_1 \leqslant i,\e = \b, \ee = \bb, \xi_i = y^{\br{j}}} = \\=\begin{cases} 
1,& \text{если }u\br{x_{i},f\br{\b}}=\G^{(j)}, x_{i+1} =x_{i}+\b+\bb - y^{\br{j}} \\
0,& \text{иначе}
\end{cases};
\label{gamma_x_mark}
}
здесь $\gamma_{s} \in \G$, $x_{s} \in X$, $\b \in Y$, $\bb \in X$, $i \geqslant 0$, $0\leqslant s \leqslant (i+1)$.

Поскольку количество поступивших требований за промежуток $(\tau_i; \tau_{i+1}]$ может зависеть от длительности этого промежутка, но не от предыстории системы до момента $\tau_i$ (так как входящие потоки групп являются простейшими и количество требований в разных группах независимы друг от друга), а $\xi_i$ функционально зависит от $\vk_i$ и $\e$ (см. определение $\xi_i$), верны равенства
\ml
{
\P{\e = \b,\ee = \bb, \xi_i = y^{(j)}}{\G_{i_1} = \gamma_{i_1}, \vk_{i_1} = x_{i_1}, 0\leqslant i_1 \leqslant i} =\\
=\P{\e = \b,\ee = \bb, \xi_i = y^{(j)}}{\G_{i} = \gamma_{i}, \vk_{i} = x_{i}} =\\= \P{\e = \b,\ee = \bb, \xi_i = y^{(j)}}{\vk_{i} = x_{i}},
\label{eta_mark}
}
для $\gamma_{s} \in \G$, $x_{s} \in X$, $\bb \in X$, $i \geqslant 0$, $0\leqslant s \leqslant i$.

\remark{ Если рассматривать введенные условные вероятности $\P{A}{B}$ в соответствии с определением $\P{A}{B} = \frac{P(A \bigcap B)}{P(B)}$, то в некоторых случаях они теряют всякий смысл (например, при $B = \brrr{\omega \colon \G_i = \Gr{2}, \vk_i = \br{1, 0, 0, \ldots, 0}}$, вероятность $P(B)$ равна нулю). Поэтому здесь и далее в работе будем придерживаться обобщения определения условных вероятностей относительно случайных величин и элементов, введенное А.~Н.~Колмогоровым. Из этого определения, в частности, следует, что для множеств $B$, в совокупности образующих множество меры ноль, величину $\P{A}{B}$ можно взять произвольной.}

\section{Получение рекуррентных соотношений для одномерных распределений последовательностей $\Mark$  и $\Markk$}
%\addcontentsline{toc}{section}{Получение рекуррентных соотношений для одномерных распределений последовательностей $\Mark$  и $\Markk$}
\lemma{Последовательность $\Mark$ при заданном распределении начального вектора $\br{\G_0, \vk_0}$ является марковской цепью.}
\begin{proof}
Учитывая формулу полной вероятности, \eqref{gamma_x_mark} и \eqref{eta_mark}, для $\gamma_{s} \in \G$, $x_s \in X$, $0 \leqslant s \leqslant (i+1)$  и $i \geqslant 0$ имеем:
\ml
{
\P{\G_{i+1} = \Gr{j}, \vk _{i+1} = x_{i+1}}{\G_{i_1} = \gamma_{i_1}, \vk_{i_1} = x_{i_1}, 0 \leqslant i_1\leqslant i} =\\= \sum_{\substack{\b \in Y, \bb \in X\\ r = 1,2,\ldots,m}} P\left(\G_{i+1} = \Gr{j}, \vk _{i+1} = x_{i+1}, \e = \b, \ee = \bb , \xi_i = y^{(r)}\right|\\ \left|\G_{i_1} = \gamma_{i_1}, \vk_{i_1} = x_{i_1}, 0 \leqslant i_1\leqslant i\right)  = \\ = \sum_{\substack{\b \in Y, \bb \in X\\ r = 1,2,\ldots,m}} \P{\e = \b, \ee = \bb , \xi_i = y^{(r)}}{\G_{i_1} = \gamma_{i_1}, \vk_{i_1} = x_{i_1}, 0 \leqslant i_1\leqslant i}  \times \\ \times \P{\G_{i+1} = \Gr{j}, \vk _{i+1} = x_{i+1}}{\G_{i_1} = \gamma_{i_1}, \vk_{i_1} = x_{i_1}, 0 \leqslant i_1\leqslant i,  \e = \b, \ee = \bb , \xi_i = y^{(r)}}  = \\ = \sum_{\substack{\b \in Y, \bb \in X\\ r = 1,2,\ldots,m}} \P{\e = \b, \ee = \bb , \xi_i = y^{(r)}}{\G_{i} = \gamma_{i}, \vk_{i} = x_{i}}  \times \\ \times \P{\G_{i+1} = \Gr{j}, \vk _{i+1} = x_{i+1}}{\G_{i} = \gamma_{i}, \vk_{i} = x_{i},   \e = \b, \ee = \bb , \xi_i = y^{(r)}}
\label{temp_one}
}
С другой стороны, по формуле полной вероятности получим
\ml
{
\P{\G_{i+1} = \Gr{j}, \vk_{i+1} = x_{i+1}}{\G_i = \gamma_i, \vk_i = x_i} = \\ = \sum_{\substack{\b \in Y, \bb \in X\\ r = 1,2,\ldots,m}} \P{\G_{i+1} = \Gr{j}, \vk _{i+1} = x_{i+1}, \e = \b, \ee = \bb , \xi_i = y^{(r)}}{\G_{i} = \gamma_{i}, \vk_{i} = x_{i}} = \\ = \sum_{\substack{\b \in Y, \bb \in X\\ r = 1,2,\ldots,m}} \P{\e = \b, \ee = \bb , \xi_i = y^{(r)}}{\G_{i} = \gamma_{i}, \vk_{i} = x_{i}}  \times \\ \times \P{\G_{i+1} = \Gr{j}, \vk _{i+1} = x_{i+1}}{\G_{i} = \gamma_{i}, \vk_{i} = x_{i},  \e = \b, \ee = \bb , \xi_i = y^{(r)}}
\label{temp_two}
}
Сравнивая \eqref{temp_one} и \eqref{temp_two} получаем утверждение леммы.
\end{proof}

Поскольку величина $\vk_i$ выражается в соответствии с \eqref{queue_func}, то из 
\eqref{eta_mark} аналогичными рассуждениями доказывается
\lemma{Последовательность $\Markk$ при заданном распределении начального вектора $\vk_0$ является марковской цепью.}

\lemma{Имеют место следующие рекуррентные по $i \geqslant 0$ соотношения для одномерных распределений марковской цепи $\Mark$:
\ml
{
P\br{\G_{i+1} = \Gr{j}, \vk_{i+1}  = x} = \sum_{l = 1}^m P\br{\G_{i} = \Gr{l}, \vk_i = y^{(0)}} p_j \vp_j(x) + \\ 
+ \sum_{\tilde{x} \in \tilde{X}(j)} \sum_{l=1}^m P\br{\G_i = \Gr{l}, \vk_i = \tilde{x}} \vp_j\br{x - \tilde{x} + y^{(j)}},
\label{rek}
}
где $\tilde{x} = (\tilde{x}_1, \tilde{x}_2, \ldots, \tilde{x}_m)$, $x \in X$ и 
$$
\tilde{X}\br{j}= \brrr{\tilde{x} \in X \backslash \brrr{y^{(0)}}\colon \min \brrr{1 \leqslant s \leqslant m \colon \tilde{x}_s \neq 0} = j}
$$

} 
\begin{proof}
По формуле полной вероятности имеем:
\mll
{
P\br{\G_{i+1} = \Gr{j}, \vk_{i+1}  = x}  = \sum_{l=1}^m \sum_{\tilde{x}} P\br{\G_i = \Gr{l}, \vk_i = \tilde{x}}\times \\ \times \sum_{\b, \bb, y} \P{\e = \b}{\G_i = \Gr{l}, \vk_i = \tilde{x} } \P{\ee = \bb}{\G_i = \Gr{l}, \vk_i  = \tilde{x}, \e =\b} \times \\
\times \P{\xi_i=y}{\G_i = \Gr{l} , \vk_i = \tilde{x}, \e = \b, \ee = \bb} \times \\ 
\times \P{\G_{i+1} = \Gr{j}, \vk_{i+1} = x}{\G_i = \Gr{l} , \vk_i = \tilde{x}, \e = \b, \ee = \bb, \xi_i = y},
}
где суммирование происходит по $\b \in Y$, $\bb \in X$, $y \in Y\backslash \brrr{y^{(0)}}$ и $\tilde{x} \in X$.

Из \eqref{gamma_x_mark} видно, что ненулевыми остаются слагаемые, для которых $u\br{\tilde{x}, f\br{\b}} = \Gr{j}$; в соответствии с  \eqref{xi_func} при $y \neq y^{(j)}$ слагаемые также занулятся, поэтому оставим $y = y^{(j)}$.

Далее выделим из суммы слагаемое с $\tilde{x} = y^{(0)}$. В соответствии с  \eqref{gamma_x_mark} получаем, что в этом слагаемом остаются члены с $\b = f^{-1}(j)$ и $\bb = x$:
$$
 \sum_{l = 1}^m P\br{\G_{i}  = \Gr{l}, \vk_i = y^{(0)}} p_j \vp_j(x).
$$
В оставшейся сумме ненулевыми могут быть только слагаемые, в которых $\b = y^{(0)}$  (см. \eqref{eta1_func}). При этом из \eqref{gamma_x_mark} опять получаем условие на $\bb$: $\bb = x - \tilde{x} + y$, а также условие на $\tilde{x}$: $\min \brrr{1 \leqslant s \leqslant m \colon \tilde{x}_s \neq 0} = j$; соответствующее слагаемое  примет вид
$$
 \sum_{\tilde{x} \in \tilde{X}(j)} \sum_{l=1}^m P\br{\G_i = \Gr{l}, \vk_i = \tilde{x}} \vp_j\br{x - \tilde{x} + y^{(j)}}.
$$

Складывая полученные выражения, получим требуемые рекуррентные соотношения.
\end{proof}

\lemma{Имеют место следующие рекуррентные по $i \geqslant 0$ соотношения для одномерных распределений марковской цепи $\Markk$:
\ml
{
P\br{\vk_{i+1} = x} = P\br{\vk_i = y^{(0)}} \sum_{j = 1}^m p_j \vp_j(x) +  \sum_{j = 1}^m \sum_{\tilde{x} \in \tilde{X}(j)} P\br{\vk_i = \tilde{x}} \vp_j\br{x - \tilde{x} + y^{(j)}},
\label{rekk}
}
где $\tilde{x} = (\tilde{x}_1, \tilde{x}_2, \ldots, \tilde{x}_m)$, $x \in X$ и, как и раньше, 
$$
\tilde{X}\br{j} = \brrr{\tilde{x} \in X \backslash \brrr{y^{(0)}}\colon \min \brrr{1 \leqslant s \leqslant m \colon \tilde{x}_s \neq 0} = j}
$$}
\begin{proof}
Учитывая \eqref{rek}, получим:
\mll
{
P\br{\vk_{i+1} = x} = \sum_{j=1}^m P\br{\G_{i+1} = \Gr{j}, \vk_{i+1} = x} = \\ 
=  \sum_{j = 1}^m p_j \vp_j(x) \sum_{l = 1}^m P\br{\G_i = \Gr{l},\vk_i = y^{(0)}}+\\ +  \sum_{j = 1}^m \sum_{\tilde{x} \in \tilde{X}(j)} \vp_j\br{x - \tilde{x} + y^{(j)}} \sum_{l = 1}^m  P\br{\G_i = \Gr{l}, \vk_i = \tilde{x}} = \\
=P\br{\vk_i = y^{(0)}} \sum_{j = 1}^m p_j \vp_j(x) +  \sum_{j = 1}^m \sum_{\tilde{x} \in \tilde{X}(j)} P\br{\vk_i = \tilde{x}} \vp_j\br{x - \tilde{x} + y^{(j)}},
}
что и требовалось доказать.
\end{proof}

\section{Классификация состояний марковской цепи $\Mark$}
%\addcontentsline{toc}{section}{Классификация состояний марковской цепи $\Mark$}
Под фазовым пространством состояний марковской цепи $\Mark$ будем понимать декартово произведение $E = \G \times X$.

Для решения вопроса о классификации нам понадобятся переходные вероятности в явном виде (см. \eqref{rek}):
\begin{align}
&\P{\G_{i+1} = \Gr{j}, \vk_{i+1} = x}{\G_i = \gamma, \vk_i = y^{(0)}} = p_j\vp_j(x),
\label{rek_new_one} \\
&\P{\G_{i+1} = \Gr{j}, \vk_{i+1} = x}{\G_i = \gamma, \vk_i = \tilde{x}} =
\nonumber \\
&=\begin{cases}
\vp_j( x- \tilde{x} + y^{(j)}), & \text{если $\tilde{x}\neq0$ и $\min\brrr{1 \leqslant s \leqslant m \colon \tilde{x}_s \neq 0} = j$},\\
0, & \text{если $\tilde{x}\neq0$ и $\min\brrr{1 \leqslant s \leqslant m \colon \tilde{x}_s \neq 0} \neq j$},
\end{cases}
\label{rek_new_two}
\end{align}
где $x$, $\tilde{x} \in X$. Отсюда, в частности, видно, что переходные вероятности не зависят от состояния прибора $\G_i$ в настоящий момент времени $\tau_i$, то есть переходные вероятности для соответствующих состояний равны.

\subsection{Классификация состояний по арифметическим свойствам переходных вероятностей}
%\addcontentsline{toc}{subsection}{Классификация состояний по арифметическим свойствам переходных вероятностей}
\lemma{Марковская цепь $\Mark$ из любого состояний вида $(\tilde{\gamma},\tilde{x})$, $\tilde{\gamma} \in \G$, $\tilde{x} \in X \backslash \brrr{y^{(0)}}$, с ненулевой вероятностью за конечное число шагов попадает в состояние вида $(\gamma, y^{(0)})$, $\gamma \in \G$.
\label{lem_direct_one}}
\begin{proof}
Пусть цепь находится в момент $\tau_i$ в состоянии $(\tilde{\gamma}, \tilde{x})$, причем $\tilde{x} \neq y^{(0)}$. Тогда из \eqref{rek_new_two} для $j = \min \brrr{1 \leqslant s \leqslant m \colon \tilde{x}_s \neq 0}$ и $x = \tilde{x} - y^{(j)}$ имеем 
$$
\P{\G_{i+1} = \Gr{j},\vk_{i+1} = \tilde{x} - y^{(j)}}{\G_i = \tilde{\gamma}, \vk_i = \tilde{x}} = \vp_j\br{ \tilde{x} - y^{(j) } - \tilde{x} + y^{(j)}} = \vp (j, y^{(0)})
$$ 
В соответствии с \eqref{proizvod_func_one} и  \eqref{eta2_func} имеем 
$$
\vp_j(y^{(0)}) = \int_{0}^{\infty} \prod_{s=1}^{m} e^{-\la_s t} dB_j(t) =  \int_{0}^{\infty} e^{-\la_+ t} dB_j(t)>0,
$$
где $\la_+ = \sum_{s=1}^m \la_s$.

Таким образом, какое бы ни было состояние $(\tilde{\gamma}, \tilde{x})$, $\tilde{\gamma} \in \G$, $\tilde{x} \in X\backslash\brrr{y^{(0)}}$, всегда существует ненулевая вероятность перейти в состояние с очередью меньшей $\tilde{x}$ на единицу по какой-то одной компоненте. Продолжая этот процесс, рано или поздно цепь попадет в состояние вида $(\gamma, y^{(0)})$, $\gamma \in \G$.
\end{proof}

\lemma{Марковская цепь $\Mark$ из любого состояния вида $(\gamma, y^{(0)})$, $\gamma \in \G$, с ненулевой вероятностью за конечное число шагов попадает в любое другое состояние $\br{\Gr{j},\tilde{x}}$, $\tilde{x} \in X$, фазового пространства $E$.
\label{lem_reverse_one}}
\begin{proof}
Пусть цепь находится в состоянии $(\gamma, y^{(0))})$. Рассуждениями, аналогичными рассуждениям предыдущей леммы, можно показать, что с ненулевой вероятностью цепь перейдет в состояние вида $\br{\tilde{\gamma}, (0,0,\ldots, 0, 1, 0, \ldots, 0)}$, в котором все очереди, кроме $j$-ой, свободны. Тогда состояние прибора к концу следующего рабочего акта будет равно $\Gr{j}$, а по входным потокам с ненулевой вероятностью поступят ровно $\tilde{x}$ требований, так что следующим состоянием будет $\br{\Gr{j}, \tilde{x}}$. Что и требовалось доказать.
\end{proof}

Из лемм \eqref{lem_direct_one} и \eqref{lem_reverse_one} с очевидностью вытекает 
\lemma{ Из любого состояния фазового пространства $E$ марковская цепь $\Mark$ с ненулевой вероятностью за конечное число шагов переходит в любое другое состояние фазового пространства $E$.
\label{lem_res_one}
}

Фазовое пространство $E$ является счетным множеством, поэтому можно некоторым способом установить взаимно-однозначное соответствие его элементов с элементами натурального ряда $N$. Тогда будем, где это не вызовет двусмысленности, вместо элементов множества $E$ писать их номер. В связи с этим, вероятности перехода из состояния $l$ в состояние $k$ за $n$ шагов будем обозначать $\Pn{n}{l}{k}$.

\theorem{Все состояния марковской цепи $\Mark$ существенные.}
\begin{proof}
Из леммы \eqref{lem_res_one} следует, что для любых состояний $k$ и $l$ существует такое количество шагов $n$, что $\Pn{n}{k}{l}>0$. Отсюда утверждение теоремы становится тривиальным.
\end{proof}

\theorem{ Все состояния марковской цепи $\Mark$ сообщающиеся.}
\begin{proof}
Непосредственно из леммы \eqref{lem_res_one} следует, что для любых состояний $k$ и $l$  существуют такие $n_1$ и $n_2$, что $\Pn{n_1}{k}{l}>0$ и $\Pn{n_2}{l}{k}>0$. Теорема доказана.
\end{proof}

Из этой теоремы можно сделать вывод, что фазовое пространство $E$ состоит из единственного неразложимого класса состояний. Найдем в этом классе период какого-либо состояния $k$, то есть число $d = d(k)$, удовлетворяющее следующим двум свойствам:
\begin{enumerate}
\item $\forall l \in E$ из того, что $\Pn{n}{k}{l}> 0 $ следует, что $n = d m$, $m \in N$;
\item $d$ --- наибольшее из чисел, удовлетворяющих условию $1$.
\end{enumerate}
 Периоды остальных состояний будут с ним совпадать.

\theorem{Состояния марковской цепи $\Mark$ являются апериодическими.}
\begin{proof}
Из доказательства лемм \eqref{lem_direct_one}  и  \eqref{lem_reverse_one}  можно заметить, что если для перехода из состояния $k$ в состояние $l$ было сделано $n$ шагов (таким образом, $\Pn{n}{k}{l}>0$), то ничто не мешает сделать этот переход за $(n+1)$  шаг. Действительно, в лемме \eqref{lem_reverse_one} вместо перехода в состояние $\br{\tilde{\gamma}, (0,0,\ldots, 0, 1, 0, \ldots, 0)}$ можно перейти в состояние $\br{\tilde{\gamma}, (0,0,\ldots, 0, 2, 0, \ldots, 0)}$, что отсрочило бы на $1$ шаг попадание цепи в состояние $l$. Следовательно, из $\Pn{n}{k}{l}>0$ следует $\Pn{n+1}{k}{l}>0$,  и для $d$ получаем следующие равентства 
\begin{align*}
 n &= d m_1, \quad m_1 \in N,\\
n + 1 &= d m_2 , \quad m_2 \in N,
\end{align*}
откуда находим, что $d=1$.
\end{proof}

\section{Классификация состояний марковской цепи $\Markk$}
%\addcontentsline{toc}{section}{Классификация состояний марковской цепи $\Markk$}

Для цепи $\Markk$ под фазовом пространством состояний будем понимать множество $E_{\vk} = X$, где мнемоника $\vk$ означает <<удаление>> из всех элементов множества $E = \brrr{e = (\gamma,x) \colon \gamma \in \G, x \in X}$ компоненты $\gamma$ (состояния обслуживающего прибора) и рассмотрение лишь компоненты $x \in X$ (состояния очереди).

Выпишем переходные вероятности и для этой марковской цепи в явном виде:
\begin{align}
\P{\vk_{i+1} = x}{\vk_i = y^{(0)}} & = \sum_{j = 1}^m p_j\vp_j(x),
\label{rekk_new_one} \\
\P{ \vk_{i+1} = x}{\vk_i = \tilde{x}} & =
%&=\begin{cases}
\vp_j( x- \tilde{x} + y^{(j)}),
%0, &\text{если $\tilde{x}\neq0$ и $\min\brrr{1 \leqslant s \leqslant m \colon \tilde{x}_s \neq 0} \neq j$},
%\end{cases}
\label{rekk_new_two}
\end{align}
где $\tilde{x}\neq0$ и $\min\brrr{1 \leqslant s \leqslant m \colon \tilde{x}_s \neq 0} = j$; $x, \tilde{x} \in X$.

\subsection{Классификация состояний по арифметическим свойствам переходных вероятностей}
%\addcontentsline{toc}{subsection}{Классификация состояний по арифметическим свойствам переходных вероятностей}

Все утверждения, связанные с классификацией марковской цепи $\Mark$, переносятся с очевидными изменениями в формулировках и доказательствах на рассматриваемый случай. Как альтернативный вариант, доказательства также можно провести, основываясь на уже доказанных соответствующих утверждениях для марковской цепи $\Mark$.

В связи с этим, приведем лишь измененные формулировки.

\lemma{Марковская цепь $\Markk$ из любого состояния $\tilde{x} \in E_{\vk} \backslash \brrr{y^{(0)}}$ с ненулевой вероятностью за конечное число шагов попадает в состояние $x = y^{(0)}$.
\label{lem_dir_two}}

\lemma{Марковская цепь $\Markk$ из состояния $x = y^{(0)}$ с ненулевой вероятностью за конечное число шагов попадает в любое другое состояние $x$ фазового пространства $E_{\vk}$.
\label{lem_reverse_two}
}\par
Из лемм \eqref{lem_dir_two} и \eqref{lem_reverse_two} вытекает 
\lemma{ Из любого состояния фазового пространства $E_{\vk}$ марковская цепь $\Markk$ с ненулевой вероятностью за конечное число шагов переходит в любое другое состояние фазового пространства $E_{\vk}$.
\label{lem_res_two}
}

\theorem{Все состояния марковской цепи $\Markk$ существенные.}

\theorem{Все состояния марковской цепи $\Markk$ сообщающиеся.\label{soob_markk}}

Из последней теоремы видно, что фазовое пространство $E_{\vk}$ состоит из единственного неразложимого класса состояний.

\theorem{Состояния марковской цепи $\Markk$ являются апериодическими.}




\section{Соотношения для производящих функций}
%\addcontentsline{toc}{section}{Соотношения для производящих функций}

Положим для $v = \br{v_1, v_2, \ldots, v_m}$ и $w = \br{w_1, w_2, \ldots, w_m}$
$$
v^w = v_1^{w_1} \times v_2^{w_2} \times \ldots \times v_m^{w_m},
$$
а также введем производящие функции
\begin{align*}
\mathfrak{M}^{(i)}\br{\Gr{j},v} &= \sum_{w\in X} P\br{\G_i=\Gr{j},\vk_i=w}v^w,\\
 \mathfrak{M}_{\vk}^{(i)}\br{v} &= \sum_{w\in X} P\br{\vk_i=w}v^w,\\
\Phi^{(i)}\br{\Gr{j},v} &=  \sum_{w \in \tilde{X}(j)} P\br{\vk_i = w} v^w,
\end{align*}
для $i\geqslant 0$. Тогда непосредственно из \eqref{rek} получим
\ml
{
\mathfrak{M}^{(i+1)}\br{\Gr{j},v} = P\br{\vk_i=y^{(0)}}p_j\sum_{w\in X}\vp_j\br{w}v^w +\\+ \sum_{x \in \tilde{X}(j)} \sum_{w\in X}v^w P\br{\vk_i = x}\vp_j\br{w-x+y^{(j)}}
}
Обозначим 
\begin{equation}
q_j(v) = v_j^{-1} \sum_{w \in X} \vp_j\br{w} v^w
\label{q}
\end{equation}

Далее, поскольку  $v^{-y^{(j)}} = v_j^{-1}$ и $\vp_j \br{ w-x+y^{(j)}} = 0$, если хотя бы одна компонента вектора $\br{w-x + y^{(j)}}$ отрицательна, выводим
\mll
{
\mathfrak{M}^{(i+1)}\br{\G^{(j)},v} = P\br{\vk_i = y^{(0)}} p_j \sum_{w \in X} \vp_j\br{w}v^w + \\
+ \sum_{x \in \tilde{X}(j)} P\br{\vk_i =x } v^x v_j^{-1} \sum_{w \in X}\vp_j\br{w} v^w = \\
= p_j v_j q_j(v) P\br{\vk_i = y^{(0)}} + q_j(v) \Phi^{(i)}\br{\Gr{j},v}.
}

Из  \eqref{eta2_func}  можем расписать 
\mll
{
\sum_{w\in X}\vp_j\br{w}v^w = \int_0^{\infty} \prod_{s=1}^m \sum_{w_s \geqslant 0} \alpha_{s, w_s}(t) v_s^{w_s} d B_j (t) = \int_0^{\infty} \prod_{s=1}^m F_s\br{t, v_s}d B_j(t) = \\
= \int_{0}^{\infty} \prod_{s=1}^m e^{\la_s t (f_s(v_s) - 1)} d B_j(t) = \int_{0}^{\infty} e^{\sum_{s=1}^m \br{\la_s t (f_s(v_s) - 1)}} d B_j(t),
}
где знаки интегрирования и суммирования можно менять местами в силу равномерной сходимости соответственно интегралов $\int_0^{\infty} \prod_{s=1}^m \alpha_{s, w_s}(t) v_s^{w_s} d B_j (t) $ по $w \geqslant \overline{0}$  и рядов $\sum_{w _s\geqslant 0}\alpha_{s,w_s}(t)v_s^{w_s}$ по $t \in R^+$. 

Окончательно сформулируем следующие теоремы.

\theorem{Имеют место следующие рекуррентные по $i \geqslant 0$ соотношения для многомерных производящих функций марковской цепи $\Mark$:

\begin{equation}
\mathfrak{M}^{(i+1)} \br{\Gr{j}, v} = p_j v_j q_j(v) P\br{\vk_i = y^{(0)}} + q_j(v) \Phi^{(i)} \br{\Gr{j},v}
\end{equation}
}

\theorem{Имеют место следующие рекуррентные по $i \geqslant 0$ соотношения для многомерных производящих функций марковской цепи $\Markk$:

\begin{equation}
\mathfrak{M}^{(i+1)}_{\vk} \br{v} =P\br{\vk_i = y^{(0)}} \sum_{j=1}^m p_j v_j q_j(v)  + \sum_{j=1}^m q_j(v) \Phi^{(i)} \br{\Gr{j},v}
\label{markk_proiz}
\end{equation}
}
\begin{proof}
Утверждение теоремы получаем из предыдущей теоремы и очевидного равенства
$$
\mathfrak{M}^{(i+1)}_{\vk} (v) = \sum_{j=1}^{m} \mathfrak{M}^{(i+1)} \br{\Gr{j},v}.
$$
\end{proof}

\section{Условия существования стационарного распределения марковской цепи $\Markk$}
%\addcontentsline{toc}{section}{Условия существования стационарного распределения марковской цепи $\Markk$}
Обозначим 
\begin{align*}
\beta_{r,1}& = \int_0^{\infty} t d B_r(t), &    \rho&  =\la_+ \sum_{k=1}^m p_k f'_k(1) \beta_{k,1} \\
\beta_+& = \max_{1 \leqslant r \leqslant m} \beta_{r,1},&  \beta_-& =\min_{1\leqslant r \leqslant m} \beta_{r,1}
\end{align*}

\theorem{Для существования стационарного распределения 
$$
Q(x) = \lim_{i \to \infty} P\br{\vk_i = x}, \quad x \in X
$$
последовательности $\brrr{\vk_i, i\geqslant 0}$ необходимо выполнение неравенства $\rho < 1$.
}

\begin{proof}
Пусть при каждом $1 \leqslant j \leqslant m$ $F_j(u)$ --- произвольная дифференцируемая в окрестности точки $u=1$ функция, имеющая в точке $u=1$ положительную производную $F'_j(1)$, и $F_j(1) = 1$. Тогда поскольку 
$$
q_j(v) = v_j^{-1} \int_0^{\infty} \exp{\br{-\la_+ (1-z)t}}d B_j(t), \quad z = \sum_{k=1}^m p_k f_k (v_k),
$$
имеем
\mll
{
\left.\frac{d}{du}\brr{q_j\br{F(u)}}\right|_{u=1} = q_j'(1) = -F'_j(1) + \sum_{k=1}^{m} \beta_{j,1} \la_+ p_k f'_k(1) F'_k(1) = \beta_{j,1} \la_+ \sum_{k=1}^m p_k f'_k(1)F_k'(1) - F'_j(1),
}
где $F(u) = \br{F_1(u), F_2(u), \ldots, F_m(u)}$.

Подберем $F(u)$ так, чтобы набор чисел $\brrr{F'_j(1), 1 \leqslant j \leqslant m}$ совпадал с набором $\brrr{\beta_{j,1}, 1 \leqslant j \leqslant m}$. Тогда $q'_j(1) = \beta_{j,1} \rho - \beta_{j,1} = \beta_{j,1} \br{\rho -1}$.

Пусть последовательность $\Markk$ имеет стационарное распределение. Выберем его в качестве начального:
$$
P\br{\vk_0 = x} = Q(x), \quad x \in X.
$$

Пусть приняты обозначения 
\begin{align*}
\mathfrak{M}_{\vk}\br{v} &= \sum_{w \in X} Q\br{w} v^w, \\
\Phi\br{\Gr{j},v} &=  \sum_{w \in \tilde{X}(j)} Q\br{w}v^w,
\end{align*}
Тогда, разлагая функции $q_j\br{F(u)}$ и $F_j(u)\cdot q_j\br{F(u)}$ в левой окрестности точки $u=1$ (и, следовательно,  $F(u) < 1$, поскольку $F(1) = 1$ и $F'(1)>0$) по степеням $(u-1)$, принимая во внимание равенство $\sum_{j = 1}^{m} \Phi\br{\Gr{j}, v} + Q\br{y^{(0)}} = \mathfrak{M}_{\vk}(v)$ и применяя \eqref{markk_proiz} найдем
\mll
{
\mathfrak{M}_{\vk}\br{F(u)} = Q\br{y^{(0)}} \sum_{j=1}^m p_j \br{F_j(1) q_j\br{F(1)} + \br{F'_j(1) +\beta_{j,1} (\rho - 1)} (u-1) + O\br{\br{u-1}^2}} + \\ + \sum_{j=1}^m \Phi \br{\Gr{j}, F(u)} \br{q_j(1) + \beta_{j,1} (\rho - 1) (u-1) + O\br{\br{u-1}^2}} =\\= Q\br{y^{(0)}} +  Q\br{y^{(0)}}\rho (u-1) \sum_{j=1}^m p_j \beta_{j,1}  
+\sum_{j=1}^m \Phi \br{\Gr{j}, F(u)} +\\+ (\rho - 1) (u-1)\sum_{j=1}^m \Phi \br{\Gr{j}, F(u)} \beta_{j,1}  + O\br{\br{u-1}^2} .
}

Разделим полученное равенство на $(u-1)$ и устремим $u \to 1$, тогда
$$
 Q\br{y^{(0)}}\rho \sum_{j=1}^m p_j \beta_{j,1}  + (\rho - 1)\sum_{j=1}^m \Phi \br{\Gr{j}, F(1)} \beta_{j,1} = 0,
$$
откуда получим выражение для $\rho$:
$$
\rho = \br{\sum_{j=1}^m \Phi \br{\Gr{j}, F(1)} \beta_{j,1}} \br{ Q\br{y^{(0)}} \sum_{j=1}^m p_j \beta_{j,1} +\sum_{j=1}^m \Phi \br{\Gr{j}, F(1)} \beta_{j,1} }^{-1} < 1,
$$
поскольку 
\begin{equation}
Q\br{y^{(0)}} \sum_{j=1}^m p_j \beta_{j,1} > 0.
\label{Q}
\end{equation}

Неравенство \eqref{Q} верно для рассматриваемой системы в следствие неравенств $p_j > 0$, $\beta_{j,1} > 0$ и $Q\br{y^{(0)}}>0$. Для доказательства последнего неравенства достаточно рассмотреть все возможные случаи (см. рассуждения \cite[гл. $3$ пар. 3-4]{Shiryaev}):
\begin{enumerate}
\item все состояния цепи $\Markk$ невозвратные, тогда $\lim_{n \to \infty}\Pn{n}{i}{l} = 0$ и стационарного распределения не существует;
\item существует хотя бы одно возвратное состояние, тогда все состояния возвратные (поскольку все состояния сообщающиеся); пусть все состояния нулевые, тогда $\Pn{n}{i}{l} \to 0$ и стационарного распределения не существует;
\item все состояния возвратные и существует хотя бы одно положительное, тогда все состояния положительные и пределы $\lim_{n \to \infty}\Pn{n}{i}{l} >0$ являются стационарными вероятностями;
\end{enumerate}
\end{proof}

\theorem{Для существования стационарного распределения 
$$
Q(x) = \lim_{i \to \infty} P\br{\vk_i = x}, \quad x \in X
$$
последовательности $\brrr{\vk_i, i\geqslant 0}$ достаточно выполнения неравенства $\rho < 1$.
} 

\begin{proof}
Пусть $\rho < 1$ и цепь $\Markk$ не имеет стационарного распределения. Тогда по рассуждениям конца предыдущей теоремы независимо от начального распределения $P\br{\vk_0 = x}$, $x \in X$, имеют место предельные равенства 
\begin{equation}
\lim_{i \to \infty} P\br{\vk_i = x} = 0, \quad x \in X. 
\label{lim_equations}
\end{equation}


Выберем начальное распределение так, чтобы выполнялось неравенство $\mathfrak{M}_{\vk}^{(0)}\br{F(u_0)}<\infty$ для некоторого $u_0 > 1$ такого, что $F(u_0) > 1$. Это ограничение, в силу \eqref{markk_proiz}, обеспечивает при любом $i \geqslant 0$ существование функций 
\begin{equation*}
\mathfrak{M}^{(i)}_{\vk}\br{F(u)}, \quad \frac{d}{du} \brr{\mathfrak{M}^{(i)}_{\vk}\br{F(u)}}
\end{equation*}
по крайней мере в некоторой окрестности точки $u=1$. 

В силу равенств \eqref{lim_equations},  для любого натурального числа $M$ найдется такое число $I$, что для всех $i > I$ будет $1 > (1+M)\sum_{s=1}^m \sum_{x_s = 0}^M  P\br{\vk_i = x}$. 
Тогда 
\mll
{
\sum_{s = 1}^m E\brr{\vk_{s,i}} = \sum_{s = 1}^m \sum_{x_s = 0}^M x_s P\br{\vk_{s,i} = x_s}  +  \sum_{s = 1}^m \sum_{x_s = M + 1}^{\infty} x_s P\br{\vk_{s,i} = x_s} \geqslant \\   \geqslant   \sum_{s = 1}^m \sum_{x_s = M + 1}^{\infty} x_s P\br{\vk_{s,i} = x_s}   \geqslant \br{M+1} \sum_{s = 1}^m \sum_{x_s = M + 1}^{\infty} P\br{\vk_{s,i} = x_s}  =  \br{M+1} \sum_{s=1}^m P\br{\vk_{s,i} \geqslant M} \geqslant \\ \geqslant \br{M+1} \br{1 - \frac{1}{M+1}} = M;
}
стало быть, $\sum_{j=1}^m E\brr{\vk_{j,i}}$ неограниченно возрастает при $i \to \infty$. 

Другое рассуждение, однако, приводит к противоположному результату. Действительно, при $\rho < 1$ имеем $q'_j(1) = \beta_{j,1}(\rho - 1) < 0$. Если теперь ради определенности допустим $\beta_- = \beta_{1,1}$, то при $\mathfrak{M}_{\vk,+}^{(0)}(v) =\mathfrak{M}_{\vk}^{(0)}(v) $ и $v = F(u)$ в некоторой правой окрестности  $1 < u\leqslant u_1 < u_0$ точки $u=1$ последовательность $\brrr{\mathfrak{M}_{\vk,+}^{(i)}\br{F(u)}, i \geqslant 0}$ рекуррентного отображения 
\begin{equation}
\mathfrak{M}_{\vk,+}^{(i+1)}\br{F(u)} = q_1\br{F(u)} \mathfrak{M}_{\vk,+}^{(i)}\br{F(u)} + L(u)
\label{markk_proiz_+}
\end{equation}
будет мажорантной для последовательности  $\brrr{\mathfrak{M}_{\vk}^{(i)}\br{F(u)}, i \geqslant 0}$ рекуррентного отображения \eqref{markk_proiz}, где $L(u) = \sum_{s = 1}^m F_s (u)$. Нетрудно убедиться, что в некоторой правой окрестности $1 < u \leqslant u_2 < u_1$ точки  $u= 1$ будет выполнено неравенство $0 < q_1\br{F(u)} < 1$, так как $q_1\br{F(1)} = 1$ и 
$$
\left. \frac{d}{du}\brr{q_1\br{F(u)})} \right|_{u=1} = \beta_+(\rho - 1)<0
$$
при $\rho < 1$. Но тогда числовая последовательность $\brrr{\mathfrak{M}_{\vk,+}^{(i)}\br{F(u_2)}, i \geqslant 0}$, порожденная рекуррентным соотношением \eqref{markk_proiz_+} при $u = u_2$ сходится и, следовательно, 
ограничена некоторым числом $\tilde{M}$. Итак, для всех $i \geqslant 0$ будет $0 < \mathfrak{M}_{\vk}^{(i)}\br{F(u_2)} \leqslant \mathfrak{M}_{\vk, +}^{(i)}\br{F(u_2)}< \tilde{M}$ и, значит,  $0 < \mathfrak{M}_{\vk}^{(i)}\br{F(u_2)}< \tilde{M}$ при $\abs{v_j}\leqslant F_j(u_2)$, где $F_j(u_2)>1$. В частности, в некоторой окрестности точки $v_j$ функции 
$$
\mathfrak{M}_{j,\vk}^{(i)} (v_j) = \sum_{x \in X} P\br{\vk_i = x} v_j^{x_j}
$$
аналитические и равномерно по $i$ ограничены, например, числом $\tilde{M}$. Теперь без труда получается, что числовая последовательность 
$$
\brrr{\sum_{j=1}^m \left.\frac{d}{d v_j}\brr{\mathfrak{M}_{j,\vk}^{(i)} (v_j)}\right|_{v_j = 1} = \sum_{j=1}^m E\brr{\vk_{j,i}}, i \geqslant 0} 
$$
в силу интегральной формулы Коши ограничена некоторой постоянной величиной. Поэтому принятое в самом начале доказательства этой теоремы предположение не будет справедливым. Доказательство этим завершается.
\end{proof}

\newpage

\section{Стационарное распределение марковской цепи $\Markk$ в случае $m=2$. Цензурированные марковские цепи}
%\addcontentsline{toc}{section}{Стационарное распределение в случае $m=2$. Цензурированные марковские цепи}

\subsection{Дополнительные обозначения}
%\addcontentsline{toc}{subsection}{Основные обозначения}

В случае двух очередей пространство состояний $E_{\vk}$ марковской цепи
$\Markk$ примет вид $E_{\vk} = Z_+^2$, а переходные
вероятности из \eqref{rekk_new_one} и \eqref{rekk_new_two}  упростятся следующим образом:
\begin{align}
&\P{\vk_{i+1} = \br{x_1,x_2}}{\vk_i =\br{0,0}}  = p_1\vp_1(x_1, x_2) + p_2\vp_2(x_1, x_2) = p \br{0, 0, x_1, x_2} ,
\label{rekk_2d_one} \\
&\P{ \vk_{i+1} = \br{x_1,x_2}}{\vk_i = \br{\tilde{x}_1,\tilde{x}_2}} =
\nonumber \\
&=\begin{cases}
\vp_1(x_1- \tilde{x}_1 + 1,x_2- \tilde{x}_2), &\text{ если } \tilde{x}_1 > 0,\\
\vp_2(x_1 ,x_2- \tilde{x}_2 + 1),  &\text{ если } \tilde{x}_1 = 0 \text{ и } \tilde{x}_2 > 0,
\end{cases}  = p \br{\tilde{x}_1, \tilde{x}_2, x_1, x_2}
\label{rekk_2d_two}
\end{align}
где $x = \br{x_1,x_2}, \tilde{x}=  \br{\tilde{x}_1,\tilde{x}_2}\in Z_+$ и для удобства введено новое обозначение для переходных вероятностей $p \br{\tilde{x}_1, \tilde{x}_2, x_1, x_2}$.

Зафиксируем множество состояний $E^a_{\vk} = \brrr{\br{x_1,x_2} \in Z_+^2 \colon x_1 \leqslant a} \subseteq E_{\vk}$
для некоторого $a \geqslant 0$, которое назовем
цензурирующим множеством, и рассмотрим
последовательные моменты попадания марковской цепи $\Markk$ в него. Определим эти моменты следующим образом:
\begin{equation}
\begin{array}{lll}
\theta_1 (a) &=& \min \brrr{k \geqslant 0 \colon \vk_k \in E^a_{\vk}},\\
\theta_{i+1} (a) &=& \min \brrr{k > \theta_i (a) \colon \vk_k \in E^a_{\vk}}, \quad i = 1, 2, \ldots.
\end{array}
\label{theta_mark}
\end{equation}
В результате цензурирования получим новую последовательность случайных величин:
\begin{equation}
 \hat{\vk}_i (a)= \vk_{\theta_i (a)}, \quad i \geqslant 1.
 \label{markkhat}
\end{equation}

\lemma{Последовательность $\Markkhata$, определяемая соотношениями \eqref{theta_mark} и \eqref{markkhat}, является марковской цепью.
\label{lemma:markovost}}
\begin{proof}
 Утверждение леммы следует из строго марковского свойства цепи $\Markk$ (см. \cite[теорема п. 5, пар. 1, гл. 8]{Shiryaev})
 и того факта, что случайные величины  $ \theta_{k} (a), k = 1, 2, \ldots$, являются моментами останова для марковской цепи $\Markk$. 
 
 Последнее верно, поскольку, зная значения случайных  величин $\br{\vk_0, \vk_1, \ldots, \vk_n}$, 
 можно абсолютно точно определить, имеет ли место событие $\brrr{\theta_k (a) = n }$.
 Другими словами,  для любых $k \geqslant 1, n \geqslant 0$ событие $\brrr{\theta_k (a) = n}$ принадлежит наименьшей сигма-алгебре 
 $\sigma\br{\vk_0, \vk_1, \ldots, \vk_n}$,  порожденной случайными величинами $\br{\vk_0, \vk_1, \ldots, \vk_n}$. 
 Следовательно, $\theta_k (a), k = 1, 2, \ldots,$ являются моментами останова по определению.
\end{proof}
 
Марковская цепь $\Markkhata$ носит название цензурированная марковская цепь.

\subsection{Вспомогательные вероятности}
%\addcontentsline{toc}{subsection}{Вспомогательные вероятности}
%Пусть цепь $\Markk$ после некоторого $\hat{i}$ рабочего акта находится в состоянии $\br{x_1, x_2}$.
Введем событие $A\br{x_1,x_2,x_1-1,x_2+w}$, заключающееся в том, что цепь $\Markk$ из состояния $\br{x_1,x_2} \in E_{\vk}$, в котором она находилась
в некоторый момент времени $\hat{i}$, впоследствии впервые приходит во $E_{\vk}^{x_1-1} = \brrr{(a,b) \in Z_+^2 \colon a \leqslant x_1 -1}$ через состояние $\br{x_1-1,x_2 + w}$:
\begin{multline*}
 A\br{x_1,x_2,x_1-1,x_2+w} = \\
 \brrr{\omega \colon \vk_{\hat{i}}=\br{x_1,x_2}} \bigcap  \bigcup_{\hat{k}\geqslant \hat{i} + 1}\br{ \bigcap_{\hat{l}= \hat{i}}^{\hat{k}-1}
  \brrr{\omega \colon \vk_{\hat{l}} \notin E_{\vk}^{x_1-1} } \bigcap \brrr{\omega \colon \vk_{\hat{k}} = \br{x_1 - 1, x_2 + w}} },
\end{multline*}
где $x_1 > 0, w \geqslant 0$. В дальнейшем нам будет нужна вероятность введенного события, поэтому найдем ее.

Из свойства марковости цепи $\Markk$ следует независимость
события $A\br{x_1,x_2,x_1-1,x_2+w}$ от состояния $\br{x_1,x_2}$, поэтому введем следующее обозначение:
\begin{equation}
 P\br{A\br{x_1,x_2,x_1-1,x_2+w}} = \alpha\br{w}, \quad x_1 > 0, w \geqslant 0.
  \label{addition_prob_three}
\end{equation}

\remark{Поскольку марковская цепь $\Markk$ является однородной, то рассматриваемые в этом пункте вероятности не зависят от номера рабочего акта $\hat{i}$. По этой причине зависимость событий от
$\hat{i}$ опускается.}


\begin{lemma}
Вероятности $\alpha\br{w}$, определенные в \eqref{addition_prob_three}, удовлетворяют следующей системе уравнений:
 \begin{align}
\alpha\br{w} &= \vp_1\br{0,w} + \sum_{k=1}^{\infty} \sum_{w_0 + w_1 + \ldots + w_k = w} \vp_1\br{k,w_0} \alpha\br{w_1}
 \alpha\br{w_2} \ldots \alpha\br{w_k}, \quad w \geqslant 0,
 \label{alpha_eq}
\end{align}
где $\vp_1\br{x,y}$ из \eqref{eta2_func}. 
\end{lemma}

\begin{proof}
Для доказательства рассмотрим совокупность несовместных событий $B_{k,w_0}\br{x_1,x_2}$, $k = 0, 1, \ldots$, $w_0 = 0, 1, \ldots, w$, объединение которых 
$\bigcup_{k\geqslant 0} \bigcup_{w_0 = 0}^{w} B_{k,w_0}\br{x_1,x_2}$ есть более широкое событие, чем $A\br{x_1,x_2,x_1-1,x_2+w}$:
\begin{align}
B_{k^1, w_0^1} \br{x_1,x_2} \bigcap B_{k^2, w_0^2} \br{x_1,x_2} &= \emptyset, \quad \br{k^1, w_0^1} \neq \br{k^2, w_0^2}, \\
A\br{x_1,x_2,x_1-1,x_2+w} &\subseteq \bigcup_{k\geqslant 0} \bigcup_{w_0 = 0}^{w} B_{k,w_0}\br{x_1,x_2},
\label{ab_rel}
\end{align}
где $x_1 >0$, $x_2 \geqslant 0$, $k^1,k^2 \geqslant 0$ и $0 \leqslant w_0^1, w_0^2 \leqslant w$.
В качестве события $B_{k,w_0}\br{x_1,x_2}$ возьмем событие, заключающееся в том,
что цепь $\Markk$, находясь в момент времени $\hat{i}$ в состоянии $\br{x_1,x_2}$, в следующий момент времени $(\hat{i}+1)$ окажется в состоянии $\br{x_1 + k - 1,x_2 + w_0}$ 
(качественно это означает, что в систему в течение $(\hat{i}+1)$ рабочего акта поступят $k$ и $w_0$ требований первого и второго типа соответственно):
\begin{equation*}
 B_{k,w_0}\br{x_1,x_2} = \brrr{\omega \colon \vk_{\hat{i}} = \br{x_1,x_2}} \bigcap \brrr{\omega \colon  \vk_{\hat{i}+1} = \br{x_1 + k - 1, x_2 + w_0}}.
\end{equation*}

Поскольку введеные события удовлетворяют соотношению \eqref{ab_rel}, то по формуле полной вероятности можно записать:
\begin{multline}
 P\br{A\br{x_1,x_2,x_1-1,x_2+w}} = \\ = \sum_{k\geqslant 0} \sum_{w_0 = 0}^{w} P\br{B_{k,w_0}\br{x_1,x_2}} P\br{A\br{x_1,x_2,x_1-1,x_2+w}|B_{k,w_0}\br{x_1,x_2}}.
 \label{addition_prob_one}
\end{multline}

Из формулы \eqref{rekk_2d_two} можем заключить, что  
\begin{equation}
 P\br{B_{k,w_0}\br{x_1,x_2}} = \vp_1\br{k,w_0}
 \label{addition_prob_two}
 \end{equation}
и эта вероятность не зависит от состояния $\br{x_1,x_2}$. 

Найдем теперь оставшиеся, условные вероятности. В тривиальном случае $k=0$, когда цепь сразу же попадает во множество $E_{\vk}^{x_1-1}$, имеем
\begin{equation}
 P\br{A\br{x_1,x_2,x_1-1,x_2+w}|B_{0,w}\br{x_1,x_2}} = 1.
 \label{addition_prob_two_one}
\end{equation}
Далее будем считать, что $k>0$.

После того, как цепь попадет на первом шаге из состояния $\br{x_1,x_2}$  в состояние
$\left( x_1 + k - 1\right.$, $\left. x_2 + w_0\right)$, $k > 0$, ее дальнеший путь до состояния $\br{x_1,x_2}$ можно разделить на 
$k$ итераций, определенных по некоторому правилу: 
\begin{itemize}
 \item из состояния $\br{x_1 + k -1,x_2 + w_0}$ рано или поздно придет в состояние $\br{x_1+ k -2,x_2 + w_0 + w_1}$ (для некоторого
 $w_1 \leqslant w - w_0$), не зайдя до этого ниразу во множество вида 
$\brrr{(a,b)\in Z_+^2  \colon a < x_1+ k - 1}$; 
 \item из $\br{x_1+ k -2,x_2 + w_0 + w_1}$ в $\br{x_1+ k - 3,x_2 + w_0 + w_1 + w_2}$ (для некоторого $w_2 \leqslant w - w_0-w_1$), не зайдя до этого ниразу во множество вида $\brrr{(a,b) \in Z_+^2  \colon a < x_1+ k -2}$;
 \item $\ldots$
 \item из $\br{x_1,x_2 + w_0 + w_1 + \ldots + w_{k - 1}}$ в $\br{x_1 - 1,x_2 + w_0 + w_1 + \ldots + w_{k - 1} + w_k}$
 (для $w_k$ такого, что $w_0 + w_1 + \ldots + w_{k - 1} + w_k = w$), 
 не зайдя до этого ниразу во множество вида $\brrr{(a,b) \in Z_+^2  \colon a < x_1 }$
 \end{itemize}
 
Путь цепи можно представить таким образом в следствие двух фактов: 
\begin{enumerate}
\item все состояния марковской цепи $\Markk$ являются сообщающимися (см. теорему \ref{soob_markk}) 
\item эта марковская цепь не имеет пропусков в левом направлении
ни по одной координате своих состояний (так как обслуживающий прибор может обслуживать одновременно только одно требование), поэтому 
за один шаг любая из координат не может уменьшиться больше, чем на единицу. 
\end{enumerate}
%Таким образом, на каждой $i$-ой итерации ($1 \leqslant i \leqslant k$) в очереди будет появляться дополнительные $w_i$ требований второго типа. 
Теперь являются обоснованными следующие выкладки:
  \begin{multline*}
P\br{A\br{x_1,x_2,x_1-1,x_2+w}|B_{k,w_0}\br{x_1,x_2}} =\\= \sum_{w_0 + w_1+w_2 +\ldots + w_k = w} 
P\left(A\br{x_1+k -1,x_2 + w_0,x_1 + k -2,x_2+w_0 + w_1} \bigcap \right. \\ \bigcap
A\br{x_1+k -2,x_2 + w_0 + w_1,x_1 + k -3,x_2+w_0 + w_1 + w_2}\bigcap \ldots \bigcap \\ \left.  \bigcap 
A\br{x_1,x_2 + w_0 + w_1 + \ldots + w_{k-1},x_1 - 1,x_2+w}|B_{k,w_0}\br{x_1,x_2}\right),
 \end{multline*}
где снова в силу марковского свойства цепи $\Markk$ при вычислении последних вероятностей условие $B_{k,w_0}\br{x_1,x_2}$ можно отбросить
и вероятность произведения оставшихся событий записать как произведение вероятностей этих событий; тогда получим:
\begin{equation}
 P\br{A\br{x_1,x_2,x_1-1,x_2+w}|B_{k,w_0}\br{x_1,x_2}} = \sum_{w_0 + w_1 + \ldots + w_k = w} \alpha\br{w_1}
 \alpha\br{w_2} \ldots \alpha\br{w_k}
 \label{addition_prob_four}
 \end{equation}
 
Подставляя \eqref{addition_prob_two},\eqref{addition_prob_two_one} и \eqref{addition_prob_four}  в  \eqref{addition_prob_one}, получим формулу 
\eqref{alpha_eq}.

 \end{proof}
\subsection{Переходные вероятности цензурированных цепей}
%\addcontentsline{toc}{subsection}{Переходные вероятности цензурированных цепей}

Обозначим вероятность перехода цензурированной марковской цепи $\Markkhata$ из состояния $\br{x_1,x_2} \in E_{\vk}^a$ 
в состояние $\br{w_1,w_2} \in E_{\vk}^a $ через $\p^a \br{x_1,x_2,w_1,w_2}$.

Отметим сначала следующее важное свойство переходных вероятностей $p \br{x_1, x_2, w_1, w_2}$ исходной марковской цепи $\Markk$, вытекающее непосредственно из \eqref{rekk_2d_one} и \eqref{rekk_2d_two}:
\begin{equation}
\begin{array}{llll}
\displaystyle p \br{x_1, x_2, w_1, w_2} &=& p_1 \br{w_1 - x_1, w_2 - x_2},& \quad x_1 > 0\\
\displaystyle p \br{0, x_2, w_1, w_2} &=& p_2 \br{w_1, w_2 - x_2},&\quad x_2 > 0,
\end{array}
\label{transition_property:1}
\end{equation}
где $p_1 \br{w_1 - x_1, w_2 - x_2} = \vp_1(w_1- x_1 + 1,w_2- x_2)$ и $p_2 \br{w_1, w_2 - x_2} = \vp_2(w_1,w_2- x_2 + 1)$.
Качественно оно означает, что вероятность перехода из состояния $\br{x_1,x_2}$ в состояние $\br{w_1,w_2}$ не зависит от самих состояний $\br{x_1,x_2}$ и $\br{w_1,w_2}$, 
а зависит лишь от попарной разности их координат; в случае, когда $x_1 = 0$ (то есть первая очередь пуста), данное свойство сохраняется, однако функция, 
характеризующая переходную вероятность, будет другой (а именно $p_2\br{\cdot,\cdot}$, а не $p_1\br{\cdot,\cdot}$). Ситуация, когда $x_1 = x_2 = 0$, представляет собой отдельный, третий случай, 
который мы не будем выделять, а переходную вероятность писать как есть: $p \br{0, 0, w_1, w_2}$.

Покажем теперь, что это свойство сохраняется и для случая цензурированных цепей.

\begin{lemma}
Переходные вероятности $\p^a \br{\cdot,\cdot,\cdot,\cdot}$ цензурированных марковских цепей $\Markkhata$ выражаются через переходные вероятности
$p\br{\cdot,\cdot,\cdot,\cdot}$
исходной марковской цепи $\Markk$ 
следующим образом:
\begin{multline}
\p^a \br{x_1, x_2, a, w_2} = p \br{x_1, x_2, a, w_2}  + \\+ 
\sum_{y_1 \geqslant 1} \sum_{y_2 = -1}^{w_2 - x_2} p\br{x_1, x_2, a + y_1, x_2 + y_2}
\sum_{k_1 + k_2 + \ldots + k_{y_1} = w_2 - x_2- y_2} \alpha\br{k_1} \alpha\br{k_2} \ldots \alpha\br{k_{y_1}},
\label{transition_two}
\end{multline}
где $\br{x_1,x_2} \in E^a_{\vk}$, $w_2 \in Z_+$, $a \geq 0$.
\end{lemma}

\remark{Нас интересуют только те вероятности перехода, в которых конечное состояние
находится на границе цензурирующего множества $E_{\vk}^a$, то есть вероятности вида $\p^a \br{x_1, x_2, a, w_2}$, 
$\br{x_1,x_2}$ и $\br{a,w_2}$ $\in E_{\vk}^a$. Поэтому выражения для остальных вероятностей в \eqref{transition_two} не включены.}

\begin{proof}
Введем следующие события (время $j\geqslant 0$ фиксировано):
\begin{equation*}
\begin{array}{lll}
 C\br{x_1,x_2, a +y_1, x_2 + y_2} &=& \brrr{\omega \colon \vk_j = \br{x_1,x_2}, \vk_{j+1} = \br{a+y_1, x_2 + y_2}},\\
 D\br{x_1,x_2, a , w_2} &=&  \brrr{\omega \colon \hat{\vk}_{\hat{j}} = \br{x_1,x_2}, \hat{\vk}_{\hat{j}+1} = \br{a, w_2}},
 \end{array}
\end{equation*}
где $\hat{j}$ таково, что $\theta_{\hat{j}} = j$ (см. \eqref{theta_mark}),
$\br{x_1,x_2}$ и $\br{a,w_2}$ $\in E_{\vk}^a$, $y_1 \geqslant 0$ и $y_2 \geqslant -1$. 
Причем событие $C\br{x_1,x_2, a +y_1, x_2 + y_2}$ при $y_2=-1$ может иметь 
отличную от нуля вероятность только если $x_1 = 0$. Качественно событие $C\br{x_1,x_2, a +y_1, x_2 + y_2}$ заключается в том, что
цепь $\Markk$ из состояния $\br{x_1,x_2}$ за один шаг перейдет в состояние $\br{a +y_1, x_2 + y_2}$, а событие $D\br{x_1,x_2, a , w_2}$ ---
в том, что цепь $\Markkhata$ за один шаг перейдет из состояния $\br{x_1,x_2}$ в состояние $\br{a , w_2}$.

Поскольку введеные события $C\br{\cdot,\cdot}$ несовместны и
удовлетворяют соотношению
\begin{equation*}
 D\br{x_1,x_2, a , w_2} \subseteq C\br{x_1,x_2, a , w_2}
 \bigcup \bigcup_{y_1 \geqslant  1} \bigcup_{y_2 = -1}^{w_2-x_2} C\br{x_1,x_2, a +y_1, x_2 + y_2},
\end{equation*}
то для вычисления вероятности $ P\br{D\br{x_1,x_2, a , w_2}}$ можно воспользоваться формулой полной вероятности:
\begin{multline}
P\br{D\br{x_1,x_2, a , w_2}} =  \p^a \br{x_1, x_2, a, w_2} =\\=
 P\br{C\br{x_1,x_2, a, w_2}}P\br{D\br{x_1,x_2, a , w_2} | C\br{x_1,x_2, a, w_2}} +\\+
 \sum_{y_1 \geqslant 1} \sum_{y_2 = -1}^{w_2-x_2} 
  P\br{C\br{x_1,x_2, a +y_1, x_2 + y_2}}P\br{D\br{x_1,x_2, a , w_2} | C\br{x_1,x_2, a +y_1, x_2 + y_2}}.
  \label{trans:temp}
\end{multline}
Вероятность $P\br{D\br{x_1,x_2, a , w_2} | C\br{x_1,x_2, a, w_2}}$ из первого слагаемого равна $1$, поскольку 
$C\br{x_1,x_2, a, w_2} \subseteq D\br{x_1,x_2, a , w_2}$. Вероятности $P\br{C\br{x_1,x_2, a +y_1, x_2 + y_2}}$ суть 
$p\br{x_1, x_2, a + y_1, x_2 + y_2}$. Тогда \eqref{trans:temp} приобретает вид
\begin{multline}
\p^a \br{x_1, x_2, a, w_2} = p\br{x_1,x_2, a, w_2} +\\+
 \sum_{y_1 = 1}^{\infty} \sum_{y_2 = -1}^{w_2-x_2} 
 p\br{x_1,x_2, a +y_1, x_2 + y_2}P\br{D\br{x_1,x_2, a , w_2} | C\br{x_1,x_2, a +y_1, x_2 + y_2}}.
  \label{trans:temp:1}
\end{multline}
Оставшиеся условные вероятности находятся из рассуждений, аналогичных рассуждениям, проводившихся для вывода формулы 
\eqref{addition_prob_four}. А именно, путь цепи $\Markk$ из состояния $\br{a +y_1, x_2 + y_2}$ в состояние $\br{a , w_2}$ можно
разложить на $y_1$ итераций, после каждой из которых первая координата будет уменьшаться на единицу. В итоге, из 
\eqref{trans:temp:1} получаем окончательное выражение \eqref{transition_two} для $\p^a \br{x_1, x_2, a, w_2}$.
% Выражения для остальных переходных вероятностей выписывать не будем, поскольку они нам не пригодятся, а сохраним для дальнейшего оставшиеся свободные обозначения $\hat{p} \br{x_1, x_2, a, w_2} $ (для других значений $a$).Заметим, что в \eqref{transition_two} неявно объединены два случая: $x_1 = 0$ и $x_1 > 0$: при $x_1 > 0$ суммирование по $y_2$ осуществляется не с $(-1)$, а с $0$ (за счет обнуления соответствующего слагаемого).
\end{proof}

Учитывая \eqref{transition_property:1} и \eqref{transition_two}, можем теперь выписать уже упоминавшееся свойство
переходных вероятностей цензурированной цепи $\Markkhata$ .
\begin{lemma}
 Для цензурированных марковских цепей $\Markkhata$ имеют место следующие соотношения:
 \begin{equation}
\begin{array}{llll}
 %\item $ 0 < x_1 \leqslant w_1, 0 \leqslant x_2 \leqslant w_2$
\displaystyle \p^a \br{x_1, x_2, a, w_2} &=& \p_1 \br{a - x_1, w_2 - x_2},& \quad 
 0 < x_1 \leqslant a, 0 \leqslant x_2 \leqslant w_2\\
%\item $x_1 = 0, 0 < x_2 \leqslant w_2 + 1$
\displaystyle \p^a \br{0, x_2, a, w_2} &=& \p_2 \br{a, w_2 - x_2},& \quad  0 < x_2 \leqslant w_2 + 1
\end{array}
\label{transition_property:2}
\end{equation}
где $\br{x_1,x_2}, \br{a,w_2} \in E_{\vk}^a$ и функция $\p_1 \br{\cdot, \cdot}$ не зависит от параметра цензурирования $a \geqslant 0$.
\end{lemma}

\subsection{Рекуррентные соотношения для стационарных вероятностей}
%\addcontentsline{toc}{subsection}{Рекуррентные соотношения для стационарных вероятностей}
Из формулы полной вероятности легко получить следующие уравнения, связывающие стационарные вероятности цензурированных марковских цепей ($a \geqslant 0$):
\begin{align}
\hat{\pi}^a \br{w_1, w_2} & =\sum_{\br{x_1,x_2}\in E^a_{\vk}} \hat{\pi}^a\br{x_1,x_2} \hat{p}^a\br{x_1,x_2,w_1,w_2},\label{equil_zero}\\
\sum_{\br{x_1,x_2}\in E^a_{\vk}} \hat{\pi}^a\br{x_1,x_2} & =1,
\end{align}
где $\br{w_1,w_2} \in E^a_{\vk}$, $\hat{\pi}^a\br{x_1,x_2}$ --- стационарная вероятность для состояния $\br{x_1,x_2}$ цепи 
$\Markkhata$, а $\hat{p}^a\br{x_1,x_2,w_1,w_2}$ --- ее переходная вероятность из состояния $\br{x_1,x_2}$ в состояние $\br{w_1,w_2}$.

Учитывая специфику механизма обслуживания, некоторые вероятности в \eqref{equil_zero} равны нулю, 
поэтому приведенные уравнения существенно упрощаются. При $a=0$
 уравнение \eqref{equil_zero} преобразуется следующим образом:
 %(первый аргумент $\hat{\pi}^a \br{0, w_2}$ для краткости опустим):
\begin{equation}
\hat{\pi}^0 \br{0,w_2} = \sum_{k = 0}^{w_2 +1} \hat{\pi}^0\br{0,k} \hat{p}^0\br{0,k,0,w_2}, \quad w_2 \geqslant 0,
\label{equil_zero:1}
\end{equation}
При $a\geqslant 1$ из \eqref{equil_zero} для состояний на границе (то есть для $w_1 = a$) получим: 
\begin{equation}
\hat{\pi}^a \br{a, w_2} = \sum_{x_1 = 0}^{a}\sum_{x_2 = 0}^{w_2} \hat{\pi}^a\br{x_1,x_2} \p^a\br{x_1,x_2,a,w_2} +
 \hat{\pi}^a\br{0,w_2 + 1} \p^a\br{0,w_2 + 1,a,w_2},
\label{equil_zero:2}
\end{equation}
где $w_2 \geqslant 0$.

Поскольку стационарные вероятности цензурированной и исходной цепи связаны соотношением (см. \cite[с. 142]{Kemeny})
\begin{equation*}
 \hat{\pi}^a \br{w_1, w_2} = \frac{\pi \br{w_1, w_2}}{\sum_{\br{x_1,x_2} \in E^a_{\vk}}{\pi \br{x_1, x_2}}}, \quad \br{w_1,w_2} \in E^a_{\vk},
\end{equation*}
то, выражая в  \eqref{equil_zero:1} и \eqref{equil_zero:2} $\hat{\pi}^a \br{\cdot, \cdot}$ через $\pi \br{\cdot, \cdot}$, 
получим аналогичные \eqref{equil_zero:1} и \eqref{equil_zero:2} соотношения для стационарных вероятностей исходной цепи:
\begin{align}
\pi \br{0,w_2} &= \sum_{k = 0}^{w_2 +1} \pi\br{0,k} \hat{p}^0\br{0,k,0,w_2}, \label{equil_zero:3}\\
\pi \br{a, w_2} &= \sum_{x_1 = 0}^{a}\sum_{x_2 = 0}^{w_2} \pi\br{x_1,x_2} \p^a\br{x_1,x_2,a,w_2} +
\pi\br{0,w_2 + 1} \p^a\br{0,w_2 + 1,a,w_2}, a > 0
 \label{equil_zero:4}
\end{align}
где $w_2 \geqslant 0$ и $\pi \br{w_1, w_2}$ есть стационарная вероятность исходной марковской цепи $\Markk$ для состояния $\br{w_1,w_2}\in E_{\vk}^a$.

\begin{lemma}
 Стационарные вероятности марковской цепи $\Markk$ удовлетворяют следующим рукуррентным соотношениям:
 \begin{equation}
\pi\br{0,1} = \p_2\br{0,-1}^{-1} \brrr{1 - \p^0\br{0,0,0,0}} \pi\br{0,0} 
\label{rek:1} 
\end{equation}
\begin{multline}
 \pi\br{0,x} = \p_2\br{0,-1}^{-1}  \left\{ \pi\br{0,x-1} \br{1 - \p_2\br{0,0}} - \pi\br{0,0}\p^0\br{0,0,0,x-1} - \right. \\
 \left. \sum_{k=1}^{x-2}\pi\br{0,k}\p_2\br{0,x-k-1}\right\}, \quad x \geqslant 2,
\label{rek:2} 
\end{multline}
\begin{multline}
 \pi\br{a,x} = \br{1-\p_1\br{0,0}}^{-1} \left\{\pi\br{0,0}\p^a\br{0,0,a,x} + \sum_{k=1}^{x+1}\pi\br{0,k}\p_2\br{a,x-k} +\right.\\ 
  + \left. \sum_{l=1}^{a-1}\sum_{m=0}^{x}\pi\br{l,m}\p_1\br{a-l,x-m} +  \sum_{n=0}^{x-1}\pi\br{a,n}\p_1\br{0,x-n}\right\}, \quad a >0,
  x \geqslant 0,
\label{rek:3}
 \end{multline}
 где $\p_1\br{\cdot,\cdot}$ и $\p_2\br{\cdot,\cdot}$ определены в \eqref{transition_property:2}, а $\p^a\br{\tilde{x}_1,\tilde{x}_2,x_1,x_2}$ 
 --- переходная вероятность цензурированной цепи $\Markkhata$ из состояния $\br{\tilde{x}_1,\tilde{x}_2}$ в состояние $\br{x_1,x_2}$.
\end{lemma}
\begin{proof}
Раскроем сумму в \eqref{equil_zero:3} и, учитывая \eqref{transition_property:2}, получим: для нулевого состояния
\begin{equation*}
 \pi\br{0,0} = \pi(0,0) \p^0\br{0,0,0,0} + \pi(0,1) \p^0\br{0,1,0,0} = \pi(0,0) \p^0\br{0,0,0,0} + \pi(0,1) \hat{p}_2\br{0,-1},
\end{equation*}
откуда, выражая $ \pi\br{0,1}$ и заменяя $x$ на $x-1$, имеем \eqref{rek:1}; аналогично при $x>0$
\begin{multline*}
 \pi\br{0,x} = \sum_{k=0}^{x+1} \pi\br{0,k}\p^0\br{0,k,0,x} =\pi\br{0,0}\p^0\br{0,0,0,x} + \sum_{k=1}^{x-1}\pi\br{0,k}\p^0\br{0,k,0,x}+\\
 +\pi\br{0,x}\p^0\br{0,x,0,x} + \pi\br{0,x+1}\p^0\br{0,x+1,0,x} =\pi\br{0,0}\p^0\br{0,0,0,x} +\\
 +\sum_{k=1}^{x-1}\pi\br{0,k}\p_2\br{0,x-k} + \pi\br{0,x}\p_2\br{0,0} + \pi\br{0,x+1}\p_2\br{0,-1},
\end{multline*}
откуда, выражая $\pi\br{0,x+1}$, получим \eqref{rek:2}.

Далее, раскрывая сумму в \eqref{equil_zero:4} и учитывая \eqref{transition_property:2}, для $a \geqslant 1$ и $x \geqslant 0$ получим
\begin{multline*}
 \pi\br{a,x} = \pi\br{0, 0} \p^a\br{0,0,a,x} + \sum_{k=1}^{x+1} \pi\br{0, k} \p^a\br{0,k,a,x} + 
 \sum_{l=1}^{a-1} \sum_{m=0}^{x}\pi\br{l,m} \p^a\br{l,m,a,x} +\\
+ \sum_{n=0}^{x-1}\pi\br{a,n}\p^a\br{a,n,a,x} +  \pi\br{a,x}\p^a\br{a,x,a,x} =
\pi\br{0, 0} \p^a\br{0,0,a,x} + \\+
\sum_{k=1}^{x+1} \pi\br{0, k} \p_2\br{a, x-k} + 
 \sum_{l=1}^{a-1} \sum_{m=0}^{x}\pi\br{l,m} \p_1\br{a-l,x-m} +\\
+ \sum_{n=0}^{x-1}\pi\br{a,n}\p_1\br{0,x-n} +  \pi\br{a,x}\p_1\br{0,0},
\end{multline*}
откуда, выражая $\pi\br{a,x}$, получим \eqref{rek:3}.
\end{proof}
Стоит отметить, что в полученных рекуррентных соотношениях до сих пор остается неизвестным значение вероятности $\pi\br{0,0}$, что мешает их
применить. Найдем эту вероятность.

\subsection{Выражение для стационарной вероятности $\pi\br{0,0}$ марковской цепи $\Markk$}
%\addcontentsline{toc}{subsection}{Выражение для $\pi\br{0,0}$}
\subsubsection{Условие нормировки}
%\addcontentsline{toc}{subsubsection}{Условие нормировки}

Условие нормировки для исходной марковской цепи $\Markk$ имеет следующий вид:
\begin{equation*}
 \sum_{x\geqslant0} \sum_{a\geqslant 0} \pi\br{a,x} = 1
\end{equation*}
Разделим приведенную сумму на несколько частей так, чтобы для ее вычисления можно было применить \eqref{rek:1}, \eqref{rek:2} и \eqref{rek:3}:
\begin{equation}
 \sum_{x\geqslant0} \sum_{a\geqslant 0} \pi\br{a,x} =  \pi\br{0, 0} + \pi\br{0,1} +
 \sum_{x \geqslant 2} \pi\br{0,x} + \sum_{a \geqslant 1} \sum_{x\geqslant 0} \pi\br{a,x} = 1
 \label{norm_constr}
\end{equation}

\begin{lemma}
 Имеет место следующее соотношение для $\pi\br{0,0}$:
\begin{multline}
  \pi\br{0,0}\brrr{1 + \sum_{a\geqslant 1}\sum_{x\geqslant 0}\p^a\br{0,0,a,x} - \sum_{a\geqslant 0}\sum_{x\geqslant 0} \p_1\br{a,x}} + \\ +
\sum_{k \geqslant 1} \pi\br{0,k} \brrr{1 + \sum_{a\geqslant 1}\sum_{x\geqslant -1}\p_2\br{a,x}  - \sum_{a\geqslant 0}\sum_{x\geqslant 0}\p_1\br{a,x} }
= \\= 1 -\sum_{a\geqslant 0}\sum_{x\geqslant 0}\p_1\br{a,x}
\label{final_eq}
\end{multline}
\end{lemma}
\begin{proof}
Найдем последовательно выражения для сумм из \eqref{norm_constr}.

Для суммы $\sum_{x \geqslant 2} \pi\br{0,x}$, учитывая \eqref{rek:2}, получим:
\begin{multline}
 \sum_{x \geqslant 2} \pi\br{0,x} = \p_2\br{0,-1}^{-1} \left\{\sum_{x \geqslant 2} \pi\br{0,x -1} \br{1 - \p_2\br{0,0}} -
\sum_{x \geqslant 2} \pi\br{0,0}\p^0\br{0,0,0,x-1} \right.-\\- \left.\sum_{x \geqslant 2}  \sum_{k=1}^{x-2}\pi\br{0,k}\p_2\br{0,x-k - 1}
\right\}
\label{first_sum}
\end{multline}
Полученные суммы также рассмотрим отдельно.

Первая сумма из \eqref{first_sum} преобразуется следующим образом:
\begin{equation}
 \sum_{x \geqslant 2} \pi\br{0,x -1} \br{1 - \p_2\br{0,0}} =  \br{1 - \p_2\br{0,0}} \sum_{x \geqslant 1} \pi\br{0,x}
 \label{temp:1:1}
\end{equation}

Вторая сумма:
\begin{equation}
 \sum_{x \geqslant 2} \pi\br{0,0}\p^0\br{0,0,0,x-1} =  \pi \br{0,0}\sum_{x \geqslant 1}\p^0\br{0,0,0,x} 
 \label{temp:1:2}
\end{equation}

Третья сумма:
\begin{multline}
  \sum_{x \geqslant 2} \sum_{k=1}^{x-2}\pi\br{0,k}\p_2\br{0,x-k - 1} = 
  \sum_{x \geqslant 3} \sum_{k=1}^{x-2}\pi\br{0,k}\p_2\br{0,x-k - 1} =\\ =
  \sum_{k \geqslant 1} \pi\br{0,k} \sum_{x \geqslant k+2} \p_2\br{0,x-k - 1} 
 = \sum_{k \geqslant 1} \pi\br{0,k} \sum_{x \geqslant 1} \p_2\br{0,x}  
 \label{temp:1:3}
\end{multline}	

Для суммы $\sum_{a \geqslant 1} \sum_{x\geqslant 0} \pi\br{a,x}$, учитывая \eqref{rek:3}, получим:
\begin{multline}
\sum_{a \geqslant 1} \sum_{x\geqslant 0} \pi\br{a,x} =\br{1-\p_1\br{0,0}}^{-1} \left\{ \sum_{a \geqslant 1} \sum_{x\geqslant 0} \pi\br{0,0}\p^a\br{0,0,a,x} + 
\sum_{a \geqslant 1} \sum_{x\geqslant 0} \sum_{k=1}^{x+1}\pi\br{0,k}\p_2\br{a,x-k} + \right.\\ \left.+
\sum_{a \geqslant 1} \sum_{x\geqslant 0} \sum_{l=1}^{a-1}\sum_{m=0}^{x}\pi\br{l,m}\p_1\br{a-l,x-m} + 
\sum_{a \geqslant 1} \sum_{x\geqslant 0} \sum_{n=0}^{x-1}\pi\br{a,n}\p_1\br{0,x-n} \right\}.
\label{first_sum_two}
\end{multline}
Рассмотрим эти четыре суммы отдельно.

Из первой суммы в \eqref{first_sum_two} лишь вынесем множитель, не зависящий от индекса суммирования:
\begin{equation}
\sum_{a \geqslant 1}  \sum_{x\geqslant 0} \pi\br{0,0}\p^a\br{0,0,a,x} = \pi\br{0,0} \sum_{a \geqslant 1}  \sum_{x\geqslant 0} \p^a\br{0,0,a,x}.
\label{temp:2:1}
\end{equation}

Вторая сумма преобразуется следующим образом:
\begin{multline}
 \sum_{a \geqslant 1} \sum_{x \geqslant 0} \sum_{k=1}^{x+1}\pi\br{0,k}\p_2\br{a,x-k} =  
\sum_{k\geqslant 1} \pi\br{0,k} \sum_{x\geqslant k-1}\sum_{a \geqslant 1} \p_2\br{a,x-k} =
\sum_{k\geqslant 1} \pi\br{0,k} \sum_{x\geqslant -1}\sum_{a \geqslant 1} \p_2\br{a,x}
\label{temp:2:2}
\end{multline}

Третья сумма :
\begin{multline}
 \sum_{a \geqslant 1} \sum_{x\geqslant 0} \sum_{l=1}^{a-1}\sum_{m=0}^{x}\pi\br{l,m}\p_1\br{a-l,x-m} =
 \sum_{a \geqslant 2} \sum_{x\geqslant 0} \sum_{l=1}^{a-1}\sum_{m=0}^{x}\pi\br{l,m}\p_1\br{a-l,x-m} = \\ =
 \sum_{l\geqslant 1}\sum_{m\geqslant 0}\pi\br{l,m} \sum_{a \geqslant l+ 1} \sum_{x\geqslant m} \p_1\br{a-l,x-m} =
\sum_{l\geqslant 1}\sum_{m\geqslant 0}\pi\br{l,m} \sum_{a \geqslant 1} \sum_{x\geqslant 0} \p_1\br{a,x} = \\
\br{1 - \sum_{m\geqslant 0}\pi\br{0,m}} \sum_{a \geqslant 1} \sum_{x\geqslant 0} \p_1\br{a,x} 
\label{temp:2:3}
\end{multline}

И, наконец, последняя, четвертая сумма:
\begin{multline}
 \sum_{a \geqslant 1} \sum_{x\geqslant 0} \sum_{n=0}^{x-1}\pi\br{a,n}\p_1\br{0,x-n} =
 \sum_{a \geqslant 1} \sum_{x\geqslant 1} \sum_{n=0}^{x-1}\pi\br{a,n}\p_1\br{0,x-n} = \\=
\sum_{a \geqslant 1}  \sum_{n\geqslant 0} \pi\br{a,n} \sum_{x\geqslant n+1} \p_1\br{0,x-n} =
\br{1 - \sum_{n\geqslant 0}\pi\br{0,n}}\sum_{x\geqslant 1} \p_1\br{0,x} 
\label{temp:2:4}
\end{multline}

Теперь подставим выражения \eqref{temp:1:1}-\eqref{temp:1:3} в равенство \eqref{first_sum}:
\begin{multline}
  \sum_{x \geqslant 2} \pi\br{0,x} = \p_2\br{0,-1}^{-1} \left\{\br{1 - \p_2\br{0,0}} \sum_{x \geqslant 1} \pi\br{0,x} -
\pi \br{0,0}\sum_{x \geqslant 1}\p^0\br{0,0,0,x}  \right.-\\- \left. \sum_{k \geqslant 1} \pi\br{0,k} \sum_{x \geqslant 1} \p_2\br{0,x}  
\right\},
\label{temp:3:1}
\end{multline}
а выражения \eqref{temp:2:1} - \eqref{temp:2:4} в равенство \eqref{first_sum_two}:
\begin{multline}
 \sum_{a \geqslant 1} \sum_{x\geqslant 0} \pi\br{a,x} =\br{1-\p_1\br{0,0}}^{-1} \left\{
 \pi\br{0,0} \sum_{a \geqslant 1}  \sum_{x\geqslant 0} \p^a\br{0,0,a,x} + 
\sum_{k\geqslant 1} \pi\br{0,k} \sum_{x\geqslant -1}\sum_{a \geqslant 1} \p_2\br{a,x} + \right.\\ \left.+
\br{1 - \sum_{m\geqslant 0}\pi\br{0,m}} \sum_{a \geqslant 1} \sum_{x\geqslant 0} \p_1\br{a,x} + 
\br{1 - \sum_{n\geqslant 0}\pi\br{0,n}}\sum_{x\geqslant 1} \p_1\br{0,x} \right\}.
\label{temp:3:2}
\end{multline}

Подставив полученные выражения \eqref{temp:3:1} и \eqref{temp:3:2}, а также выражение \eqref{rek:1} в \eqref{norm_constr}
и сгруппировав слагаемые при $\pi\br{0,0}$ и $\sum_{k \geqslant 1} \pi\br{0,k}$, получим:
\begin{multline*}
 \pi\br{0,0}\left\{1 + \frac{1- \p^0\br{0,0,0,0}}{\p_2\br{0,-1}} - 
 \frac{1- \p^0\br{0,0,0,0}}{\p_2\br{0,-1}} + \frac{\sum_{a\geqslant 1}\sum_{x\geqslant 0}\p^a\br{0,0,a,x}}{1 - \p_1\br{0,0}} 
 -\right. \\ \left. -\frac{\sum_{a\geqslant 1}\sum_{x\geqslant 0} \p_1\br{a,x}}{1 - \p_1\br{0,0}}  - \frac{\sum_{x \geqslant 1} \p_1\br{0,x}}{1 - \p_1\br{0,0}}
\right\} + \\ +
\sum_{k \geqslant 1} \pi\br{0,k}\left\{\frac{1-\p_2\br{0,0}}{\p_2\br{0,-1}} - \frac{1}{\p_2\br{0,-1}} \sum_{x\geqslant 1}\p_2 \br{0,x} +
\frac{\sum_{x\geqslant -1}\sum_{a\geqslant 1}\p_2\br{a,x}}{1 - \p_1\br{0,0}} - \right. \\ -\left.  \frac{\sum_{a\geqslant 1}\sum_{x\geqslant 0}\p_1\br{a,x}}{1 - \p_1\br{0,0}} -
\frac{\sum_{x\geqslant 1}\p_1\br{0,x}}{1 - \p_1\br{0,0}} \right\} = 1  - \frac{\sum_{a\geqslant 1}\sum_{x\geqslant 0}\p_1\br{a,x}}{1 - \p_1\br{0,0}} -
\frac{\sum_{x\geqslant 1}\p_1\br{0,x}}{1 - \p_1\br{0,0}} 
\end{multline*}
Также здесь мы учли, что $\sum_{x \geqslant 1} \p^0\br{0,0,0,x} = 1 - \p^0\br{0,0,0,0}$.

Далее заметим, что $\p^a\br{0,0,0,0} = \p_2\br{0,-1}$ и $\sum_{x\geqslant 1}\p_2 \br{0,x} = 1 - \p_2 \br{0,-1} - \p_2 \br{0,0}$. 
Тогда, приведя подобные слагаемые, получим:
\begin{multline*}
  \pi\br{0,0}\brrr{ \frac{1 - \p_1\br{0,0} + \sum_{a\geqslant 1}\sum_{x\geqslant 0}\p^a\br{0,0,a,x} -
  \sum_{a\geqslant 0}\sum_{x\geqslant 0} \p_1\br{a,x} + \p_1\br{0,0}}{1 - \p_1\br{0,0}} }  + \\ +
\sum_{k \geqslant 1} \pi\br{0,k}\frac{1 - \p_1\br{0,0} + \sum_{a\geqslant 1}\sum_{x\geqslant -1}\p_2\br{a,x}  - \sum_{a\geqslant 0}\sum_{x\geqslant 0}\p_1\br{a,x} + \p_1\br{0,0}}{1 - \p_1\br{0,0}} 
= \\= \frac{1 - \p_1\br{0,0}  - \sum_{a\geqslant 0}\sum_{x\geqslant 0}\p_1\br{a,x} + \p_1\br{0,0}}{1 - \p_1\br{0,0}} 
\end{multline*}
откуда с очевидностью следует \eqref{final_eq}.
\end{proof}

Из \eqref{final_eq} видно, что кроме вероятности $\pi\br{0,0}$ остается еще одно неизвестное выражение:
$\sum_{m\geqslant 1}\pi\br{0,m}$. Найдем еще одно независимое уравнение, которое связывает величины
 $\pi\br{0,0}$ и $\sum_{m\geqslant 1}\pi\br{0,m}$.

\subsubsection{Вложенные цензурированные марковские цепи}
%\addcontentsline{toc}{subsubsection}{Вложенные цензурированные марковские цепи}
Рассмотрим цензурированную марковскую цепь $\Markkhato$ и проведем с ней (вложенную) процедуру цензурирования, аналогичную той, 
которую делали до этого, однако, теперь будем ограничивать вторую координату. 

Ценурированное множество обозначим $E^{a}_{\hat{\vk}\br{0}}=\brrr{\br{0,y} \colon 0 \leqslant y \leqslant a}, a\geqslant 1$, причем двумерные состояния будем отождествлять 
с их второй координатой, поскольку первая координата всегда равна нулю. Рассмотрим
последовательные моменты попадания марковской цепи $\Markkhato$ во множество $E^{a}_{\hat{\vk}\br{0}}$. Определим эти моменты следующим образом:
\begin{equation}
\begin{array}{lll}
\hat{\theta}_1 (a) &=& \min \brrr{k \geqslant 1 \colon \hat{\vk}_k\br{0} \in E^{a}_{\hat{\vk}\br{0}}},\\
\hat{\theta}_{i+1} (a) &=& \min \brrr{k > \hat{\theta}_i (a) \colon \hat{\vk}_k\br{0} \in E^{a}_{\hat{\vk}\br{0}}}, \quad i = 1, 2, \ldots.
\end{array}
\label{theta_mark:2}
\end{equation}
В результате цензурирования получим новую последовательность случайных величин:
\begin{equation}
 \hat{\hat{\vk}}_i (a)= \hat{\vk}_{\hat{\theta}_i (a)}, \quad i \geqslant 1.
 \label{markkhat:2}
\end{equation}

\lemma{Последовательность $\Markkhatoa$, определяемая соотношениями \eqref{theta_mark:2} и \eqref{markkhat:2}, является марковской цепью.}
\begin{proof}
 Рассуждения полностью повторяют рассуждения доказательства леммы \eqref{lemma:markovost}
\end{proof}

Обозначим через $\hat{\p}^a\br{x,y}$ вероятность перехода цепи $\Markkhatoa$ из состояния $0 \leqslant x \leqslant a$
в состояние $0 \leqslant y \leqslant a$, а через
$\hat{\hat{\pi}}\br{x}$ --- стационарную вероятность этой цепи для состояния $0 \leqslant x \leqslant a$.

\begin{lemma}
Величины $\pi\br{0,0}$ и $\sum_{k \geqslant 1} \pi\br{0,k}$ связаны следующим соотношением:
 \begin{equation}
\sum_{k \geqslant 1} \pi\br{0,k} = \pi\br{0,0} \br{\frac{1}{\hat{\pi}^0\br{0,0}} - 1},
\label{sum_p:0}
\end{equation}
где 
\begin{equation}
 \hat{\pi}^0\br{0,0}= 1- \sum_{a \geqslant 0}\sum_{y_2 \geqslant 0} \p_2\br{0,a+y_2}
 \label{sum_p:1}
\end{equation}


\end{lemma}
\begin{proof}


Из соотношения 
\begin{equation*}
 \hat{\pi}^0 \br{0, 0} = \frac{\pi \br{0, 0}}{\sum_{\br{x_1,x_2} \in E^0_{\vk}}{\pi \br{x_1, x_2}}}
\end{equation*}
(см. \cite[с. 142]{Kemeny}) находим
\begin{equation*}
  \hat{\pi}^0 \br{0, 0} = \frac{\pi \br{0, 0}}{\sum_{k\geqslant 0}{\pi \br{0, k}}} =
  \frac{\pi \br{0, 0}}{\pi \br{0, 0} + \sum_{k\geqslant 1}{\pi \br{0, k}}}
\end{equation*}
и, выражая $\sum_{k\geqslant 1}{\pi \br{0, k}}$, получим \eqref{sum_p:0}.

Найдем теперь вероятность перехода цепи $\Markkhatoa$ из состояния $x$ в граничное состояние $a$, учитывая \eqref{transition_property:2}:
\begin{multline}
 \hat{\p}^a\br{x,a} = \p^0\br{0,x,0,a} + \sum_{y_2 \geqslant 1}\p^0\br{0,x,0,a+y_2} = \sum_{y_2 \geqslant 0} \p^0\br{0,x,0,a+y_2} = \\=
\left\{ 
\begin{align}
  \sum_{y_2 \geqslant 0} \p_2\br{0,a+y_2 - x}, \quad x > 0,\\
 \sum_{y_2 \geqslant 0} \p^0\br{0,0,0,a+y_2} , \quad x = 0,
\end{align}
\right.=
\left\{ 
\begin{align}
  \sum_{y_2 \geqslant 0} \p_2\br{0,a+y_2 - x}, \quad x > 0,\\
 \sum_{y_2 \geqslant 0} \p^0\br{0,1,0,a+y_2} , \quad x = 0,
\end{align}
\right.
=\\=
\left\{ 
\begin{align}
  \sum_{y_2 \geqslant 0} \p_2\br{0,a+y_2 - x}, \quad x > 0,\\
 \sum_{y_2 \geqslant 0} \p_2\br{0,a+y_2 - 1} , \quad x = 0,
\end{align}
\right.
=
\left\{ 
\begin{align}
 \hat{\p}\br{a-x}, \quad x > 0,\\
 \hat{\p}\br{a-1} , \quad x = 0,
\end{align}
\right.
\label{nested_rek}
\end{multline}
где для удобства введено новое обозначение 
\begin{equation}
\hat{\p}\br{y} = \sum_{y_2 \geqslant 0} \p_2\br{0,y+y_2}.
\label{hathatp}
\end{equation}

Уравнения для стационарных вероятностей $\hat{\hat{\pi}}^a\br{a}$ марковских цепей $\Markkhatoa$ имеют следующий вид:
\begin{equation*}
 \hat{\hat{\pi}}^a\br{a} = \sum_{x=0}^a \hat{\hat{\pi}}^a \br{x} \hat{\p}^a\br{x,a}, \quad a \geqslant 1,
\end{equation*}
откуда, подставляя $\eqref{nested_rek}$ и выражая $\hat{\hat{\pi}}^a\br{a}$, находим
\begin{equation}
 \hat{\hat{\pi}}^a\br{a} = \br{1 - \hat{\p}\br{0}}^{-1}\brrr{\hat{\hat{\pi}}^a\br{0}\hat{\p}\br{a-1} +
 \sum_{x=1}^{a-1}\hat{\hat{\pi}}^a\br{x}\hat{\p}\br{a-x}}, \quad a \geqslant 1.
 \label{temp:4}
\end{equation}

Поскольку стационарные вероятности марковских цепей $\Markkhatoa$, $a \geqslant 1$, связаны со стационарными 
вероятнотями марковской цепи $\Markkhato$ соотношениями (см. \cite[с. 142]{Kemeny})
\begin{equation*}
 \hat{\hat{\pi}}^a \br{a} = \frac{\hat{\pi}^0 \br{0,a}}{\sum_{x=0}^{a}\hat{\pi}^0 \br{0, x}},
\end{equation*}
то \eqref{temp:4} можно переписать в терминах стационарных вероятностей цепи $\Markkhato$:
\begin{equation}
\hat{\pi}^0 \br{0,a} = \br{1 - \hat{\p}\br{0}}^{-1}\brrr{\hat{\pi}^0 \br{0,0}\hat{\p}\br{a-1} +
 \sum_{x=1}^{a-1}\hat{\pi}^0 \br{0,x}\hat{\p}\br{a-x}}, \quad a \geqslant 1.
 \label{temp:5}
\end{equation}

Условие нормировки для цепи $\Markkhato$ тогда примет вид
\begin{multline*}
 1= \sum_{a \geqslant 0}  \hat{\pi}^0 \br{0,a}  = \hat{\pi}^0 \br{0,0} + \sum_{a \geqslant 1}\hat{\pi}^0 \br{0,a}  =  
\hat{\pi}^0 \br{0,0} + \br{1-\hat{\p}\br{0}}^{-1}\left\{\hat{\pi}^0 \br{0,0}\sum_{a \geqslant 1} \hat{\p}\br{a-1} + \right. \\ + \left.
\sum_{a \geqslant 1} \sum_{x=1}^{a-1}\hat{\pi}^0 \br{0,x}\hat{\p}\br{a-x}\right\}=
 \hat{\pi}^0 \br{0,0} + \br{1-\hat{\p}\br{0}}^{-1}\left\{ \hat{\pi}^0 \br{0,0}\sum_{a \geqslant 1} \hat{\p}\br{a-1} \right. +\\
 + \left. \sum_{a \geqslant 2} \sum_{x=1}^{a-1}\hat{\pi}^0 \br{0,x}\hat{\p}\br{a-x}\right\}=
\hat{\pi}^0 \br{0,0} +\br{1-\hat{\p}\br{0}}^{-1}\times \\ \times \brrr{ \hat{\pi}^0 \br{0,0}\sum_{a \geqslant 1}\hat{\p}\br{a-1} + 
\sum_{x \geqslant 1}\hat{\pi}^0 \br{0,x}\sum_{a \geqslant x+1} \hat{\p}\br{a-x}}=\\=
\hat{\pi}^0 \br{0,0}+ \br{1-\hat{\p}\br{0}}^{-1}\brrr{\hat{\pi}^0 \br{0,0}\sum_{a \geqslant 1} \hat{\p}\br{a-1}+ 
(1 -\hat{\pi}^0 \br{0,0}) \sum_{a \geqslant 1} \hat{\p}\br{a}}
\end{multline*}
откуда находим выражение для стационарной вероятности $\hat{\pi}^0\br{0,0}$:
\begin{multline*}
 \hat{\pi}^0\br{0,0} = \br{1 -\br{1-\hat{\p}\br{0}}^{-1}\sum_{a \geqslant 1} \hat{\p}\br{a}} \times \left\{1 +  \br{1-\hat{\p}\br{0}}^{-1}
\sum_{a \geqslant 1}\hat{\p}\br{a-1} -\right. \\- \left. \br{1-\hat{\p}\br{0}}^{-1} \sum_{a \geqslant 1} \hat{\p}\br{a}\right\}^{-1} = 
 \br{1-\hat{\p}\br{0} -\sum_{a \geqslant 1} \hat{\p}\br{a}} \times \brrr{1-\hat{\p}\br{0} +  \sum_{a \geqslant 1} \hat{\p}\br{a-1} - 
 \sum_{a \geqslant 1} \hat{\p}\br{a}}^{-1} =\\=  
\br{1-\sum_{a \geqslant 0} \hat{\p}\br{a}} \times \brrr{1 +  \sum_{a \geqslant 0} \hat{\p}\br{a}- 
 \sum_{a \geqslant 0} \hat{\p}\br{a}} = 
1-\sum_{a \geqslant 0} \hat{\p}\br{a}.
\end{multline*}
Таким образом, \eqref{sum_p:1} доказано.
\end{proof}
\subsubsection{Окончательное выражение для $\pi\br{0,0}$}
%\addcontentsline{toc}{subsubsection}{Окончательное выражение для $\pi\br{0,0}$}

\begin{lemma}
 Суммы $\sum_{a\geqslant 0}\sum_{x\geqslant 0} \p_1\br{a,x}$, $ \sum_{a\geqslant 1}\sum_{x\geqslant -1}\p_2\br{a,x}$ и 
 $\sum_{a\geqslant 1}\sum_{x\geqslant 0}\p^a\br{0,0,a,x}$ в уравнении \eqref{final_eq} вычисляются следующим образом:
 \begin{equation}
 \begin{align*}
 \sum_{a\geqslant 0}\sum_{x\geqslant 0} \p_1\br{a,x} &=  \la_1 f_1'\br{1} \beta_1,\\
\sum_{a\geqslant 1}\sum_{x\geqslant -1}\p_2\br{a,x}  &= \la_1 f_1'\br{1} \beta_2, \\
 \sum_{a\geqslant 1}\sum_{x\geqslant 0}\p^a\br{0,0,a,x} &= \frac{\la_1^2}{\la_1+\la_2} f_1'\br{1} \beta_1 + \frac{\la_2 \la_1}{\la_1+ \la_2}
 f_1'\br{1} \beta_2
\end{align*}
\label{help_sum}
\end{equation}
\end{lemma}

\begin{proof}
Вычислим имеющиеся суммы, учитывая \eqref{transition_two}, \eqref{transition_property:2} и
выражения для переходных вероятностей исходной марковской цепи из \eqref{rekk_new_two} (также см. \eqref{eta2_func}):
\begin{multline*}
\sum_{a\geqslant 0}\sum_{x\geqslant 0} \p_1\br{a,x} =\sum_{a\geqslant 0}\sum_{x\geqslant 0} p_1\br{a,x}  +\\+ \sum_{a\geqslant 0}\sum_{x\geqslant 0} \sum_{y_1 \geqslant 1} \sum_{y_2 = 0}^{x} p_1\br{a + y_1, y_2}
\sum_{k_1 + k_2 + \ldots + k_{y_1} = x - y_2} \alpha\br{k_1} \alpha\br{k_2} \ldots \alpha\br{k_{y_1}} = \\=
1 - \sum_{x\geqslant 0} p_1\br{-1,x}  + \sum_{a\geqslant 0}\sum_{y_1 \geqslant 1} \sum_{y_2 \geqslant 0} p_1\br{a+y_1,y_2}\sum_{x \geqslant 0} \sum_{k_1 + k_2 + \ldots + k_{y_1} = x} \alpha\br{k_1} \alpha\br{k_2} \ldots \alpha\br{k_{y_1}} =
\end{multline*}
и поскольку $\sum_{x \geqslant 0} \sum_{k_1 + k_2 + \ldots + k_{y_1} = x} \alpha\br{k_1} \alpha\br{k_2} \ldots \alpha\br{k_{y_1}} = 1$, то 
\begin{multline*}
= 1 - \sum_{x\geqslant 0} p_1\br{-1,x}  + \sum_{a\geqslant 0}\sum_{y_1 \geqslant 1} \sum_{y_2 \geqslant 0} p_1\br{a+y_1,y_2} =  1 - \sum_{x\geqslant 0} \int_{0}^{\infty} \alpha_{1,0} (t) \alpha_{2,x} (t)  dB_1(t)  +\\
+ \sum_{a\geqslant 0}\sum_{y_1 \geqslant 1} \sum_{y_2 \geqslant 0}  \int_{0}^{\infty} \alpha_{1,a + y_1 + 1} (t) \alpha_{2,y_2} (t)  dB_1(t) = 1 - \int_{0}^{\infty} \alpha_{1,0} (t) \sum_{x\geqslant 0}  \alpha_{2,x} (t)  dB_1(t) +\\
+ \sum_{a\geqslant 0}\sum_{y_1 \geqslant 1}  \int_{0}^{\infty} \alpha_{1,a + y_1 + 1} (t) \sum_{y_2 \geqslant 0} \alpha_{2,y_2} (t)  dB_1(t) = 
1 - \int_{0}^{\infty} \alpha_{1,0} (t) dB_1(t)  +  \sum_{a\geqslant 0}\sum_{y_1 \geqslant 1}  \int_{0}^{\infty} \alpha_{1,a + y_1 + 1} (t) dB_1(t)  = \\=
1 - \int_{0}^{\infty} \alpha_{1,0} (t) dB_1(t)  +  \sum_{a\geqslant 0}\sum_{y_1 \geqslant 0}  \int_{0}^{\infty} \alpha_{1,a + y_1 + 1} (t) dB_1(t)  - 
\sum_{a\geqslant 0} \int_{0}^{\infty} \alpha_{1,a + 1} (t) dB_1(t) = \\ =
1 - \int_{0}^{\infty} \alpha_{1,0} (t) dB_1(t)  + \la_1 f_1'\br{1}  \int_{0}^{\infty} t dB_1(t)  - \int_0^{\infty} 1 - \alpha_{1,0}\br{t}d B_1\br{t} = \la_1 f_1'\br{1} \beta_1
\end{multline*}

Аналогично вычислим сумму, содержащую $\p_2$:
\begin{multline*}
 \sum_{a\geqslant 1}\sum_{x\geqslant -1}\p_2\br{a,x} = \sum_{a\geqslant 1}\sum_{x\geqslant -1} p_2\br{a,x}  +\\+ \sum_{a\geqslant 1}\sum_{x\geqslant -1} \sum_{y_1 = 1}^{\infty} \sum_{y_2 = -1}^{x} p_2\br{a + y_1, y_2}
\sum_{k_1 + k_2 + \ldots + k_{y_1} = x - y_2} \alpha\br{k_1} \alpha\br{k_2} \ldots \alpha\br{k_{y_1}} = \\=
\sum_{a\geqslant 1}\sum_{x\geqslant -1} p_2\br{a,x}  + \sum_{a\geqslant 1}\sum_{x\geqslant -1} \sum_{y_1 = 1}^{\infty} \sum_{y_2 = -1}^{x} p_2\br{a + y_1, y_2}
\sum_{k_1 + k_2 + \ldots + k_{y_1} = x - y_2} \alpha\br{k_1} \alpha\br{k_2} \ldots \alpha\br{k_{y_1}} = \\=
1 - \sum_{x\geqslant -1} p_2\br{0,x} + \sum_{a\geqslant 1}\sum_{y_1 \geqslant 1} \sum_{y_2 \geqslant -1} p_2\br{a+y_1,y_2}\sum_{x \geqslant 0} \sum_{k_1 + k_2 + \ldots + k_{y_1} = x} \alpha\br{k_1} \alpha\br{k_2} \ldots \alpha\br{k_{y_1}} = \\
= 1 - \sum_{x\geqslant -1} p_2\br{0,x + 1} + \sum_{a\geqslant 1}\sum_{y_1 \geqslant 1} \sum_{y_2 \geqslant -1} p_2\br{a+y_1,y_2} = 1 - \sum_{x\geqslant -1}  \int_{0}^{\infty} \alpha_{1,0} (t) \alpha_{2,x + 1} (t)  dB_1(t)  +\\
+ \sum_{a\geqslant 1}\sum_{y_1 \geqslant 1} \sum_{y_2 \geqslant -1} \int_{0}^{\infty} \alpha_{1,a + y_1} (t) \alpha_{2,y_2 + 1} (t)  dB_1(t) = 1 -  \int_{0}^{\infty} \alpha_{1,0} (t) \sum_{x\geqslant -1}  \alpha_{2,x+1} (t)  dB_1(t)  +\\
+ \sum_{a\geqslant 1}\sum_{y_1 \geqslant 1}  \int_{0}^{\infty} \alpha_{1,a + y_1} (t) \sum_{y_2 \geqslant -1} \alpha_{2,y_2 + 1} (t)  dB_1(t) = 1 -  \int_{0}^{\infty} \alpha_{1,0} (t) dB_1(t) 
+ \sum_{a\geqslant 1}\sum_{y_1 \geqslant 1}  \int_{0}^{\infty} \alpha_{1,a + y_1} (t)  dB_1(t) = 
\end{multline*}
\begin{multline*}
= 1 -  \int_{0}^{\infty} \alpha_{1,0} (t) dB_1(t) + \sum_{a\geqslant 0}\sum_{y_1 \geqslant 1}  \int_{0}^{\infty} \alpha_{1,a + y_1} (t)  dB_1(t)  - \sum_{y_1 \geqslant 1}  \int_{0}^{\infty} \alpha_{1, y_1} (t)  dB_1(t) = \\
= \sum_{a\geqslant 0}\sum_{y_1 \geqslant 1}  \int_{0}^{\infty} \alpha_{1,a + y_1} (t)  dB_1(t) = \la_1 f_1'\br{1} \beta_2
\end{multline*}

Учитывая вычисленные суммы, также можем получить выражение и для оставшейся третьей суммы:
\begin{multline*}
 \sum_{a\geqslant 1}\sum_{x\geqslant 0}\p^a\br{0,0,a,x} = p_1  \sum_{a\geqslant 1}\sum_{x\geqslant 0}\p^a\br{1,0,a,x} + 
p_2  \sum_{a\geqslant 1}\sum_{x\geqslant 0}\p^a\br{0,1,a,x} =  \\= p_1  \sum_{a\geqslant 1}\sum_{x\geqslant 0}\p_1\br{a-1,x} + 
p_2  \sum_{a\geqslant 1}\sum_{x\geqslant 0}\p_2\br{a,x-1} = p_1  \sum_{a\geqslant 0}\sum_{x\geqslant 0}\p_1\br{a,x} + 
p_2  \sum_{a\geqslant 1}\sum_{x\geqslant -1}\p_2\br{a,x} = \\ =\frac{\la_1^2}{\la_1+\la_2} f_1'\br{1} \beta_1 + \frac{\la_2 \la_1}{\la_1+ \la_2}
 f_1'\br{1} \beta_2
\end{multline*}

Лемма доказана.
\end{proof}

\begin{lemma}
 Стационарная вероятность $\pi\br{0,0}$ исходной марковской цепи $\Markk$ вычисляется по следующей формуле:
 \begin{equation}
  \pi\br{0,0} = 
  \frac{  1 -\la_1 f_1'\br{1} \beta_1}{\la_1 + \la_2} \left\{\la_1^2 f_1'\br{1}\br{ \beta_1 - \beta_2} + \frac{1}{\hat{\pi}^0\br{0,0}}
 \br{1 - \la_1 f_1'\br{1} \br{\beta_1 - \beta_2} }\right\}^{-1}
\end{equation}
\end{lemma}

\begin{proof}
Подставим выражения \eqref{help_sum} и \eqref{sum_p:0} в \eqref{final_eq} и получим
\begin{multline*}
  \pi\br{0,0}\brrr{1 + \frac{\la_1^2}{\la_1+\la_2} f_1'\br{1} \beta_1 + \frac{\la_2 \la_1}{\la_1+ \la_2}
 f_1'\br{1} \beta_2  - \la_1 f_1'\br{1} \beta_1} +\\+
\pi\br{0,0} \br{\frac{1}{\hat{\pi}^0\br{0,0}} - 1}\br{1 + \la_1 f_1'\br{1} \beta_2  - \la_1 f_1'\br{1} \beta_1}
=  1 -\la_1 f_1'\br{1} \beta_1
\end{multline*}
далее
\begin{multline*}
  \pi\br{0,0}\left\{1 + \frac{\la_1^2}{\la_1+\la_2} f_1'\br{1} \beta_1 + \frac{\la_2 \la_1}{\la_1+ \la_2}
 f_1'\br{1} \beta_2 - \la_1 f_1'\br{1} \beta_1   -
  1 - \la_1 f_1'\br{1} \beta_2  + \la_1 f_1'\br{1} \beta_1  + \right. \\ \left. + \frac{1}{\hat{\pi}^0\br{0,0}}
 \br{1 + \la_1 f_1'\br{1} \br{\beta_2 - \beta_1} }\right\} =  1 -\la_1 f_1'\br{1} \beta_1.
\end{multline*}
И в итоге:
\begin{multline}
  \pi\br{0,0} = \br{  1 -\la_1 f_1'\br{1} \beta_1} \left\{\frac{\la_1^2}{\la_1+\la_2} 
  f_1'\br{1} \beta_1 + \frac{\la_2 \la_1}{\la_1+ \la_2}
 f_1'\br{1} \beta_2  - \la_1 f_1'\br{1} \beta_2  + \right. \\ +\left.   \frac{1}{\hat{\pi}^0\br{0,0}}
 \br{1 + \la_1 f_1'\br{1} \br{\beta_2 - \beta_1} }\right\}^{-1} =
\frac{  1 -\la_1 f_1'\br{1} \beta_1}{\la_1 + \la_2} \left\{\la_1^2 f_1'\br{1} \beta_1 + \la_2 \la_1 f_1'\br{1} \beta_2 
 - \la_1^2 f_1'\br{1} \beta_2 -\right.\\ -\left.  \la_1 \la_2 f_1'\br{1} \beta_2 +\frac{1}{\hat{\pi}^0\br{0,0}}
 \br{1 + \la_1 f_1'\br{1} \br{\beta_2 - \beta_1} }\right\}^{-1} = \\=
\frac{  1 -\la_1 f_1'\br{1} \beta_1}{\la_1 + \la_2} \left\{\la_1^2 f_1'\br{1}\br{ \beta_1 - \beta_2} + \frac{1}{\hat{\pi}^0\br{0,0}}
 \br{1 - \la_1 f_1'\br{1} \br{\beta_1 - \beta_2} }\right\}^{-1}
\end{multline}

\end{proof}
\newpage

\section*{Заключение}
% Не удаляйте следующую строчку!
%\addcontentsline{toc}{section}{Заключение}
%
В работе была рассмотрена система обслуживания в классе приоритетных алгоритмов. Проведена вероятностная формализация задачи и анализ полученной модели.

Были введены необходимые случайные величины и случайные элементы. Возникающие в системе потоки представлены в виде точечных маркированных процессов с соответствующими выделенными дискретными компонентами. Формализована работа процесса обслуживания в виде описания законов изменения состояния обслуживающего устройства и изменения размеров очередей. Как окончательный результат в построении математической модели, были выписаны выражения для необходимых условных вероятностей.

Доказана марковость последовательностей $\Mark$ и $\Markk$. Получены рекуррентные соотношения для одномерных распределений последовательностей $\Mark$ и $\Markk$.  Была проведена классификация состояний как марковской цепи $\Mark$, так и марковской цепи $\Markk$. Выписаны соотношения для многомерных производящих функций обеих последовательностей и найдено необходимое и достаточное условие существования стационарного (эргодического) распределения марковской цепи $\Markk$.

\newpage

\begin{thebibliography}{99}
% Не удаляйте следующую строчку!
\addcontentsline{toc}{section}{Литература}
\bibitem{FedotkinOne} Федоткин М.~А. Оптимальное управление конфликтными потоками и маркированные точечные процессы с выделенной дискретной компонентой. 1 // Liet. matem. rink. 1988. Т.28, № 4. С. 783-794. ISSN 0132-2818.
\bibitem{FedotkinTwo} Федоткин М.~А. Оптимальное управление конфликтными потоками и маркированные точечные процессы с выделенной дискретной компонентой. 2 //  Liet. matem. rink. 1989. Т.29, № 1. С. 148-159.
\bibitem{ZorinFedotkin} Зорин А.~В., Федоткин М.~А. Оптимизация управления дважды стохастическими неординарными потоками в системах с разделением времени. Автоматика и телемеханика, № 7, 2005. С. 102-111.
\bibitem{KlimovArticle} Климов Г.~П. Системы обслуживания с разделением времени. 1 // Теория вероятностей и ее применения. 1974. Т. 19. Вып. 3. С. 558-576.
\bibitem{Chinchin} Хинчин А.~Я. Работы по математической теории массового обслуживания. --- М.:Государственное издательство физико-математической литературы, 1963.
\bibitem{Kolmogorov:1974} Колмогоров А.Н. Основные понятия теории
  вероятностей. М.: Наука, 1974. --- 119~с.
\bibitem{Gnedenko} Гнеденко Б.~В.\ Курс теории вероятностей. --- М.:~Издательство ЛКИ, 2007.
\bibitem{Kolmogorov} Колмогоров А.~Н., С.~В. Фомин Элементы теории функций и функционального анализа --- М.:~Физматилит,2006.
\bibitem{Shiryaev} Ширяев А.~Н.Вероятность --- 2-е изд. --- М.:~Наука, 1989.
\bibitem{Kemeny} Кемени Дж., Снелл Дж., Кнепп А. Счетные цепи Маркова --- М.:~Наука, 1987.
\end{thebibliography}
\end{document}

\end{document}

