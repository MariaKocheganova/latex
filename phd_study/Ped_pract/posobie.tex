\documentclass[10pt,oneside,final]{book}
\usepackage[utf8]{inputenc}
\usepackage[T1,T2A]{fontenc}
\usepackage{type1ec}
%\usepackage[mathlit]{newliterat}
\usepackage[russian,english]{babel}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[sumlimits,intlimits,namelimits]{amsmath}
\usepackage{indentfirst} 
\usepackage{verse}
\usepackage[a5paper,width=115mm,height=175mm, %
includefoot,ignorehead]{geometry}
\usepackage{ccaption}
\captiondelim{. }
\captionnamefont{\small}
\captiontitlefont{\small}
\captionstyle{\centering}
\usepackage[dvipsnames]{xcolor}
\usepackage{graphicx}
\usepackage{lettrine}
\usepackage{fancyvrb}
\pagestyle{plain}
\usepackage{tikz}

\usepackage{titlesec}
\titleformat{\chapter}[hang]{\Large\bfseries\sffamily%
  \color{CadetBlue}}{\chaptertitlename\ %
  \thechapter~\raisebox{-2.5ex}{\rule{1mm}{5ex}}~}{0pt}{}{}
\titleformat{\section}[block]{\filright\large\bfseries\sffamily%
  \color{CadetBlue}}{\thesection.\ }{0pt}{}{}
\titlelabel{\thetitle.\ }
\titlespacing{\section}{\parindent}{2\baselineskip}{\baselineskip}
\titlespacing{\chapter}{\parindent}{0pt}{2\baselineskip}
\usepackage{titletoc}
\titlecontents{chapter}%
              [0pt]%
              {\vspace{1ex}}%
              {\bfseries \color{dark-red}\chaptertitlename~\thecontentslabel.\ }%
              {}
              {\color{dark-red}\titlerule*[1em].\quad\bfseries\thecontentspage}[\vspace{1ex}] 
\titlecontents{section}%
              [1em]%
              {}%
              {\color{dark-red}\thecontentslabel.\ }%
              {}
              {\color{dark-red}\titlerule*[1em].\quad\thecontentspage}%[\vspace{1ex}] 
%\contentsmargin{0pt}

\usepackage{makeidx}

\pdfcompresslevel=9

%
% про усечение заголовка главы в хедере
% http://tex.stackexchange.com/questions/41277/how-to-cut-a-section-title-in-the-header
%

\usepackage{cmap}
\usepackage{xcolor}
\usepackage[pdftex,unicode]{hyperref}
\definecolor{dark-red}{rgb}{0.4,0.15,0.15}
\definecolor{dark-blue}{rgb}{0.15,0.15,0.4}
\definecolor{medium-blue}{rgb}{0,0,0.5}
\hypersetup{
    colorlinks, linkcolor={dark-red},
    citecolor={dark-blue}, urlcolor={medium-blue}
}

\renewcommand{\Pr}{{\mathbf P}}
\renewcommand{\le}{\leqslant}
\renewcommand{\leq}{\leqslant}
\renewcommand{\ge}{\geqslant}
\renewcommand{\geq}{\geqslant}
\newcommand{\M}{{\mathbf M}}
\newcommand{\D}{{\mathbf D}}
\newcommand{\bQ}{{\boldsymbol Q}}
%\newcommand{\ctg}{\mathrm{ctg}\,}
\newcommand*{\hm}[1]{#1\nobreak\discretionary{}%
  {\hbox{$\mathsurround=0pt #1$}}{}} 
\newcommand*{\htimes}{{}\nobreak%
  \discretionary{\hbox{$\mathsurround=0pt \times$}}%
  {\hbox{$\mathsurround=0pt \times$}}{}} 
\newtheorem{theorem}{\color{CadetBlue}Теорема}
\newtheorem{lemma}{\color{CadetBlue}Лемма}
\newtheorem{definition}{\color{CadetBlue}Определение}
\newtheorem{zadacha}{}[chapter]

\makeatletter
\renewcommand{\@biblabel}[1]{#1.}
\renewenvironment{thebibliography}[1]
     {\chapter*{\refname}%
       \addcontentsline{toc}{chapter}{\refname}%
       \addcontentsline{tce}{chapter}{References}%
      \@mkboth{\MakeUppercase\refname}{\MakeUppercase\refname}%
      \list{\@biblabel{\@arabic\c@enumiv}}%
           {\settowidth\labelwidth{\@biblabel{#1}}%
            \leftmargin 0pt % \labelwidth 
            \itemindent \parindent
            \advance\itemindent\labelwidth
            % \advance\leftmargin\labelsep
            \itemsep 0ex \parsep 0ex
            \@openbib@code
            \usecounter{enumiv}%
            \let\p@enumiv\@empty
            \renewcommand\theenumiv{\@arabic\c@enumiv}}%
      \sloppy
      \clubpenalty4000
      \@clubpenalty \clubpenalty
      \widowpenalty4000%
      \sfcode`\.\@m}
     {\def\@noitemerr
       {\@latex@warning{Empty `thebibliography' environment}}%
      \endlist}
\makeatother

\newcounter{example}
\renewcommand{\theexample}{(\alph{example})}
\newenvironment{example}[1]%
{\par\medskip\refstepcounter{example}
  \textbf {Пример \theexample: #1.}}%
{}

\makeindex

\begin{document}
\selectlanguage{russian}
\begin{titlepage}
  \begin{center}
    МИНИСТЕРСТВО ОБРАЗОВАНИЯ И НАУКИ 
    \\ РОССИЙСКОЙ ФЕДЕРАЦИИ
    
    \medskip
    
    {\textbf{Национальный исследовательский 
        \\ Нижегородский  государственный университет 
        \\  им.~Н.И.~Лобачевского}} 
    
    
    \vfill 
    
    \large \textbf{\Large Аналитические и численные методы в теории очередей}
    
    \bigskip
    
    Учебно-методическое пособие
    
    \bigskip
    
    Рекомендовано методической комиссией 
    \\факультета ВМК для студентов ННГУ, 
    \\ обучающихся по направлениям подготовки 
    \\ 010400 <<Прикладная
    математика и информатика>> и 
    \\ 010300 <<Фундаментальная информатика
    \\ и информационные технологии>> \vfill
    
    Нижний Новгород \\ 2013
  \end{center}
  
\end{titlepage}

\addtocounter{page}{1}
\thispagestyle{empty}
\indent УДК 519.245\\
\indent ББК В17\\
\indent\phantom{ББК }В24

\vspace{1cm}

В24\quad Аналитические и численные методы в теории очередей. Авторы:~Зорин~А.В.,
Зорин~В.А., Пройдакова~Е.В., Федоткин~М.А.: Учебно-методическое
пособие~--- Нижний Новгород:
 Нижегородский госуниверситет, 2017.~---
\pageref{p:thelast}~с.

\bigskip

Рецензент: к.ф.-м.н., доцент \textbf{О.А. Кузенков}

\vfill

% Настоящее пособие является введением в теорию цепей Маркова с
% общим измеримым пространством состояний. В нём разбираются те понятия
% теории общих цепей Маркова, которые имеют наглядные прообразы в теории
% классических счётных цепей Маркова: неприводимость, минорантные
% множества, цикличность, возвратность и невозвратность,
% стационарность. Отобранный материал применяется к одной содержательной
% задаче об обслуживания конфликтных транспортных потоков с
% последействием в классе циклических алгоритмов.

Пособие предназначено для студентов, обучающихся по
направлениям <<Прикладная математика и информатика>> и
<<Фундаментальная информатика и информационные технологии>>, и
может быть использовано при чтении  специальных курсов <<Теория случайных
процессов>>, <<Дополнительные главы теории вероятностей>>, <<Теория
управляемых систем массового обслуживания>>, <<Теория меры>>. 

\vfill

\begin{center}
  Ответственный за выпуск:\\
  заместитель председателя методической комиссии \\
  факультета ВМК ННГУ, \\ к.т.н., доцент \textbf{В.М. Сморкалова}
\end{center}

\vfill

\hfill \parbox{2.65cm}{
  \noindent УДК 519.245 \\ ББК В17 }

\vfill

\hfill 
\begin{minipage}{0.65\linewidth}\raggedright \noindent \bfseries
  \copyright{} Зорин А.В., Зорин В.А., Пройдакова~Е.В., Федоткин М.А.,
  2013  
  \\ \copyright{} Нижегородский госуниверситет, 2013
\end{minipage}

\newpage

\tableofcontents
% \chapter*{Предисловие}
% \addcontentsline{toc}{chapter}{Предисловие}


\newpage

\begin{verse}
  Учить, иль не учить? Вот в чем вопрос\\
  Уж скоро век, как вычислитель стал <<железом>>\\
  ...

Размышление о том, что  с одной стороны многие задачи допускают аналитическое
решение, для широкого диапазова параметров и оно известно, но в маленьком курсе всего не расскажешь и у бакалавров
может не хватить подготовки, чтобы осознать и использовать точное
решение. Поэтому альтернатива -- научить, как численно обсчитывать конкретную
систему, используя самые общие идеи, без учета специфики задачи.

И не понятно, хорошо это или плохо.
\end{verse}

\newpage
\chapter{Введение}

Пусть есть кафе с $N=10$ местами (индивидуальными столиками). Очереди нет,
столики обслуживаются официантами. Клиент в среднем
проводит в кафе пол-часа. Среднее число поступающих клиентов в час изменяется. В
момент открытия, в 9:00, в приходят 6 клиентов в час; с~9 до 15 интенсивность
линейно растёт до 10 клиентов в час; с 15 до 18 часов она линейно убывает до 8
клиентов в час. В 18:00 кафе закрывается. В момент открытия кафе пустует. Как
изменяется в течение дня число занятых мест?

Мы понимает, что в работе такого кафе есть большая доля влияния случая: моменты,
когда входят посетители, их заказы, их темп еды --- всё заранее предвидеть и
распланировать невозможно. Поэтому мы будет рассматривать эту задачу методами
теории вероятностей. Итак, мы принимает, что число занятых мест в каждый
отдельно взятый момент времени есть случайная величина. Тогда вопрос можно
переформулировать так: как изменяется среднее число клиентов? как изменяется
дисперсия среднего числа клиентов?

Рассмотрим поподробнее входные данные задачи, поймём их вероятностный
смысл. Во-первых, запишем выражение для мгновенной интенсивности прихода
клиентов (то, что мы ранее назвали <<число клиентов в час>>) для произвольного
момента времени $t$. Выберем в качестве начального момента отсчёта времени $t=0$
время 9:00 утра, тогда будем считать, что $0\leq t\leq 9$. Обозначим эту
интенсивность через $\lambda(t)$. Физический смысл этой характеристики такой: за
интервал времени вида $(t, t+h)$ в среднем поступает $\lambda(t)\cdot h+o(h)$
требований.  Имеем:
\[
\lambda(t)=\begin{cases}
  6+2t/3,& 0\leq t\leq 6\\
  14-2t/3,& 6< t \leq 9.
\end{cases}
\]
Понятно, что такое
условие не определяет полностью вероятностный закон поступления
клиентов. Сформулируем следующие постулаты \emph{нестационарного ординарного
  потока без последействия}: независимо от того, как приходили клиенты прежде
момента $t$, за промежуток времени $(t, t+h)$ приходит ровно один новый клиент с
вероятностью $\lambda(t)h+o(h)$, поступает более одного клиента с
вероятностью $o(h)$ и не поступает ни одного клиента с вероятностью
$1-\lambda(t)h+o(h)$. 

Дифференциальные уравнения: 
\begin{align*}
  p_0'(t) & = -\lambda(t)p_0(t)+\mu p_1(t);\\
  p_i'(t) & = \lambda(t)p_{i-1}(t)-(\lambda(t)+i\mu)p_i(t)+(i+1)\mu
  p_{i+1}(t),\\ & \qquad \qquad i=1, 2, \ldots, N-1;\\
  p_N'(t) & = \lambda(t)p_{N-1}(t)-N\mu p_N(t).
\end{align*}

Среднее число клиентов:
\[
m(t)=\sum_{i=0}^N i p_i(t).
\]
\begin{Verbatim}[frame=single,xleftmargin=2em,numbers=left]
function pdot = kolm(p,t)
  m=2;
  if (t<6) l=6+2/3*t; else l=14-2/3*t; endif;
  sz = length(p);
  A = zeros(sz,sz);
  A(1:sz+1:sz^2) = -l-m*(0:sz-1);
  A(2:sz+1:sz^2) = l;
  A(sz+1:sz+1:sz^2) = m*(1:sz-1);
  A(sz^2) = -(sz-1)*m;
  pdot = A*p;
endfunction;

N=10;
tt = 0:0.1:9;
pp0 = [1, zeros(1,N)];
pp = lsode("kolm", pp0, tt);
plot(tt,pp); ## распределение вероятностей
plot(tt,pp*(0:N)'); ## среднее число клиентов
\end{Verbatim}


Как мы можем проверить этот результат и, главное, объяснить его <<заказчику>>? 
Ключевой момент здесь --- связать вероятность с частотой и заодно увидеть
собственными глазами, как выглядят \emph{траектории случайного процесса}.

Итак, в оставшейся части Введения мы продемонстрируем один важный метод анализа
процессов обслуживания: метод имитационного моделирования --- и больше про него
не будем вспоминать, так как это отдельная большая наука. В качестве рабочего
определения примем, что имитационное моделирование состоит в выделении некоторых
существенных событий, происходящих в сложной системе, и в <<розыгрыше>>
возможной последовательности наступления этих событий с учётом известных
распределений вероятностей для <<входных управляющих событий>>. 

Во-первых, давайте разберёмся в том, как же всё-таки разворачивается поступление
клиентов во времени.

Надо определить моменты поступления требований в систему. Введём вспомогательную
функцию $\Lambda(t)=\int\limits_0^t \lambda(s)\,ds$. Она равна
\[
\Lambda(t)=\begin{cases}
  6t+t^2/3,& 0\leq t\leq 6\\
  14t-t^2/3-24,& 6< t \leq 9.
\end{cases}
\]
Пусть $T_0=0$, а величины $T_1$, $T_2$, \ldots~--- независимые случайные
величины с экспоненциальным распределением с параметром $1$, $\Lambda(t)$ ---
вспомогательная функция, определённая выше. Для момента $t\ge0$ введём величину
\[
\eta(t)=\sup\{n\colon T_0+T_1+\ldots+T_n<\Lambda(t)\}.
\]
Можно показать, что как функция от $t$, семейство случайных величин $\{\eta(t);
t\ge0\}$ ведёт себя как \emph{счётчик числа пришедших клиентов} в нестационарном
ординарном потоке без последействия с мгновенной интенсивностью $\lambda(t)$,
$t\ge0$. Пусть $V(t)$~--- функция, обратная к $\Lambda(t)$. Тогда моменты
поступления клиентов (моменты скачков считающей функции $\eta(t)$) суть 
\[
\tau_1=V(T_1), \; \tau_2=V(T_1+T_2),\; \tau_3=V(T_1+T_2+T_3),\; \ldots
\]
В нашем случае:
\[
V(t)=
\begin{cases}
  \sqrt{3(t+27)}-9,& 0\le t\le 48,\\
  \sqrt{21-3(123-t)},& 48< t\leq 75.
\end{cases}
\]
Теперь определим моменты поступления клиентов на всём промежутке наблюдения $[0,
9]$ и нарисуем вид функции $\eta(t)$ (а точнее, её \emph{выборчную реализацию}).
\begin{Verbatim}[frame=single,xleftmargin=2em,numbers=left]
function v = Vfunc(tt)
	 whr = (tt>48);
	 v = zeros(size(tt));
	 v = sqrt(3*(tt+27))-9;
	 v(whr) = 21-sqrt(3*(123-tt(whr)));
endfunction;

function taus = ClientsIn()
  taus = [];
  Tn = -log( rand() );
  y = Vfunc(Tn);
  while(y<=9)
    taus(end+1)=y;
    Tn = Tn - log( rand() );
    y = Vfunc(Tn);
  endwhile
endfunction

taus = ClientsIn();
stairs( taus, 0:(length(taus)-1) );
\end{Verbatim}

Обозначим $W_{j,i}$ время, через которое в кафе освободится не менее $j$ мест в
момент прихода $i$-го клиента (мы следуем классической работе Кифера и
Вольфовица, в которой число мест в кафе было не ограничено). Объединим эти
величины с одинаковым индексом $i$ в вектор $W_i=(W_{1,i}, \ldots, W_{N,i})$. Из
определения устанавливаем справедливость неравенств $0\le W_{1,i}\le W_{2,i}\le
\ldots \le W_{N,i}$. Этот вектор несёт в себе много интересной
информации. Например, если ровно $k$ его первых элементов равны нулю, это
означает, что в момент прихода $i$-го клиента есть $k$ свободных мест. В
частности, первый клиент за день застаёт все места свободными, так что $W_1=(0,
0, \ldots, 0)$. Пусть теперь для $i$-го клиента вектор
$0=W_{k,i}<W_{k+1,i}$. Этот клиент, очевидно, сразу займёт свободное
место. Каким тогда будет вектор $W_{i+1}$? Следующий клиент придёт через
промежуток $\alpha_{i+1}=\tau_{i+1}-\tau_i$, время обслуживания $i$-го клиента обозначим
$S_i$. Значит, в момент прихода $(i+1)$-го клиента оставшееся время до
ухода $i$-го клиента равно $(S_i-\alpha_{i+1})^+=\max\{0, S_i-\alpha_{i+1}\}$. Обозначим через
$R(\cdot)$ оператор упорядочивания по возрастанию элементов вектора,
подставленного на место точки в качестве его аргумента. Тогда будем иметь,
очевидно,
\[
W_{i+1}=
R\bigl(0, \ldots, 0,
(S_i-\alpha_i)^+,
(W_{k+1,i}-\alpha_{i+1})^+,\ldots,
(W_{N,i}-\alpha_{i+1})^+\bigr).
\]
Здесь на первых местах стоят $(k-1)$ нуль. Если же в момент прихода $i$-клиента
все места заняты, $W_{1,i}>0$, то этот клиент просто теряется, и 
\[
W_{i+1}=\bigl((W_{1,i}-\alpha_{i+1})^+, \ldots, (W_{N,i}-\alpha_{i+1})^+\bigr).
\]
Алгоритм имитации будет следующий: 1) определить моменты прихода клиентов; 2)
для каждого клиента вычислить его вектор остаточных длительностей; 3) если
клиент не видит свободных мест, помещаем его в поток потерянных клиентов; если
места есть, то определяем момент выхода этого клиента и помещаем в выходящий
поток; 4) соединяем с сортировкой список моментов начала обслуживания и моментов
выхода клиентов с учётом изменения числа клиентов ($+1$, $-1$); 5) вычисляем
актуальное число клиентов в каждый момент скачка.

\begin{Verbatim}[frame=single,xleftmargin=2em,numbers=left]
function [jmps qs taus lost srvd] = RunSim(mu, NN)
	 taus = ClientsIn;
	 jmps_temp = [];
	 lost = [];
	 W = zeros(1, NN);
	 tprev=0;
	 for tau = taus
	     if W(1)>0 
		lost(end+1)=tau;
		W = W+tprev-tau;
		W( W<0 ) = 0;
	     else
		 jmps_temp(end+1)=tau;
		 W = W+tprev-tau;
		 S = -log(rand())/mu;
		 srvd(end+1) = tau+S;
		 W(1) = max([0, W(1)-log(rand())/mu]);
		 W = sort(W);
	     endif
	     tprev=tau;
	 endfor
	 [jmps idx] = sort([0 jmps_temp srvd]);
	 qs = cumsum([0 ones(1, length(jmps_temp)), ...
               -ones(1, length(srvd))](idx));
endfunction
\end{Verbatim}


\chapter[Марковские процессы гибели и размножения с непрерывным 
  временем]%
  {\raggedright Марковские процессы гибели и размножения с непрерывным 
  временем}


\section{Период занятости. Преобразование Лапласа}
В рамках спецкурсов <<Вероятностные модели в теории очередей>> и <<Теория
массового обслуживания>> разбирались конкретные примеры простейших систем
массового обслуживания в предположении о простейшем входящем потоке и
экспоненциальном распределении длительности обслуживания произвольного
требования. В качестве математической модели выбирался процесс $\{\varkappa(t);
t\geqslant0\}$, описывающие изменение длины очереди или числа требований в
системе $\varkappa(t)$ в момент $t\geqslant0$. Во всех рассмотренных там случаях
(задачи Эрланга для конечного и бесконечного пуска, задача Пальма для $n$ линий
с потерями, система с ожиданием и $n$ приборами) процесс $\{\varkappa(t);
t\geqslant0\}$ оказывался марковским, а система дифференциальных уравнений
Чепмена--Колмогорова имела трёхдиагональную матрицу. Все рассмотренные тогда
процессы являются частными случаями важного класса марковских процессов,
носящего название процессов гибели и размножения. Введём обозначения для
переходных вероятностей
$$
p_{i,j}(t)=\Pr(\{\omega\colon \varkappa(s+t)=j\}\mid \{\omega\colon
\varkappa(s)=i\}), \quad s, t\leqslant0.
$$
Для марковского процесса доказывается существование пределов
\begin{gather*}
  a_{i,j}=p_{i,j}'(0)=\lim\limits_{t\to0}\dfrac{p_{i,j}(t)}{t}\,, \quad i\neq j,\\
  -a_i=a_{i,i}=p_{i,i}'(0)=\lim\limits_{t\to0}\dfrac{p_{i,i}(t)-1}{t}\,.
\end{gather*}
Величины $a_{i,j}$, $i$, $j\in\{0, 1, \ldots\}$ называются мгновенными
интенсивностями перехода данного марковского процесса.

\begin{definition}
  Случайный марковский процесс с конечным или бесконечным счётным числом
  состояний называется процессом гибели и размножения, если для некоторых
  неотрицательных величин $\lambda_0$, $\lambda_1$, \ldots{} и $\mu_1$, $\mu_2$,
  \ldots{} его мгновенные интенсивности перехода имеют вид:
  \[
  a_0=\lambda_0, \quad a_i=\lambda_i+\mu_i, \quad
  a_{i, i-1}=\mu_i, \quad a_{i-1,i}=\lambda_{i-1}, \quad i=1, 2, \ldots.
  \]
\end{definition}
Величины $\lambda_i$, $i\geqslant0$ называют интенсивностями рождений, а
величины $\mu_i$, $i\geqslant1$~--- интенсивностями гибели. Рассмотрим
конкретные примеры. Студенту предлагается самостоятельно проверить приведённые
ниже формулы.

В задаче Эрланга для \emph{ограниченного} пучка из $n$ идентичных линий имеем:
$\lambda_i=\lambda$, $i=0$, $1$, \ldots, $n-1$; $\lambda_i=0$ для $i\geqslant
n$; $\mu_i=i\mu$, $i=1$, $2$, \ldots, $n$; $\mu_i=0$ для $i\geqslant n+1$.  В
задаче Эрланга для \emph{бесконечного} пучка из идентичных линий имеем:
$\lambda_i=\lambda$, $i=0$, $1$, \ldots; $\mu_i=i\mu$, $i=1$, $2$, \ldots.  В
системе с ожиданием и $n$ приборами имеем: $\lambda_i=\lambda$, $i=0$, $1$,
\ldots;  $\mu_i=i\mu$, $i=1$, $2$,
\ldots, $n$; $\mu_i=n\mu$ для $i\geqslant n+1$.

Стационарное распределение $p_i$, $i=0$, $1$, \ldots{} для процесса гибели и
размножения удовлетворяет \emph{разностным} уравнениям
\[
  \left\{
    \begin{aligned}
      0&= -\lambda_0 p_0+\mu_1 p_1,\\
      0&= \lambda_{i-1}p_{i-1}-(\lambda_i+\mu_i)p_i+\mu_{i+1}p_{i+1}, \qquad
      i=1, 2, \ldots{}
    \end{aligned}
  \right.
\]
и условию нормировки
\[
p_0+p_1+p_2+\ldots=1.
\]
Из разностных уравнений находим:
\[
\lambda_{i}p_{i}-\mu_{i+1}p_{i+1}=\lambda_{i-1}p_{i-1}-\mu_{i}p_{i}=\ldots =
\lambda_0 p_0-\mu_i p_1=0.
\]
Отсюда
\[
p_i=\dfrac{\lambda_{i-1}\lambda_{i-2}\times\ldots\times\lambda_0}{\mu_i\mu_{i-1}\times\ldots\times
\mu_1}\cdot p_0.
\]
Подстановка в условие нормировки даёт уравнение для вероятности $p_0$:
\[
p_0 \Bigl(1+\dfrac{\lambda_0}{\mu_1}+\dfrac{\lambda_1\lambda_0}{\mu_2\mu_1}+\ldots
\Bigr)=1.
\]
Следовательно, \emph{стационарное} распределение существует тогда и только тогда, когда
\[
\sum_{i=1}^\infty \prod_{l=0}^{i-1} \dfrac{\lambda_l}{\mu_{l+1}}<\infty.
\]
Чтобы найти допредельное распределение вероятностей
\[
p_i(t)=\Pr(\{\omega\colon \varkappa(t)=i\}), \quad i=0, 1, \ldots
\]
надо решить (бесконечную) систему линейных дифференциальных уравнений
\[
\left\{
  \begin{aligned}
  p_0'(t)&=-\lambda_0 p_0(t)+\mu_1p_1(t),\\
  p_i'(t)&=\lambda_{i-1}p_{i-1}(t)-(\lambda_i+\mu_i)
  p_i(t)+\mu_{i+1}p_{i+1}(t),\quad
   i=1, 2, \ldots
 \end{aligned}
\right.
\]
с начальным условием $p_i(0)=\tilde{p}_i$, $i=0$, $1$, \ldots. Если число
состояние системы конечно, для решения дифференциальных уравнений естественно
воспользоваться тем или иным приближённым методом.

Рассмотрим теперь новую характеристику функционирования системы массового
обслуживания, которая не рассматривалась на спецкурсах бакалавриата:
\emph{период занятости} система. Будем называть \emph{периодом занятости} $\Pi$
системы обслуживания промежуток времени с началом в момент поступления в пустую
систему первого требования и с окончанием в момент первого затем освобождения
системы от вновь поступивших требований. Для изучения вероятностных свойств
периода занятости можно применять различные методы.

Пусть в однолинейной системе с простейшим входящим потоком и экспоненциальным
обслуживанием имеется неограниченное число мест ожидания. В нотации Кендалла это
система M/M/1/$\infty$. Соответствующий процесс гибели и размножения задаётся
параметрами: $\lambda_i=\lambda$, $\mu_{i+1}=\mu$, $i=0$, $1$, \ldots. С целью
изучить период занятости сделаем состояние $0$ поглощающим: положим
$\lambda_0=0$. Тогда событие <<период занятости закончился до момента $t$>>,
$\Pi<t$, эквивалентно событию <<вспомогательный процесс в момент $t$ находится в
состоянии $0$>>. Система дифференциальных уравнений для состояний
модифицированного процесса примет вид:
\[
\left\{
  \begin{aligned}
  \tilde p_0'(t)&=\mu \tilde p_1(t),\\
  \tilde p_1'(t)&=-(\lambda+\mu) \tilde p_1(t)+\mu \tilde p_2(t),\\
  \tilde p_i'(t)&=\lambda \tilde p_{i-1}(t)-(\lambda+\mu)
  \tilde p_i(t)+\mu \tilde p_{i+1}(t),\quad
   i=2, 3, \ldots
 \end{aligned}
\right.
\]
с начальными условиями: $\tilde p_0(0)=\tilde p_2(0)=\tilde p_3(0)=\ldots=0$,
$\tilde p_1(0)=1$. 
Введём производящие функции 
\[
F(z,t)=\sum_{i=0}^\infty \tilde p_i(t) z^i, \quad |z|\leqslant 1,\; t\geqslant 0.
\]
Так же, как и при изучении входящего потока в спецкурсе по вероятностным моделям
ТМО, получаем дифференциальное уравнение для производящей функции:
\[
\dfrac{\partial F}{\partial t}(z,t)=
\Bigl(\lambda( z-1)-\mu\Bigl(1-\dfrac1z\Bigr)\!\Bigr) F(z,t)+
\Bigl(\lambda(z-1)+\mu-\dfrac{\mu}{z}\Bigr)\tilde p_0(t).
\]
Перейдём к преобразованиям Лапласа:
\[
\hat F(z,s)=\int_0^\infty e^{-st} F(z,t)\,dt,\qquad
\hat p_0(s)=\int_0^\infty e^{-st} \tilde p_0(t)\,dt.
\]
Дифференцирование фун\-к\-ции-ори\-гинала эквивалентно умножению её
преобразования Лапласа на $s$ с последующим вычитанием значения функции в нуле.
Поскольку $F(z,0)=z$, получим:
\begin{gather*}
s\hat F(z,s)-z= \Bigl(\lambda( z-1)-\mu\Bigl(1-\dfrac1z\Bigr)\!\Bigr) \hat F(z,s)+
\Bigl(\lambda(z-1)+\mu-\dfrac{\mu}{z}\Bigr)\hat p_0(s),
\intertext{откуда}
 \hat F(z,s)=
\dfrac{z^2+(\lambda z^2-(\lambda -\mu) z-\mu)\hat p_0(s)}%
{z(s+\lambda+\mu)-\lambda z^2-\mu}\,.
\end{gather*}
Пусть 
\begin{gather*}
  z_1(s)=\dfrac{\lambda+\mu+s-\sqrt{(\lambda+\mu+s)^2-4\lambda\mu}}{2\lambda},\\
  z_2(s)=\dfrac{\lambda+\mu+s+\sqrt{(\lambda+\mu+s)^2-4\lambda\mu}}{2\lambda},
\end{gather*}
где ветвь корня задана условием $\sqrt{1}=1$. Тогде $|z_1(s)|<|z_2(s)|$. По
теореме Руше, ровно один из двух корней лежит в круге $|z|<1$, следовательно,
это именно $z_1(s)$. Значит, он же должен обращать числитель в ноль. Отсюда
находим $\hat p_0(s)$:
\[
%\hat F(z,s)=\dfrac{z^2-(\mu-\lambda
%  z)(1-z)(z_1(s)/s)}{\lambda(z-z_1(s))(z_2(s)-z)}\,.
\hat
p_0(s)=\dfrac{2\mu}{s(\lambda+\mu+s+\sqrt{(\lambda+\mu+s)^2-4\lambda\mu})}\,. 
\]
Функция $s \hat p_0(s)$ есть преобразование Лапласа для $g(t)=p_0'(t)$, т.е. для
плотности распределения $g(t)$ периода занятости~$\Pi$. Представляет интерес
вопрос о численном обращении данного преобразования Лапласа. Результат работы
численного алгоритма можно сравнить в данном случае с точным решением, которое
может быть найдено из таблиц:
\[
p_0'(t)=\dfrac{\sqrt{\mu/\lambda} e^{-(\lambda+\mu)t}
  I_1(2\sqrt{\lambda\mu}t)}{t}\,,
\]
где $I_1(\cdot)$~--- (модифицированная) функция Бесселя первого рода. Один из
способов численного обращения описан в статье: \foreignlanguage{english}{J.~Abate and
P.~Valk\'o. Multi-precision Laplce transform inversion~// International journal
for numerical methods in engineering, 2004, v.~60, p.~979--993.}

В основе численных методов обращения преобразования Лапласа лежит следующая
формула из теории комплексного переменного:
\[
f(t) = \dfrac{1}{2\pi i} \int_{c-i\cdot\infty}^{c+i\cdot\infty} F(s) e^{st}\,ds,
\]
в отечественной литературе известная под названием преобразования Меллина, а в
англоязычных публикациях называемая также интегралом Бромвича
(\foreignlanguage{english}{Bromwich}). Интегрирование производится вдоль
вертикальной прямой $s=c+i y$, $-\infty<y<\infty$, а константа $c$ может
выбираться произвольно, но проваее абсциссы абсолютной сходимости преобразования
Лапласа. А.~Тальбот (A.~Talbot) в~1979 году предложил производить интегрирование
вдоль другого контура, охватывающего отрицательную действительную полуось и
содержащего все особые точки функции $F(s)$. Равенство интеграла Меллина --
Бромвича и интеграла Тальбота устанавливается по теореме Коши. Тальбот предложил
семейство контуров, из которых выберем один с параметрическим заданием 
\[
s(y)=cy(\ctg y+i),\qquad -\pi<y<\pi.
\]
Тогда 
\(s'(y)=i c (1+i \sigma(y))\), где 
$$
\sigma(y)=y+(y\ctg y-1)\ctg y.
$$
Тогда
\begin{align*}
  f(t)&=\dfrac{1}{2\pi i} \int_{-\pi}^\pi e^{ts(y)} F(s(y)) s'(y)\, dy=
  \\ &=
  \dfrac{r}{\pi} \int_0^\pi \mathfrak{Re}\bigl(
  e^{ts(y)} F(s(y)(1+i \sigma(y)) \bigr)\,dy.
\end{align*}
Применяя к определённому интегралу формулу трапеций с узлами $y_j\hm=k\pi/N$, получим:
\[
f(t)\approx\dfrac{c}{N}
\biggl\{
\dfrac12 F(c) e^{ct}+
\sum_{k=1}^{N-1} \mathfrak{Re}\bigl(
  e^{ts(y_k)} F(s(y_k)(1+i \sigma(y_k)) \bigr)
\biggr\}.
\]
Авторы цитированной выше статьи рекомендуют брать $c=2N/(5t)$. Число интервалов
$N$ можно брать порядка нескольких десятков. Программный код на языке
\foreignlanguage{english}{Octave} 
приведён ниже.
\begin{Verbatim}[frame=single,xleftmargin=2em,numbers=left]
function ans = talbot(F, t,  N)
  r = 2*N./(5*mean(t));
  h = pi / N;
  k=1:(N-1);
  [xt, xk] = meshgrid(t,k);
  thk = xk*pi/N;
  s = r*thk.*(i+cot(thk));
  sgm = thk + (thk.*cot(thk)-1).*cot(thk);
  ans = r/N*( feval(F,r)*exp(r*t)/2+sum( real( ...
       (feval(F,s).* (1+i*sgm)).*exp(xt.*s)), 1 ) );
endfunction
\end{Verbatim}
На вход функции \texttt{talbot} подаётся функция, вычисляющая преобразование
Лапласа. Она может быть указана либо по имени, либо с помощью конструкции
<<дескриптора функции>>, либо в виде <<анонимной функции>>. Второй аргумент ---
одно значение $t$ или вектор значений $(t_1, t_2, \ldots, t_m)$, в которых
требуется вычислить значение исходной функции $t(t)$. Третий параметр задаёт
число параметр аппроксимации интеграла по методу трапеций. Обратим с помощью этой
функции преобразование Лапласа для плотности $g(t)$ периода занятости~$\Pi$. Пусть
$\lambda=0{,}3$, $\mu=0{,}6$. 
\begin{Verbatim}[frame=single,xleftmargin=2em,numbers=left]
function y = F(s)
  mu = 0.6;
  lmb = 0.3;
  y = 2*mu./(lmb+mu+s+sqrt((sqrt(lmb)-sqrt(mu))^2+s) ...
      .*sqrt((sqrt(lmb)+sqrt(mu))^2+s));
endfunction

mu = 0.6;
lmb = 0.3;
tt = 0.01:0.2:5;
xtrue = sqrt(mu/lmb)*exp(-(lmb+mu)*tt) ...
        .*besseli(1,2*sqrt(lmb*mu)*tt)./tt;
xx = talbot(@F,tt,16);
plot(tt,xtrue,'-',tt,xx,'+')
\end{Verbatim}

В строках 1--6 определяется функция, задающая преобразование Лапласа. Следует
отметить, что при вычислениях с комплексными числами возникает проблема перехода
между ветвями многозначных функций. В данном случае при работе с
функцией вычисления квадратного корня (строки~4--5) пришлось использовать
тождество
\begin{multline*}
\sqrt{(\lambda+\mu+s)^2-4\lambda\mu}=
\\ =
\sqrt{\lambda+\mu+s+2\sqrt{\lambda\mu}} \cdot
\sqrt{\lambda+\mu+s-2\sqrt{\lambda\mu}}=
\\ =
\sqrt{(\sqrt\lambda-\sqrt\mu)^2+s} \cdot
\sqrt{(\sqrt\lambda+\sqrt\mu)^2+s}.
\end{multline*}
Результат представлен на рисунке~\ref{fig:bes}.

% \begin{figure}[thb]
%   \centering
%   \includegraphics[width=10cm]{plot_bessel}
%   \caption{Сравнение точного решения (сплошная линия) и приближённого решения
%     (крестики)
%     \label{fig:bes}}
% \end{figure}

Наряду с применениями преобразования Лапласа для аналитического решения задач,
следует отметить огромную его полезность для решения \emph{вероятностных}
задач. Интеграл преобразования Лапласа
\[
\varphi(s)=\int_0^\infty e^{-st}g(t)\,dt
\]
есть в то же время и \emph{математическое ожидание} непрерывной случайной
величины $\exp\{-s\Pi\}$:
\[
\varphi(s)=\M( e^{-s\Pi}).
\] 
В нашем случае значение случайной величины $\Pi$
однозначно определяется реализацией $\varkappa(\cdot, \omega)$ марковского
процесса. 

Используя понятие математического ожидания можно теперь определить
преобразование Лапласа (называемое более точно преобразованием
Лапласа--Стилтьеса) произвольной неотрицательной случайной величины.
\begin{definition}
  Преобразованием Лапласа неотрицательной случайной величины $\boldsymbol{X}$
  (возможно, принимающей значение $\infty$) называется функция действительного
  переменного $s\geqslant0$ или комплексного переменного $s$, 
  $\mathfrak{Re}\,s\geqslant c_0$, определяемая равенством
  \[
  \varphi(s)=\M\,(e^{-\boldsymbol{X}}).
  \]
\end{definition}

В частности, если $\boldsymbol{X}$~--- дискретная случайная величина,
принимающая значение $x_k\geqslant0$ с вероятностью $p_k$, $k=1$, $2$, \ldots{},
то её преобразование Лапласа вычисляется с помощью ряда
\[
\varphi(s)=\sum_{k=1}^\infty e^{-s x_k} p_k.
\]
Также в теории массового обслуживания встречается случай \emph{смешанной}
случайной величины, имеющей как дискретную, так и непрерывную компоненту в законе
распределения. Пусть функция распределения случайной величина $\boldsymbol{X}$
равна
\enlargethispage{3ex}
\[
G(u)=\begin{cases}
  0 & \text{при $u\leqslant0$,}\\
\displaystyle  \sum_{x_k<u} p_k + \int_{0}^u f(t)\,dt  & \text{при $u>0$,}
\end{cases}
\]
где $p_k>0$, $f(t)\geqslant0$, $\sum\limits_{k}p_k+\int\limits_{-0}^\infty
f(t)\,dt=1$. Тогда 
\[
\M(e^{-s\boldsymbol{X}})=\sum_{k}p_ke^{-s x_k}+\int_{-\infty}^\infty e^{-st}
f(t)\,dt.
\]
Важными свойствами преобразования Лапласа являются следующие: если
неотрицательные случайные величины $\boldsymbol{X}$ и $\boldsymbol Y$
независимы, то преобразование Лапласа
$\varphi_{\boldsymbol{X}+\boldsymbol{Y}}(s)$ их суммы равно
$\varphi_{\boldsymbol{X}}(s)\cdot\varphi_{\boldsymbol{Y}}(s)$, где
$\varphi_{\boldsymbol{X}}(s)$ есть преобразование Лапласа для $\boldsymbol{X}$,
а $\varphi_{\boldsymbol{Y}}(s)$ есть преобразование Лапласа для
$\boldsymbol{Y}$. Если существует $\M(\boldsymbol{X}^k)$, то $\M(\boldsymbol{X}^k)=(-1)^k\varphi_{\boldsymbol{X}}^{(k)}(0)$.

Покажем теперь другое решение задачи о распределении периода занятости системы
M/M/1/$\infty$. Его можно получить, рассмотрев траекторию процесса
$\{\varkappa(t); t\geqslant0\}$. Пусть марковский процесс $\{\varkappa(t);
t\geqslant0\}$ имеет непрерывные справа траектории и пусть $\tau_1$, $\tau_2$,
\ldots{}~--- его моменты скачков. Последовательность $\varkappa_0=\varkappa(0)$,
$\varkappa_1=\varkappa(\tau_1)$, $\varkappa_2=\varkappa(\tau_2)$, \ldots{}
называется \emph{цепью скачков}. Введём величины $\xi_k=\tau_k-\tau_{k-1}$
интервалов между скачками, $k=1$, $2$, \ldots{}. Из теории марковских процессов
известно, что
\begin{multline*}
  \Pr\bigl( \mathop{\cap}\limits_{k=1}^n \{\omega\colon
  \varkappa_k=i_k, \xi_k<u_k
  \}\mid\{\omega\colon \varkappa_0=i_0\}\bigr)=
  \\ =
  \dfrac{a_{i_0,i_1}}{a_{i_0}}\times (1-e^{-a_{i_0} u_1})\times
  \dfrac{a_{i_1,i_2}}{a_{i_1}} (1-e^{-a_{i_1} u_2}) \times \ldots\times
  \dfrac{a_{i_{n-1},i_n}}{a_{i_{n-1}}} \times(1-e^{-a_{i_{n-1}} u_n}).
\end{multline*}
Другими словами, последовательность $\{\varkappa_k; k=0, 1, \ldots\}$ является
цепью Маркова, вероятность её перехода  из состояния $i$ в состояние $j$ равна
$a_{i,j}(a_i)^{-1}$, а при фиксированной траектории $i_0$, $i_1$, \ldots, $i_n$
величины интервалов условно независимы и интервал $\xi_k$ имеет экспоненциальное
распределение с параметром~$a_{i_{k-1}}$. Таким образом, после того, как
определены интенсивности перехода марковского процесса $\{\varkappa(t);
t\geqslant0\}$ по содержательной постановке задачи, можно мыслить этот процесс
как последовательность проходимых состояний и длительностей пребывания в них. На
рисунке~\ref{fig:birth-death} приводится пример реализации процесса гибели и
размножения. 

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}
    \draw[->] (0,0)--(0,3.5);
    \draw[->] (0,0)--(8.5,0);
    \draw
    (0.5,1)--(2,1)--(2,2)--(4,2)--(4,3)--(5.5,3)--(5.5,2)--(7,2)--(7,1)--(7.5,1);
    \draw[red] (2,2)--(4,2)
               (4,3)--(5.5,3)
               (5.5,2)--(7,2);
    \draw (0,0) node[anchor=north] {$O$}
          (0,3.5) node[anchor=west] {$\varkappa(t)$}     
          (8.5,0) node[anchor=south] {$t$}
          (0, 1) node[anchor=east] {$i-1$}
          (0, 2) node[anchor=east] {$i$}
          (0, 3) node[anchor=east] {$i+1$}
          (2,0) node[anchor=north] {$\tau_{k-1}$}
          (4,0) node[anchor=north] {$\tau_{k}$}
          (5.5,0) node[anchor=north] {$\tau_{k+1}$}
          (7,0) node[anchor=north] {$\tau_{k+2}$}
          (3,2) node[red,anchor=south] {$\xi_k$}
          (4.75,3) node[red,anchor=south] {$\xi_{k+1}$}
          (6.25,2) node[red,anchor=south] {$\xi_{k+2}$};
    \filldraw (0,1) circle (1pt)
         (0,2) circle (1pt)
         (0,3) circle (1pt)
         (2,0) circle (1pt)
         (4,0) circle (1pt)
         (5.5,0) circle (1pt)
         (7,0) circle (1pt);
    \draw[->,blue] (2,2) to[bend left] (3.9,3);
    \draw[->,blue] (2,2) to[bend right] (3.9,1);    
    \draw[blue] (3.1,3) node[anchor=south] {$\dfrac{\lambda_{i}}{\lambda_i+\mu_i}$}
          (3.3,1) node[anchor=north] {$\dfrac{\mu_{i}}{\lambda_i+\mu_i}$};
  \end{tikzpicture}
  \caption{Реализация процесса гибели и размножения \label{fig:birth-death}}
\end{figure}

Вернёмся к изучению периода занятости системы, описываемой процессом гибели и
размножения. Пусть $\tilde\Pi$ есть время достижения процессом $\{\varkappa(t);
t\geqslant0\}$ состояния $0$ и рассмотрим различные начальные состояния. Введём
соответствующее преобразование Лапласа
\[
\varphi_i(s)=\M(e^{-s\tilde\Pi}\mid\{\omega\colon \varkappa(0)=i\}), \qquad i=1,
2, \ldots.
\]
Очевидно, всё время достижения нуля состоит из двух частей: из интервала $\xi_1$
прибывания в начальном состоянии и из времени $\tilde\Pi_1$ достижения нуля из нового
состояния $\varkappa_1$. По формуле полного математического ожидания,
\begin{align*}
  \varphi_1(s)&= \dfrac{\mu_1}{\lambda_1+\mu_1}
  \M(e^{-s(\xi_1+\tilde\Pi_1)}\mid\{\omega\colon \varkappa_0=1, \varkappa_1=0\})
  +
  \\ & \quad 
  +\dfrac{\lambda_1}{\lambda_1+\mu_1}
  \M(e^{-s(\xi_1+\tilde\Pi_1)}\mid\{\omega\colon \varkappa_0=1,
  \varkappa_1=2\})=
  \\ & =
  \dfrac{\mu_1}{\lambda_1+\mu_1}\cdot
  \dfrac{\lambda_1+\mu_1}{\lambda_1+\mu_1+s}+
  \dfrac{\lambda_1}{\lambda_1+\mu_1}\cdot
  \dfrac{\lambda_1+\mu_1}{\lambda_1+\mu_1+s} \cdot \varphi_2(s)=
  \\ & =
  \dfrac{\mu_1}{\lambda_1+\mu_1+s}+
  \dfrac{\lambda_1}{\lambda_1+\mu_1+s} \cdot \varphi_2(s)\,. 
\end{align*}
Здесь мы использовали тот факт, что при достижении состояния $0$ величина
$\tilde\Pi_1$ равна нулю. Далее, аналогичные рассуждения дают:
\[
\varphi_i(s)=\dfrac{\mu_i}{\lambda_i+\mu_i+s} \cdot \varphi_{i-1}(s)+
\dfrac{\lambda_i}{\lambda_i+\mu_i+s} \cdot \varphi_{i+1}(s),\quad i=2, 3, \ldots{}.
\]

В частности, для системы M/M/1/$\infty$ полный период занятости совпадает с
временем достижения процессом состояния $i-1$ из состояния $i$. Следовательно,
время достижения нуля из состояния $i$ складывается из $i$ независимых и
одинаково распределенных величин. Значит,
$\varphi_i(s)=(\varphi_1(s))^i$. Возьмём первое из написанных выше равенств и
подставим $\varphi_2(s)=\varphi_1(s)^2$. Найдём:
\[
(\lambda+\mu+s)\varphi_1(s)= \mu + \lambda (\varphi_1(s))^2.
\]
Отсюда,
\[
\varphi_1(s)=\dfrac{\lambda+\mu+s-\sqrt{(\lambda+\mu+s)^2-4\lambda\mu}}{2\lambda}\,,
\]
поскольку именно эта из двух ветвей стремится к нулю при действительных $s$,
стремящихся к $\infty$. Легко видеть, что это решение фактически совпадает с
найденным ранее выражением для $s\tilde p_0(s)$. 

Хотя проблема обращения преобразования Лапласа требует изощрённых методов,
польза от преобразования Лапласа от законов распределений в том, что легко
находить числовые характеристики случайынх величин. Формальное дифференцирование
даёт:
\begin{gather*}
  -\dfrac{d}{ds}\M(e^{-s\Pi})
  \Big|_{s=0}=\M(\Pi)=\dfrac{1}{\mu-\lambda}\,,\\
  \dfrac{d^2}{ds^2}\M(e^{-s\Pi})
  \Big|_{s=0}=\M(\Pi^2)=\dfrac{2\mu}{(\mu-\lambda)^3}\,\\
  \D(\Pi)=\dfrac{\lambda+\mu}{(\mu-\lambda)^3}\,.
\end{gather*}

\section{Задачи}
\begin{zadacha}
  Найдите преобразование Лапласа случайной величины $X$, если она имеет\par
  \textit{i})~экспоненциальное распределение с параметром $\lambda$;\par
  \textit{ii)}~распределение Эрланга порядка $m$ с параметром $\lambda$;\par
  % \textit{iii})~распределение Пуассона с параметром $\lambda$;\par
  Обратите численно данные преобразования и сравните результат с точным решением.
\end{zadacha}

\begin{zadacha}
  \label{z:MM1-PS} Пусть в вычислительную систему поступает простейший
  поток заданий с интенсивностью~$\lambda$. Обработкой заданий занимается один
  процессор, работающий в режиме <<разделения процессора>>: если в системе
  присутствуют~$i$, то за промежуток времени $\Delta t$ каждое из требований
  получает порцию времени $\Delta t/i$. Из-за ограниченности ресурсом
  максимальное число заданий в системе конечно и равно $N$. Задания,
  заставшие все ресурсы занятыми, теряются. \par
  \textit{i})~Выпишите и решите численным методом дифференциальные уравнения для
  распределения вероятностей для числа требований в системе. \par
  \textit{ii})~Найдите с помощью численных методов линейной алгебры стационарное
  распределение для числа требований в системе. Сравните стационарное
  распределение с предельным распределением. Вспомните теорему Маркова.\par
  \textit{iii})~Найдите характеристики периода занятости в системе.
\end{zadacha}

% \begin{zadacha}
%   Покажите, что преобразование Лапласа для времени ожидания начала обслуживания
%   произвольного не потерянного требования в стационарном режиме в системе
%   M/M/$n$/$r$ равно
%   \[
%   \dfrac{1}{1-p_{n+r}}\biggl( \sum_{k=0}^n p_k+n\mu
%   p_n\dfrac{1-\bigl(\frac{\lambda}{s+n\mu}\bigr)^r}{s+n\mu-\lambda}\biggr).
%   \]
%   Получите выражения для среднего значения этой величины и найдите численно
%   плотность абсолютно-непрерывной компоненты этого распределения при различных
%   значениях параметров.
% \end{zadacha}

\begin{zadacha}
  Система $M^X/M/1/n$, группа содержит 1 или 2 требования. Численно изучить
  переходный режим.
\end{zadacha}

\begin{zadacha}
  В колл-центре имеется 32 телефонные линии и 3 специалиста-консультанта. Если в
  момент звонка есть свободный консультант, звонок направляется ему. Если все
  консультанты заняты, то поступивший звонок переводится в режим ожидания. Если
  все линии заняты ожидающими, то звонок теряется. Обслуживание в порядке
  поступления. При интенсивности 100 звонков в час, средней длительности
  разговора 4 минуты, изучите вероятность потери звонка и распределение времени
  ожидания клиентом обслуживания.
\end{zadacha}

\chapter[Марковские квази-процессы рождения--\-ги\-бе\-ли. Распределения 
  фазового типа]%
  {\raggedright Марковские обобщённые процессы рождения--\-ги\-бе\-ли. Распределения 
  фазового типа}

\section{Системы со специальными распределениями длительностей между
  поступлениями или длительностей обслуживания}

В теории массового обслуживания исследователи зачастую предполагают
экспоненциальное распределение для основных временных промежутков и
концентрируют внимание на адекватном моделировании процессов обслуживания и
управления. После того, как такая <<экспоненциальная>> модель исследована,
наступает период расширения класса входящих потоков и законов длительностей
обслуживания при прочих неизменных составляющих системы обслуживания. При этом
могут возникать довольно сложные вероятностные процессы, такие как
кусочно-линейные марковские процессы, регенерирующие процессы, и т.д.

Рассмотрим систему обслуживания пуассоновского потока в предположении, что
длительности обслуживания имеют не экспоненциальное распределение, а
распределения Эрланга порядка $l$, $l=2$, $3$, \ldots{}, задаваемое плотностью
\[
p(u)=\dfrac{\mu^l u^{l-1}}{(l-1)!}e^{-\mu u},\qquad u\geqslant0.
\]
Такое распределение получается, например, для суммы $l$ независимых одинаково
распределенных экспоненциальных случайных величин, каждая с параметром
$\mu>0$. Пусть, например, обслуживание одного требования состоит из $l$
идентичных независимых <<фаз>>, каждая из которых имеет экспоненциально
распределенную длительность. Даже если реально фаз нет, удобно использовать эту
интерпретацию (фиктивных) фаз. Метод называют \emph{методом фаз Эрланга}. Пусть
по-прежнему интенсивность входного потока равна $\lambda>0$, число мест в
очереди не ограничено. Под состояниями системы выберем символ $0$, означающий
отсутствие требований, и значек $(x,k)$, означающий присутствие в системе $x=1$,
$2$, \ldots{} требований и нахождение прибоа на $k$-й фазе, $k=1$, $2$, \ldots,
$l$. Пусть $\xi(t)\in\{0\}\cup\{ (x,k)\colon x=1,2, \ldots; k=1, 2, \ldots,
l\}$~--- состояние системы в момент $t\geqslant0$, $Q_0(t)=\Pr(\{\omega\colon
\xi(t)=0\})$, $Q_{x,k}(t)\hm=\Pr(\{\omega\colon \xi(t)=(x,k)\})$, $x=1$, $2$, \ldots,
$k=1$, $2$, \ldots, $l$, $t\geqslant0$. Проведя рассуждения, как в
первой главе, убеждаемся, что процесс $\{\xi(t);
t\geqslant0\}$ является марковским, имеет следующие диаграммы переходов:
\begin{figure}[htb]
  \centering
  \begin{tikzpicture}
    \draw 
    (-1,0) circle (2pt)
    (-1,0) node[anchor=east] {$0$}
    (1,0) circle (2pt)
    (1,0) node[anchor=west] {$(1,1)$}
    (1,-1) circle (2pt)
    (1,-1) node[anchor=west] {$(1,2)$}
    (1,-2) circle(.5pt)
    (1,-2.33) circle(.5pt)
    (1,-2.67) circle(.5pt)
    (1,-4) circle(2pt)
    (1,-4) node[anchor=west] {$(1,l)$}
    (3,0) circle (2pt)
    (3,0) node[anchor=west] {$(2,1)$}
    (3,-1) circle (2pt)
    (3,-1) node[anchor=west] {$(2,2)$}
    (3,-2) circle(.5pt)
    (3,-2.33) circle(.5pt)
    (3,-2.67) circle(.5pt)
    (3,-4) circle(2pt)
    (3,-4) node[anchor=west] {$(2,l)$};
    \draw[->] (-0.9,0.1) to[bend left] (0.9,0.1);
    \draw[->] (1.1,0.1) to[bend left] (2.9,0.1);
    \draw[->] (1.1,-0.9) to[bend left] (2.9,-0.9);
    \draw[->] (1.1,-3.9) to[bend left] (2.9,-3.9);
  \end{tikzpicture}
\end{figure}
Соответствующая этой диаграмме часть уравнений Колмогорова имеет вид:
\begin{align*}
  \dfrac{dQ_0}{dt}(t)&=-\lambda Q_0(t)+\mu Q_{1,k}(t),\\
  \dfrac{dQ_{1,1}}{dt}(t)&=\lambda Q_0(t)-(\lambda+\mu) Q_{1,1}(t)+\mu
  Q_{2,l}(t),\\
  \dfrac{dQ_{1,2}}{dt}(t)&=\mu Q_{1,1}(t)-(\lambda+\mu) Q_{1,2}(t),\\
  & \ldots\\
  \dfrac{dQ_{1,l}}{dt}(t)&=\mu Q_{1,l-1}(t)-(\lambda+\mu) Q_{1,l}(t).
\end{align*}
Для $x\geqslant 2$ имеет место общий случай:
\begin{align*}
  \dfrac{dQ_{x,1}}{dt}(t)&=\lambda Q_{x-1,1}(t)-(\lambda+\mu) Q_{x,1}(t)+\mu
  Q_{x+1,l}(t),\displaybreak[0] \\
  \dfrac{dQ_{x,2}}{dt}(t)&=\lambda Q_{x-1,2}(t)+\mu Q_{x,1}(t)-(\lambda+\mu) Q_{x,2}(t),\\
  & \ldots \displaybreak[0] \\
  \dfrac{dQ_{x,l}}{dt}(t)&=\lambda Q_{x-1,l}(t+)\mu Q_{x,l-1}(t)-(\lambda+\mu) Q_{x,l}(t).
\end{align*}
Введем $l$-мерные векторные функии 
$\bQ_x(t)=(Q_{x,1}(t), \ldots, Q_{x,l}(t))$, $x=1$, $2$, \ldots{} и матрицы
\begin{gather*}
\Lambda=
\begin{pmatrix}
  \lambda & 0 & \ldots & 0 & 0\\
  0 & \lambda & \ldots & 0& 0\\
  \vdots & \vdots & \ddots & \vdots\\
  0 & 0 & \ldots & 0 & \lambda
\end{pmatrix},
\quad
N=
\begin{pmatrix}
  \lambda+\mu & 0 & \ldots & 0& 0\\
  -\mu & \lambda+\mu & \ldots& 0 & 0\\
  \vdots & \vdots & \ddots & \vdots & \vdots\\
  0 & 0 & \ldots & -\mu & \lambda+\mu
\end{pmatrix},
\\
M=
\begin{pmatrix}
  0 & \ldots & 0 & 0\\
  0 & \ldots & 0 & 0\\
  \vdots & \vdots & \ddots & \vdots \\
  \mu & \ldots & 0 & 0
\end{pmatrix}, \qquad
\Lambda_0=
( \lambda,
  0,  \ldots,0),
\qquad
M_0=
\begin{pmatrix}
  0\\
  0\\
  \vdots\\
  \mu
\end{pmatrix}.
\end{gather*}
Матрицы $\Lambda$, $N$ и $M$ имеют размер $l\times l$. Тогда бесконечный
вектор-строка $\bQ(t)=(Q_0(t), \bQ_1(t), \bQ_2(t), \ldots)$ удовлетворяет
бесконечной системе линейных дифференциальных уравнений
\[
\dfrac{d\bQ}{dt}(t)=\bQ(t)P
\]
с блочной матрицей
\[
P=
\begin{pmatrix}
  -\lambda & \Lambda_0 & 0 & 0 & 0 &\ldots \\
  M_0 & -N & \Lambda & 0 & 0 & \ldots \\
  0 & M & -N & \Lambda & 0 & \ldots \\
  0 & 0 & M & -N & \Lambda & \ldots \\
  \vdots & \vdots & \vdots & \vdots & \vdots & \ddots
\end{pmatrix}
\]
Запомним этот вид матрицы $P$. 

Рассмотрим теперь систему аналогичного устройства, но пусть теперь входной поток
не пуассоновский, а интервалы между требованиями независимы и имеют функцию
распределения 
\[
A(u)=1-\sum_{i=1}^l p_i e^{-\lambda_i u}, \qquad u\geqslant 0
\]
где $p_1+\ldots+p_l=1$, $p_i>0$, $\lambda_i>0$, $i=1$, $2$, \ldots, $l$. 
Такое распределение получается, если промежуток до следующего требования
выбирается в два этапа: сначала выбирается значение $\lambda_i$ параметр $\lambda$ экспоненциального
распределения с вероятностью $p_i$, а затем выбирается значение экспоненциальной
случайной величины с параметром $\lambda_i$. Таким образом, можно говорить о
мгновенном значении интенсивности. Пусть состояния системы имеют вид $(x,k)$,
$x=0$, $1$, \ldots{}, $k=1$, $2$, \ldots, $l$, где $x$~--- число требований в
системе, $k$~--- текущий номер значения $\lambda_k$ мгновенной
интенсивности. Обозначим $Q_{x,k}(t)\hm=\Pr(\{\omega\colon \xi(t)=(x,k)\})$, $x=0$, $1$, \ldots,
$k=1$, $2$, \ldots, $l$, $t\geqslant0$; $\bQ_x(t)=(Q_{x,1}(t), \ldots, Q_{x,l}(t))$, $x=0$, $1$, \ldots{} и матрицы
\begin{gather*}
\Lambda=
\begin{pmatrix}
  \lambda_1p_1 & \lambda_1 p_2 & \ldots  & \lambda_1 p_l\\
  \lambda_2p_1 & \lambda_2 p_2 & \ldots  & \lambda_2 p_l\\
  \vdots & \vdots & \ddots & \vdots\\
  \lambda_l p_1 & \lambda_l p_2 & \ldots  & \lambda_l p_l
\end{pmatrix},
\quad
N=
\begin{pmatrix}
  \lambda_1+\mu & 0 & \ldots & 0\\
  0 & \lambda_2+\mu & \ldots&  0\\
  \vdots & \vdots  & \ddots & \vdots\\
  0 & 0 & \ldots   & \lambda_l+\mu
\end{pmatrix},
\\
M=
\begin{pmatrix}
  \mu & 0 &\ldots  & 0 \\
  0 & \mu & \ldots & 0 \\
  \vdots & \vdots & \ddots & \vdots \\
  0 & 0 & \ldots & \mu
\end{pmatrix}
\end{gather*}

Тогда бесконечный вектор-строка $\bQ(t)=(\bQ_0(t), \bQ_1(t), \bQ_2(t), \ldots)$
удовлетворяет бесконечной системе линейных дифференциальных уравнений
\[
\dfrac{d\bQ}{dt}(t)=\bQ(t)P
\]
с блочной матрицей
\[
P=
\begin{pmatrix}
  -N & \Lambda & 0 & 0 & 0 &\ldots \\
  M & -N & \Lambda & 0 & 0 & \ldots \\
  0 & M & -N & \Lambda & 0 & \ldots \\
  0 & 0 & M & -N & \Lambda & \ldots \\
  \vdots & \vdots & \vdots & \vdots & \vdots & \ddots
\end{pmatrix}
\]

Мы снова получили дифференциальные уравнения с блочной матрицей постоянных
коэффициентов такого же вида, как и раньше. Поэтому естественно дать следующее
определение.

\begin{definition}
Однородный марковский процесс $\{\xi(t); t\geqslant0\}$ с блочной матрицей
интенсивностей переходов вида
\[
P=
\begin{pmatrix}
  -N_0 & \Lambda_0 & 0 & 0 & 0 &\ldots \\
  M_0 & -N & \Lambda & 0 & 0 & \ldots \\
  0 & M & -N & \Lambda & 0 & \ldots \\
  0 & 0 & M & -N & \Lambda & \ldots \\
  \vdots & \vdots & \vdots & \vdots & \vdots & \ddots
\end{pmatrix}
\]
называется однородным обобщенными процессом рождения и гибели.
\end{definition}

\section{Задачи}

\begin{zadacha}
  \label{z:nonhomoserv}
  Пусть в систему поступает простейший поток с
  интенсивностью~$\lambda$. Обслуживающее устройств имеет две линии
  обслуживания. Длительности обслуживания на каждой из них независимы и
  распределены по экспоненциальному закону. Среднее время обслуживания на первой
  линии $\mu_1^{-1}$ (быстрый прибор), среднее время обслуживания на второй
  линии равно $\mu_2^{-1}>\mu_1^{-1}$ (медленный прибор). Имеется конечное число
  $m$ мест ожиданий. Пришедшее требование сразу поступает на обслуживание, если
  есть свободная линия. Если свободны обе линии, занимается первая линия. Если
  обе линии заняты, требование ожидает в очереди. Требования, заставшие все
  места ожидания занятыми, теряются. \par
  \textit{i})~Выпишите и решите численным методом дифференциальные уравнения для
  распределения вероятностей для числа требований в системе. \par
  \textit{ii})~Найдите с помощью численных методов линейной алгебры стационарное
  распределение для числа требований в системе. Сравните стационарное
  распределение с предельным распределением. Вспомните теорему Маркова.\par
  \textit{iii})~Найдите характеристики периода занятости в системе.
\end{zadacha}


\chapter{Дискретные марковские модели}

\section{Метод производящих функций и быстрое преобразование Фурье}
Производящей функцией неотрицательной дискретной случайной величины $\xi$ называется функция 
\[
\Psi(z)=\M z^\xi, \qquad |z|<1.
\]
Если обозначим $p_k=\Pr(\xi=k)$, $k=0$, $1$, \ldots{}, то
\[
\Psi(z)=\sum_{k=0}^\infty p_k z^k.
\]
Задача вычисления коэффициентов $p_k$ по известной функции $\Psi(z)$ решается с
помощью интеграла типа Коши:
\[
p_k=\dfrac{1}{2\pi i}\int\limits_{|z|=r} \dfrac{\Psi(z)}{z^{k+1}}\,dz.
\]
Заменой переменного $z=re^{2\pi u i}$ получаем интеграл
\[
p_k = \dfrac{1}{r^n}\int_0^1 \Psi\bigl(r e^{2\pi u i}\bigr) e^{-2\pi u k i}\,du.
\]
Данный интеграл можно находить численно известными квадратурными формулами. 

Например, в среде Octave есть семейство функций \texttt{quad(\ldots)} (для
гауссовских квадратур),  \texttt{quadv(\ldots)} (правило Симпсона), и т.д.

Вычисление одновременно нескольких значений $p_k$ по той или иной квадратурной
формуле приводит к повторному вычислению подынтегральной функции. Поэтому для
ускорения вычислений естественно воспользоваться \emph{дискретным быстрым
  преобразованием Фурье} (Henrichi~P. Applied and computational complex
analysis. Vol.~3. Wiley, 1986).

\begin{Verbatim}[frame=single,xleftmargin=2em,numbers=left]
function pn = npois(l,n)
  pn = quad( @(t) real(exp(-2*pi*i*t*n) ...
     *exp(l*(exp(2*pi*t*i)-1))),0,1);
endfunction

function pn = pois(l,n)
  pn = l.^n./factorial(n)*exp(-l);
endfunction

for k = 0:10   disp(npois(1.0, k) - pois(1.0,k)) endfor

for k = 0:10   disp(npois(5, k) - pois(5,k)) endfor

tt = (0:1023)/1024;
Psi = exp(5*(exp(2*pi*i*tt)-1));
pn=fft(Psi)/1024;
pn(1:10)-pois(5,0:9)
\end{Verbatim}


\section{Обслуживание конфликтных потоков по~циклическому алгоритму}

Пусть в систему поступают независимые пуассоновские потоки $\Pi_1$, $\Pi_2$,
\ldots, $\Pi_m$, мгновенная интенсивность потока $\Pi_j$ равна $\lambda_j$,
$j=1$, $2$, \ldots, $m$. Требования потока $\Pi_j$ помещаются в очередь $O_j$
неограниченной вместимости. Обслуживающее устройство имеет $m$ состояний: $\hat
\Gamma^{(1)}$, $\hat \Gamma^{(2)}$, \ldots, $\hat \Gamma^{(m)}$. В состоянии $j$
обслуживаются только требования из очереди~$O_j$. Обслуживающее устройство
пребывает в состоянии $\hat \Gamma^{(j)}$ в течение неслучайного времени $\hat T_j$, после
чего мгновенно переключается в состояние $(j+1)$ при $j<m$, или в состояние
$\hat \Gamma^{(1)}$ при $j=m$. 


Будем исследовать динамику одной очереди (первой). Тогда весь цикл разбивается
на два существенных промежутка: обслуживание первой очереди длительностью
$T_1=\hat T_1$ необслуживание первой очереди длительностью $T_2=\hat
T_2+\ldots+\hat t_m$. Будем говорить, что обслуживающее устройство находится в
состоянии $\Gamma^{(1)}=\raisebox{1pt}{$\mathsurround=0pt \bigl\{$}\hat
\Gamma^{(1)}\raisebox{1pt}{$\mathsurround=0pt \bigr\}$}$ на промежутке первого
типа и в состоянии $\Gamma^{(2)}=\raisebox{1pt}{$\mathsurround=0pt \bigl\{$}\hat
\Gamma^{(2)}, \ldots, \hat\Gamma^{(m)}\raisebox{1pt}{$\mathsurround=0pt
  \bigr\}$}$ на промежутке второго типа.

\medskip

\textsl{Задание входящего потока и потока насыщения.}

\smallskip

\textsl{Доказательство марковости.}

\medskip

Обозначим $Q_{j,i}(x)=\Pr(\Gamma_i=\Gamma^{(j)}, \varkappa_i=x)$ и введем
частичные производящие функции 
\[
\Psi_{j,i}(z)=\M(z^{\kappa_i}I(\Gamma_i=\Gamma^{(j)}))=\sum_{x=0}^\infty z^x
Q_{j,i}(z).
\]

Для стационарного режима можно не писать $i$, тогда получим систему
\begin{align*}
  \Psi_1(z) & = z^{-\ell}\exp\{\lambda T_1(z-1)\} \Psi_2(z)+
  \\ & \quad + 
  \sum_{x=0}^{\ell-1}
  Q_2(x)\sum_{b=0}^{\ell-1-x} \dfrac{(\lambda T_1)^b}{b!}e^{-\lambda T_1}
  (1-z^{x+b-\ell}),\\
  \Psi_2(z) & = \exp\{ \lambda T_2(z-1)\}\Psi_1(z).
\end{align*}
Подставив в эти соотношения $z=1$, получим равенство $\Psi_1(1)=\Psi_2(1)$, что
вкупе в условием нормировки $\Psi_1(1)+\Psi_2(1)=1$ влечет
$\Psi_1(1)\hm=\Psi_2(1)\hm=\frac12$.  Учитывая соотношения
\[
Q_2(x) = \sum_{w=0}^x Q_1(w) \dfrac{(\lambda T_2)^{x-w}}{(x-w)!}e^{-\lambda T_2},
\]
задачу можно свести к одной неизвестной функции. Требуется найти аналитическую в
круге $|z|<1$ функцию $\Psi_1(z)$, удовлетворяющую уравнениям $\Psi_1(z)=
\frac12$ и 
\begin{multline*}
  \Psi_1(z)  = z^{-\ell}\exp\{\lambda (T_1+T_2)(z-1)\} \Psi_1(z)+
  \\  + 
  \sum_{x=0}^{\ell-1}
  Q_1(x)\sum_{b=0}^{\ell-1-x} \dfrac{(\lambda (T_1+T_2))^b}{b!}e^{-\lambda (T_1+T_2)}
  (1-z^{x+b-\ell}).
\end{multline*}
Перепишем последнее уравнение в форме, удобной для анализа:
\begin{multline}
  \label{eq:Psi-main}
  (z^{\ell} - \exp\{\lambda (T_1+T_2)(z-1)\})\Psi_1(z) =
  \\ =
  \sum_{x=0}^{\ell-1}
  Q_1(x)\sum_{b=0}^{\ell-1-x} \dfrac{(\lambda (T_1+T_2))^b}{b!}e^{-\lambda (T_1+T_2)}
  (z^\ell-z^{x+b}). 
\end{multline}

По теореме Руше, уравнение 
\begin{equation}
z^{\ell} - \exp\{\lambda (T_1+T_2)(z-1)\}=0
\label{eq:main-walk-kern}
\end{equation}

 при
$\lambda(T_1+T_2)<\ell$ имеет ровно $\ell$ нулей $z_1$, $z_2$, \ldots, $z_\ell$ в круге $|z|\leq 1$, один из
них $z_1=1$. Непосредственно видно, что при $z=1$ правая часть уравнения
\eqref{eq:Psi-main} также обращается в $0$. Раскладывая известные функции в
левой окрестности точки $z=1$, имеем:
\begin{multline*}
  \bigl(({\ell} -\lambda (T_1+T_2))(z-1)+o(z-1)\bigr)\Psi_1(z) =
  \\ =
  \sum_{x=0}^{\ell-1}
  Q_1(x)\sum_{b=0}^{\ell-1-x} \dfrac{(\lambda (T_1+T_2))^b}{b!}e^{-\lambda (T_1+T_2)}
  (\ell-{x+b})(z-1)+o(z-1). 
\end{multline*}
Делим на $z-1$ и переходим к пределу $z\to1$. С учетом условия
$\Psi_1(1)=\frac12$ имеем окончательно уравнение
\[
\sum_{x=0}^{\ell-1}
Q_1(x)\sum_{b=0}^{\ell-1-x} \dfrac{(\lambda (T_1+T_2))^b}{b!}e^{-\lambda (T_1+T_2)}
(\ell-{x+b}) = \frac12(\ell-\lambda(T_1+T_2)).
\]
Кстати, при $\ell=1$ этого уравнения достаточно, чтобы найти единственную
неизвестную константу $Q_1(0)$. Поэтому в дальнейшем предполагаем $\ell>1$. 

Поскольку решение уравнения, функция $\Psi_1(z)$ не должна иметь
полюсов в круге $|z|<1$, числа $z_2$,  \ldots, $z_\ell$ также должны быть
нулями числителя. Это дает нам недостающие $(\ell-1)$ уравнений:
\[
\sum_{x=0}^{\ell-1}
Q_1(x)\sum_{b=0}^{\ell-1-x} \dfrac{(\lambda (T_1+T_2))^b}{b!}e^{-\lambda (T_1+T_2)}
  (z_j^\ell-z_j^{x+b})=0, \quad j=2, \ldots, \ell.
\]

Сейчас время пояснить, как именно следует решать
уравнение~\eqref{eq:main-walk-kern}. Воспользуемся с этой целью методом из
работы: \foreignlanguage{english}{Delves L.M., Lyness~J.N. A Numerical method
  for locating the zeros of an analytic function~// Mathematics of computation,
  vol.~21, No.~100 (1967), pp.~543--560.}  Общая задача имеет вид: найти все
нули $z_1$, $z_2$, \ldots, $z_\nu$ функции $f(z)$ в заданной области,
ограниченной некоторой замкнутой кривой $C$. Сама функция должна быть
аналитической в некоторой большей области. В теории функций комплексного
переменного доказывается формула:
\[
s_N=\dfrac{1}{2\pi i} \int\limits_{C} z^N\dfrac{f'(z)}{f(z)}\,dz =
\sum_{j=1}^\mu z_j^N.
\]
Например, $s_0$ есть число нулей внутри контура $C$.  Идея метода заключается в
том, чтобы найти достаточной количество $N$ величин $s_0$, $s_1$, \ldots, $s_N$,
а затем построить многочлен степени $\nu$ с теми же корнями $z_1$, \ldots,
$z_\nu$,  к которому применить стандартные метод отыскания корней. Напомним, что
коэффициенты такого многочлены суть симметрические функции от его корней. А
именно, величины
\begin{align*}
  s_1 & = z_1+\ldots + z_\nu,\\
  s_2 & = z^2_1+\ldots + z^2_\nu,\\
   & \quad \ldots\\
  s_N & = z^N_1+\ldots + z_\nu^N
\end{align*}
и коэффициенты
\begin{align*}
  \sigma_1 & = -(z_1+\ldots+z_\nu),\\
  \sigma_2 & = (z_1z_2+\ldots+z_{\nu-1}z_\nu),\\
  & \quad \ldots\\
  \sigma_\nu & = (-1)^\nu z_1\cdots z_\nu
\end{align*}
связаны тождеством Ньютона
\begin{align*}
  s_1 &+ \sigma_1 = 0,\\
  s_2 &+ s_1\sigma_1 + 2\sigma_2 = 0,\\
  &\quad\ldots\\
  s_\nu &+ s_{\nu-1} \sigma_1+ s_{\nu-2}\sigma_2+\cdots+s_1 \sigma_{\nu-1} + \nu
  \sigma_\nu =0.
\end{align*}
Итак, искомые величины суть корни уравнения
\[
z^\ell+\sigma_1z^{\ell-1}+\ldots+\sigma_\ell=0.
\]
Таким образом, все опять сводится к вычислению семейства интегралов вида
\[
\dfrac{1}{2\pi i} \int\limits_{C} z^N\dfrac{f'(z)}{f(z)}\,dz=
r^{N+1}
\int_0^1 e^{2\pi u i}\dfrac{f'(re^{2\pi u i})}{f(re^{2\pi u i})}\,du.
\]

\begin{Verbatim}[frame=single,xleftmargin=2em,numbers=left]
function rts = newton_roots(ss)
	 sz = length(ss);
	 pp = [1 zeros(ss,1)];
	 for jj=1:sz 
	   pp(jj+1) = -( ss(jj:-1:1)*pp(1:jj)')/jj;
	 endfor
	 rts = roots(pp);
endfunction

function res = croots(ff, ffprime, r0)
  s0 = quad( @(u) real(exp(2*pi*u*i)*r0 ...
   *ffprime(r0*exp(2*pi*u*i))/ff(r0*exp(2*pi*u*i))), 0, 1)
  ss = zeros(1,fix(s0));
  for NN = 1:fix(s0)
      ss(NN) = (...
           quad( @(u) real(exp(2*pi*u*i*(NN+1))*r0 ...
                  *ffprime(r0*exp(2*pi*u*i)) ...
                  /ff(r0*exp(2*pi*u*i))), 0, 1) ...
	    + i*quad( @(u) imag(exp(2*pi*u*i*(NN+1)) ...
              *r0*ffprime(r0*exp(2*pi*u*i)) ...
              /ff(r0*exp(2*pi*u*i))), 0, 1) ...
	     )*r0^NN;
  endfor;
  res = newton_roots(ss);
endfunction


function res = myff(z)
	 res = z^5-exp(3.14*(z-1));
endfunction

function res = myffp(z)
	 res = 5*z^4-3.14*exp(3.14*(z-1));
endfunction

croots(@myff, @myffp, 1.1)
\end{Verbatim}


Оказывается, что числе реально необходимых констант равно единице.
Поэтому можно переписать уравнение в виде
\begin{equation}
  \label{eq1}
  (z^\ell-e^{\lambda T(z-1)}) \Psi_1(z) = (z-1)(A_0+A_1z+\ldots+A_{\ell-1}z^{\ell-1}).
\end{equation}
Справедливо разложение
\[
z^\ell-\exp\{\lambda T(z-1)\}=(\ell-\lambda T)(z-1)+o(z-1),
\]
и равенство $\Psi(1)=1$, в силу которых из уравнения~\eqref{eq1} откуда следует уравнение
\[
A_0+A_1+A_2+\ldots+A_{\ell-1}=\frac12(\ell-\lambda T).
\]
Остальные числа $z_j$, $j=2$, $3$, \ldots, $\ell$ также должны обращать многочлен в нуль:
\[
A_0+A_1z_j+A_2z_j^2+\ldots+A_{\ell-1}z_j^{\ell-1}=0,\qquad j=2, 3, \ldots, \ell.
\]
Зная нули многочлена, запишем:
\[
A_0+A_1z+\ldots+A_{\ell-1}z^{\ell-1}=A_{\ell-1}(z-z_2)\times \ldots \times (z-z_
\ell)
\]
В то же время,
\[
z^\ell-\exp\{\lambda T(z-1)\}=\varphi(z)\prod_{j=1}^\ell (z-z_j),
\]
где $\varphi(z)$~--- аналитическая в круге $|z|<1$ функция, не обращающаяся в ноль в
$|z|\leqslant1$.  Значит,
\[
\Psi(z)=\dfrac{A_{\ell-1}}{\varphi(z)}\,.
\]
То-есть, надо определять не все вероятности, а только один старший коэффициент. По правилу Крамера,
\[
A_{\ell-1}=\dfrac{%
  \begin{vmatrix}
    1 & 1 & 1 & \ldots & \ell-\lambda T \\
    1 & z^{(2)} & (z^{(2)})^2 & \ldots & 0\\
    1 & z^{(3)} & (z^{(3)})^2 & \ldots & 0\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    1 & z^{(\ell)} & (z^{(\ell)})^2 & \ldots & 0
  \end{vmatrix}
}{\:%
  \begin{vmatrix}
    1 & 1 & 1 & \ldots & 1 \\
    1 & z^{(2)} & (z^{(2)})^2 & \ldots & (z^{(2)})^{\ell-1}\\
    1 & z^{(3)} & (z^{(3)})^2 & \ldots & (z^{(3)})^{\ell-1}\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    1 & z^{(\ell)} & (z^{(\ell)})^2 & \ldots & (z^{(\ell)})^{\ell-1}
  \end{vmatrix}\:
}\,.
\]
В числителе разлагаем по последнему столбцу и имеем определитель Ван-дер-Монда:
\[
  \begin{vmatrix}
    1 & 1 & 1 & \ldots & \ell-\lambda T \\
    1 & z^{(2)} & (z^{(2)})^2 & \ldots & 0\\
    1 & z^{(3)} & (z^{(3)})^2 & \ldots & 0\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    1 & z^{(\ell)} & (z^{(\ell)})^2 & \ldots & 0
  \end{vmatrix} = (-1)^{\ell+1}(\ell-\lambda T) \prod_{2\leqslant i<j\leqslant \ell} (z^{(j)}-z^{(i)}).
\]
В знаменателе чисто Ван дер Монд:
\[
  \begin{vmatrix}
    1 & 1 & 1 & \ldots & 1 \\
    1 & z^{(2)} & (z^{(2)})^2 & \ldots & (z^{(2)})^{\ell-1}\\
    1 & z^{(3)} & (z^{(3)})^2 & \ldots & (z^{(3)})^{\ell-1}\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    1 & z^{(\ell)} & (z^{(\ell)})^2 & \ldots & (z^{(\ell)})^{\ell-1}
  \end{vmatrix}=
  \prod_{1\leqslant i<j\leqslant \ell} (z^{(j)}-z^{(i)}).
\]
Обозначим 
\[
w(z)=(z-z^{(2)})(z-z^{(3)})\times\ldots\times (z-z^{(\ell)}).
\]
Тогда
\begin{multline*}
\Psi(z)=\dfrac{A_{\ell-1}}{\varphi(z)}=
\dfrac{(-1)^{\ell+1}(\ell-\lambda T) \prod\limits_{2\leqslant i<j\leqslant \ell}
  (z^{(j)}-z^{(i)})}{\varphi(z)\prod\limits_{1\leqslant i<j\leqslant \ell} (z^{(j)}-z^{(i)})}=
\\ =
\dfrac{(-1)^{\ell+1}(\ell-\lambda T)}{\varphi(z)\prod\limits_{2\leqslant j\leqslant \ell} (z^{(j)}-1)}
=
\dfrac{(-1)^{\ell+1}(\ell-\lambda T)}{\varphi(z)(-1)^{\ell-1} w(1)}=
\dfrac{\ell-\lambda T}{\varphi(z)w(1)}\,.
\end{multline*}


Теперь, по интегральной формуле Коши:
\[
\Psi(z)=\dfrac{1}{2\pi \mathbf i} \int_{|\zeta|=r} \dfrac{\Psi(\zeta)}{\zeta-z}\, d\zeta.
\]
Обратно разлагаем ($r>0$):
\begin{align*}
  \Psi(z)&=\dfrac{1}{2\pi \mathbf i} \int\limits_{|\zeta|=r} \dfrac{\Psi(\zeta)}{\zeta-z}\, d\zeta=
  \\ &=
  \dfrac{1}{2\pi \mathbf i} \int\limits_{|\zeta|=r} 
  \dfrac{(\ell-\lambda T)}{\varphi(\zeta)(\zeta-z)w(1)}\, d\zeta=
  \\ &=
  \dfrac{1}{2\pi \mathbf i} \dfrac{\ell-\lambda T}{w(1)}
  \int\limits_{|\zeta|=r} 
  \dfrac{(\zeta-1)w(\zeta)}{(\zeta^\ell-e^{\lambda T(\zeta-1)})(\zeta-z)}\,
  d\zeta=
  \\ & =
  \sum_{n=0}^\infty z^n   \dfrac{1}{2\pi \mathbf i} \dfrac{\ell-\lambda T}{w(1)}
  \int\limits_{|\zeta|=r} 
  \dfrac{(\zeta-1)w(\zeta)}{(\zeta^\ell-e^{\lambda T(\zeta-1)})\zeta^{n+1}}\,
  d\zeta.
\end{align*}
Замена  при $r=1$ $\zeta=e^{\mathbf i s}$, $0\leqslant s\leqslant 2\pi$, сводим к определенному интегралу,
который численно находится. 

Для математического ожидания по формуле Коши надо вычислить
\[
\dfrac{1}{2\pi \mathbf i} \dfrac{\ell-\lambda T}{w(1)}
\int\limits_{|\zeta|=r} 
\dfrac{(\zeta-1)w(\zeta)}{(\zeta^\ell-e^{\lambda T(\zeta-1)})(\zeta-1)^2}\,
d\zeta.
\]
Окружим точку $\zeta=1$ кругом $|\zeta-1|=r_1$ малого радиуса и соединим две окружности
разрезом. Между кругами подынтегральная функция аналитична и интеграл по замкнутому контуру равен
нулю. Тогда интеграл по кругу $|\zeta|=r$ равен интегралу по кругу $|\zeta-1|=r_1$, который
выражается через вычет функции и математическое ожидание принимает вид
\[
\dfrac{\ell-\lambda T}{w(1)} \mathop{\mathrm{res}}_{\zeta=1}\,\dfrac{(\zeta-1)w(\zeta)}{(\zeta^\ell-e^{\lambda
       T(\zeta-1)})(\zeta-1)^2}\,. 
\]
Поскольку подынтегральная функция имеет в точке $\zeta=1$ полюс второго порядка, вычет ищется через
производную: 
\[
\mathop{\mathrm{res}}_{\zeta=1}\,\dfrac{(\zeta-1)w(\zeta)}{(\zeta^\ell-e^{\lambda
    T(\zeta-1)})(\zeta-1)^2}=
\lim_{\zeta\to1} \dfrac{d}{dz}\dfrac{(\zeta-1)w(\zeta)}{\zeta^\ell-e^{\lambda
    T(\zeta-1)}}.
\]
Поскольку 
\begin{multline*}
\zeta^\ell-e^{\lambda T(\zeta-1)}=(\zeta^\ell-1)-(e^{\lambda T(\zeta-1)}-1)=
\\ =
(\zeta-1)\Bigl(\zeta^{\ell-1}+\zeta^{\ell-2}+\ldots+1-\lambda T\sum_{n=1}^\infty \dfrac{(\lambda
  T(\zeta-1))^{n-1}}{n!}\Bigr)=(\zeta-1)G(\zeta), 
\end{multline*}
где функция $G(z)$ аналитическая и $G(1)\neq0$. Поэтому
\[
  \lim_{\zeta\to1} \dfrac{d}{dz}\dfrac{(\zeta-1)w(\zeta)}{\zeta^\ell-e^{\lambda
      T(\zeta-1)}}=
    \lim_{\zeta\to1} \dfrac{d}{dz}\dfrac{w(\zeta)}{G(\zeta)}=
    \dfrac{w'(1)G(1)-w(1)G'(1)}{G^2(1)}\,.
\]
Постепенно вычисляем:
\begin{align*}
  w'(1)& =w(1)\Bigl( \dfrac1{1-z^{(2)}} + \ldots+\dfrac1{1-z^{(\ell)}}\Bigr),\\
  G(1) & = \ell-\lambda T,\\
  G'(1) & = (\ell-1)+(\ell-2)+\ldots+1-\lambda T\sum_{n=0}^\infty \dfrac{n\lambda
    T(\zeta-1)^{n-1}}{(n+1)!}\Big|_{\zeta=1}=
  \\ & = \dfrac{(\ell-1)\ell}{2}-\dfrac{(\lambda T)^2}{2}
\end{align*}
Следовательно,
\[
\dfrac{w'(1)G(1)-w(1)G'(1)}{G^2(1)}=\dfrac{w(1)}{(\ell-\lambda T)^2} 
\Bigl(\dfrac{\ell-\lambda T}{1-z^{(2)}} + \ldots+\dfrac{\ell-\lambda
  T}{1-z^{(\ell)}}-\dfrac{\ell(\ell-1)}{2}+
\dfrac{(\lambda T)^2}{2}\Bigr)
\]
Окончательно, математическое ожидание принимает вид
\[
\dfrac{1}{1-z^{(2)}} + \ldots+\dfrac{1}{1-z^{(\ell)}}+\dfrac{(\lambda T)^2-\ell(\ell-1)}{2(\ell-\lambda T)}\,.
\]


Заметим, что ход вычислений останется тем же, если вместо пуассоновского потока взять произвольный
неординарный пуассоновский поток, лишь бы производящая функция размера группы сходилась в некотором
круге $|z|<1+\varepsilon$.

Более длительными вычислениями можно и дисперсию выразить через параметры задачи и корни знаменателя.


\chapter{Решения}
\ref{z:MM1-PS}. Система дифференциальных уравнений имеет вид
\begin{align*}
  p_0'(t) & = -\lambda p_0(t)+\mu p_1(t),\\
  p_i'(t) & = \lambda p_{i-1}(t)-(\lambda+\mu)p_i(t)+\mu p_{i+1}(t), \quad i=1,
  2, \ldots, N-1;\\
  p_N'(t) & = \lambda p_{N-1}(t)-\mu p_N(t).
\end{align*}
Система дифференциальных уравнений совпадает с уравнениями для системы M/M/1/N.

Преобразование Лапласа $\varphi_i(s)$ для времени достижения состояния $0$ из
начального состояния $i$

\end{document}
