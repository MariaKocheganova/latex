%\documentclass[a4paper,twoside]{article}
\documentclass[14pt]{extarticle}


\usepackage{verse}
\usepackage{ccaption}
\usepackage{fancyvrb}
\usepackage[margin=2cm]{geometry}

\usepackage{csquotes}
\usepackage[utf8x]{inputenc}
%\usepackage[cp1251]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage{array}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{latexsym}
\usepackage{indentfirst}
\usepackage{bm}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{epsf}
%\usepackage{epsfig}
%\DeclareGraphicsExtensions{.pdf,.png,.jpg}
\usepackage{wrapfig}
\usepackage{euscript}
\usepackage{indentfirst}
\usepackage[english,russian]{babel}
\usepackage{microtype}

\newcommand{\M}{{\mathsf M}\,}
\newcommand{\cov}{\mathsf{cov}}
\newcommand{\corr}{\mathsf{corr}}
\newcommand{\var}{\mathsf{D}\,}
\renewcommand{\Pr}{{\mathsf P}}
% \sloppy\unitlength=.24mm
% \renewcommand{\thefootnote}{\arabic{footnote}}

% \textwidth=132mm
% \headheight=7mm
% \headsep=5mm
% \textheight=200mm
% \oddsidemargin=0mm
% \evensidemargin=0mm
% \topmargin=0mm

\newcommand{\firstheader}[1]{\noindent\textbf{#1}\nopagebreak\bigskip}
\newcommand{\header}[1]{\bigskip\medskip\noindent\textbf{#1}\nopagebreak\bigskip}
\newcommand{\subheader}[1]{\bigskip\medskip\noindent\emph{#1}\nopagebreak\bigskip}
\newcommand{\subsub}[1]{\bigskip\medskip\noindent\emph{#1}\nopagebreak\bigskip}

\theoremstyle{theorem}
\newtheorem{theorem}{Теорема}
\newtheorem{Theorem}{Теорема}
\newtheorem{definition}{Определение}
\newtheorem{Def}{Определение}
\newtheorem{corollary}{Следствие}
\newtheorem{proposition}{Предложение}
\newtheorem{prop}{Предположение}
\newtheorem{lemma}{Лемма}
\newtheorem{assumption}{Предположение}
\newtheorem{Lemma}{Лемма}
\newtheorem{Cons}{Следствие}
\newtheorem{Proposition}{Предложение}
\newtheorem{Statement}{Утверждение}
\newtheorem{statement}{Утверждение}
\theoremstyle{remark}
\newtheorem{remark}{Замечание}
\newtheorem{Remark}{Замечание}
\newtheorem{example}{Пример}
\newtheorem{Example}{Пример}
\newtheorem{notation}{Замечание}
\newtheorem{teo}{Теорема}
\newtheorem{sled}{Следствие}
\newtheorem{sublemma}[theorem]{\indent\bf Подлемма}
\newtheorem{problem}{\indent\bf Проблема}
\newtheorem{hypothesis}{\indent\bf Гипотеза}
\newtheorem{denotation}[theorem]{\indent\bf Обозначение}
\newtheorem{thr}{Теорема}
\newtheorem{crl}[thr]{Следствие}
\newtheorem{lmm}[thr]{Лемма}
\newtheorem{qu}{Вопрос}
\newtheorem{dfn}{Определение}
\newtheorem{approval}{Утверждение}

\makeatletter
\renewcommand*{\hm}[1]{#1\nobreak\discretionary{}%
	{\hbox{$\mathsurround=0pt #1$}}{}}% перенос арифметических знаков
\newcommand{\rmnum}[1]{\romannumeral #1}
\newcommand{\Rmnum}[1]{\expandafter\@slowromancap\romannumeral #1@}
\usepackage{lipsum}
\newcommand{\Mark}{\{(\Gamma_i, \varkappa_i); \hm{} i \geqslant 0\}}
\renewcommand{\Pr}{{\mathbf P}}
\newcommand{\No}{\textnumero}
\usepackage[noadjust]{cite}

% нумерацию можно оставить как есть
\newcommand{\pages}{1-8}

\begin{document}

\begin{titlepage}

  \begin{center}
  {
    {МИНИСТЕРСТВО ОБРАЗОВАНИЯ И НАУКИ \\РОССИЙСКОЙ ФЕДЕРАЦИИ} }\\
    {
    \textbf{%
    {ФГАОУ ВО 
      <<Нижегородский государственный\\ университет им.~Н.И.~Лобачевского>>}
    }
    }

 \medskip

 
   { Институт информационных технологий, математики и механики }\\
    Кафедра математического обеспечения и суперкомпьютерных технологий

    
 \medskip
  \medskip
   \medskip \medskip
    \medskip
     \medskip
      \medskip
     \hfill
    \begin{minipage}[h]{ 0.33\linewidth}
    <<УТВЕРЖДАЮ>>\\
    Руководитель \\
    педагогической практики\\
\\
    \underline{\hspace{3cm}} Зорин~А.В.
    \end{minipage}
   \medskip \medskip
    \medskip
     \medskip
      \medskip
   \medskip \medskip
    \medskip
     \medskip
      \medskip
      
    \textbf{ОТЧЕТ  ПО}\\ \textbf{ПЕДАГОГИЧЕСКОЙ ПРАКТИКЕ}\\
 \medskip

    
         \medskip
      \medskip
               \medskip
      \medskip
    \hfill
    \begin{minipage}[h]{ 0.5\linewidth}
    Аспиранта 3 года обучения\\
    Кочеганова В.М.
    \end{minipage}
    \vfill {Н.Новгород, 2017}
  \end{center}
\end{titlepage}

\tableofcontents
\newpage

\section{Проведение открытого занятия}

  \medskip
\textbf{Тема открытого занятия:} \textit{Ковариация и ее свойства. Корреляции.}

  \medskip
  \medskip
  \medskip
\textbf{План открытого занятия.}

Данная лекция является продолжением предыдущих лекций, в которых шла речь о числовых характеристиках одной случайной величины. Ковариация и корреляция являются характеристиками совокупности случайных величин.

В течение занятия планируется придерживаться следующих этапов.
\begin{enumerate}
    \item Для большего вовлечения в тематику занятия, является важным вызвать рефлексию у студентов. Другими словами они должны прочувствовать проблематику, основываясь на собственном опыте. Для решения этого вопроса студентам будет предложена задача из области машинного обучения: задача определения рака у пациентов, основываясь на измерении показателей его здоровья (давление, температура, уровень лейкоцитов и т.п.). На этом примере будет видно, как можно упростить объем вычислений для предсказаний, вычислив корреляцию измеряемых величин.
    % :
    % \begin{displayquote}
    % sf
    % \end{displayquote}
    \item Далее необходимо ввести определение ковариации двух случайных величин. 
        \begin{definition}
  Пусть $X$, $Y$ --- случайные величины с конечными математическими ожиданиями $\M X$ и
  $\M Y$. Число 
  \[
  \cov(X,Y)=\M(X-\M X)(Y-\M Y)
  \]
  называется \emph{ковариацией} между случайными величинами $X$ и $Y$.
\end{definition}
Поскольку у студентов не было глубокого изучения теории меры и интеграла Лебега, важно сделать акцент на непрерывном и дискретном видах распределения. Далее следует привести пример вычисления ковариации для двумерного нормального распределения (со всеми выкладками).
\[
p(u,v)=\dfrac{\exp\Bigl\{-\dfrac{1}{2(1-r^2)}\Bigl(
\Bigl(\dfrac{u-a}{\sigma_1}\Bigr)^{\!\!2}-2r\dfrac{(u-a)(v-b)}{\sigma_1\sigma_2}
+ \Bigl(\dfrac{v-b}{\sigma_2}\Bigr)^{\!\!2}\,\Bigr)\Bigr\}}{2\pi\sigma_1\sigma_2\sqrt{1-r^2}}%
.
\]
    
    \item Рассказать про физический смысл ковариации. А именно, выберем направление на плоскости, задавшись направляющими
косинусами $(\theta_1, \theta_2)$, $\theta^2_1+\theta_2^2=1$. Тогда проекция на единичный
вектор $(\theta_1, \theta_2)$ отклонения $(X-\M X, Y-\M Y)$ случайной точки $(X,Y)$ от ее
среднего положения $(\M X, \M Y)$ равна
\[
\theta_1(X-\M X)+ \theta_2( Y-\M Y).
\]
Естественно измерять степень разброса случайной точки $(X, Y)$ относительно ее среднего
положения в выбранном направлении с помощью дисперсии
\begin{multline*}
\var(\theta_1(X-\M X)+ \theta_2( Y-\M Y)) = \theta_1^2 \var X +
2\theta_1\theta_2\cov(X,Y)+ \theta_2^2 \var Y =
 \\ =
 (\theta_1, \theta_2) 
 \begin{pmatrix}
   \var X & \cov(X,Y)\\
   \cov(X,Y) & \var Y
 \end{pmatrix}
 \begin{pmatrix}\theta_1\\ \theta_2
 \end{pmatrix} \geqslant 0.
\end{multline*}
Таким образом, ковариация позволяет находить разброс случайного вектора в заданном
направлении. 

    \item Привести определение матрицы ковариации как характеристику совокупности случайных величин. 
    \begin{definition}
  Пусть случайные величины  $X_1$, $X_2$, \ldots $X_n$ имеют конечные математические
  ожидания. Обозначим $\sigma_i^2=\var X_i$, $\sigma_{i,j}=\cov(X_i, X_j)$, $i\neq
  j$. Матрица 
  \[
  \Sigma=
  \begin{pmatrix}
    \sigma_1^2 & \sigma_{1,2} & \ldots & \sigma_{1,n}\\
    \sigma_{2,1} & \sigma_{2}^2 & \ldots & \sigma_{2,n}\\
    \vdots & \vdots & \ddots & \vdots\\
    \sigma_{n,1} & \sigma_{n,2} & \ldots & \sigma_n^2
  \end{pmatrix}
  \]
  называется \emph{ковариационной матрицей} этих случайных величин.
\end{definition}
    \item Важно перечислить и (выборочно) доказать основные свойства ковариации:
    \begin{itemize}
        \item симметричность (следует из определения);
        \item линейность (доказать самим);
        \item формула для вычисления через маргинальные и совокупные математические ожидания (доказать самим);
        \item вырождение ковариации для независимых случайных величин (доказать самим); дать определение некоррелированным случайным величинам;
        \item Неравенство Чебышева (с доказательством).
    \end{itemize}
    \item Ввести определение коэффициента корреляции. 
    \begin{definition}
  Величина 
  \[
  \corr(X,Y)=\dfrac{\cov(X,Y)}{\sqrt{\var X \var Y}}
  \]
  называется \emph{коэффициентом корреляции} между величинами $X$ и $Y$.
\end{definition}
    Привести его свойства:
    \begin{itemize}
        \item симметричность;
        \item вырождение коэффициента корреляции для независмых случайных величин;
        \item линейная связанность случайных величин при коэффициенте корреляции равном $1$.
    \end{itemize}
    \item Сделать заключение. Вспомнить основные темы занятия.
\end{enumerate}

\newpage
\section{Подготовка учебно-методического пособия}
В рамках педагогической практики был разработан проект учебно-методического пособия по теме <<Аналитические и численные методы в теории очередей>>. Также была подготовлена первая глава <<Введение>>, которую приведем в следующем разделе отчета. Пособие предназначено для студентов, обучающихся по направлениям «Прикладная математика и информатика» и «Фундаментальная информатика и информационные технологии», и может быть использовано при чтении специальных курсов «Теория случайных процессов», «Дополнительные главы теории вероятностей», «Теория управляемых систем массового обслуживания», «Теория меры».

Предлагается следующая структура учебно-методического пособия:
\begin{itemize}
    \item Глава 1. Введение
    \item Глава 2. Марковские процессы гибели и размножения с непрерывным временем
    \item Глава 3. Марковские квази-процессы рождения-гибели. Распределения фазового типа
    \item Глава 4. Дискретные марковские модели
    \item Решения
\end{itemize}

Во введении формулируется реальная задача и строится математическая модель для ее решения. На примере задачи продемонстрирован метод имитационного моделирования для определения некоторых числовых характеристик возникающего процесса обслуживания заявок. 

Глава~2 знакомит с понятием процесса гибели и размножения, а также важным инструментом для его исследования: преобразование Лапласа --- в применении к задаче о нахождении распределения периода занятости системы. В рамках спецкурсов <<Вероятностные модели в теории очередей>> и <<Теория
массового обслуживания>>, как правило, разбираются конкретные примеры простейших систем
массового обслуживания в предположении о простейшем входящем потоке и
экспоненциальном распределении длительности обслуживания произвольного
требования. В качестве математической модели выбирался процесс $\{\varkappa(t);
t\geqslant0\}$, описывающий изменение длины очереди или числа требований в
системе $\varkappa(t)$ в момент $t\geqslant0$. Во всех рассмотренных там случаях
(задачи Эрланга для конечного и бесконечного пуска, задача Пальма для $n$ линий
с потерями, система с ожиданием и $n$ приборами) процесс $\{\varkappa(t);
t\geqslant0\}$ оказывался марковским, а система дифференциальных уравнений
Чепмена--Колмогорова имела трёхдиагональную матрицу. Все рассмотренные тогда
процессы являются частными случаями важного класса марковских процессов,
носящего название процессов гибели и размножения. В заключении раздела предлагается перечень задач для самостоятельного решения.

Глава~3 содержит дальнейшее обобщение процессов гибели и рождения. В теории массового обслуживания исследователи зачастую предполагают экспоненциальное распределение для основных временных промежутков и концентрируют внимание на адекватном моделировании процессов обслуживания и управления. После того, как такая «экспоненциальная» модель исследована, наступает период расширения класса входящих потоков и законов длительностей обслуживания при прочих неизменных составляющих системы обслуживания. При этом могут возникать довольно сложные вероятностные процессы, такие как кусочно-линейные марковские процессы, регенерирующие процессы, и т.д. Через реальную задачу естественным образом вводится понятие однородного обобщенного процесса гибели и размножения. В завершении приводятся задачи для самостоятельного решения.

Глава~4 знакомит с мощным численным методом для поиска вероятностей дискретного распределения по известной производящей функции. Также формулируется задача об обслуживании конфликтных потоков по циклическому алгоритму и аналитически исследуется динамика длины одной из очередей.

Последняя глава содержит решения задач, встречающихся в тексте учебно-методического пособия.



\newpage
\section{Учебно-методическое пособие. Введение}

Пусть есть кафе с $N=10$ местами (индивидуальными столиками). Очереди нет,
столики обслуживаются официантами. Клиент в среднем
проводит в кафе пол-часа. Среднее число поступающих клиентов в час изменяется. В
момент открытия, в 9:00, в кафе приходят 6 клиентов в час; с~9 до 15 интенсивность
линейно растёт до 10 клиентов в час; с 15 до 18 часов она линейно убывает до 8
клиентов в час. В 18:00 кафе закрывается. В момент открытия кафе пустует. Как
изменяется в течение дня число занятых мест?

Мы понимаем, что в работе такого кафе есть большая доля влияния случая: моменты,
когда входят посетители, их заказы, их темп еды --- всё заранее предвидеть и
распланировать невозможно. Поэтому мы будет рассматривать эту задачу методами
теории вероятностей. Итак, мы принимаем, что число занятых мест в каждый
отдельно взятый момент времени есть случайная величина. Тогда вопрос можно
переформулировать так: как изменяется среднее число клиентов? как изменяется
дисперсия среднего числа клиентов?

Рассмотрим поподробнее входные данные задачи, поймём их вероятностный
смысл. Во-первых, запишем выражение для мгновенной интенсивности прихода
клиентов (то, что мы ранее назвали <<число клиентов в час>>) для произвольного
момента времени $t$. Выберем в качестве начального момента отсчёта времени $t=0$
время 9:00 утра, тогда будем считать, что $0\leq t\leq 9$. Обозначим эту
интенсивность через $\lambda(t)$. Физический смысл этой характеристики такой: за
интервал времени вида $(t, t+h)$ в среднем поступает $\lambda(t)\cdot h+o(h)$
требований.  Имеем:
\[
\lambda(t)=\begin{cases}
  6+2t/3,& 0\leq t\leq 6\\
  14-2t/3,& 6< t \leq 9.
\end{cases}
\]
Понятно, что такое
условие не определяет полностью вероятностный закон поступления
клиентов. Сформулируем следующие постулаты \emph{нестационарного ординарного
  потока без последействия}: независимо от того, как приходили клиенты прежде
момента $t$, за промежуток времени $(t, t+h)$ приходит ровно один новый клиент с
вероятностью $\lambda(t)h+o(h)$, поступает более одного клиента с
вероятностью $o(h)$ и не поступает ни одного клиента с вероятностью
$1-\lambda(t)h+o(h)$. 

Дифференциальные уравнения: 
\begin{align*}
  p_0'(t) & = -\lambda(t)p_0(t)+\mu p_1(t);\\
  p_i'(t) & = \lambda(t)p_{i-1}(t)-(\lambda(t)+i\mu)p_i(t)+(i+1)\mu
  p_{i+1}(t),\\ & \qquad \qquad i=1, 2, \ldots, N-1;\\
  p_N'(t) & = \lambda(t)p_{N-1}(t)-N\mu p_N(t).
\end{align*}

Среднее число клиентов:
\[
m(t)=\sum_{i=0}^N i p_i(t).
\]
\begin{Verbatim}[frame=single,xleftmargin=2em,numbers=left]
function pdot = kolm(p,t)
  m=2;
  if (t<6) l=6+2/3*t; else l=14-2/3*t; endif;
  sz = length(p);
  A = zeros(sz,sz);
  A(1:sz+1:sz^2) = -l-m*(0:sz-1);
  A(2:sz+1:sz^2) = l;
  A(sz+1:sz+1:sz^2) = m*(1:sz-1);
  A(sz^2) = -(sz-1)*m;
  pdot = A*p;
endfunction;

N=10;
tt = 0:0.1:9;
pp0 = [1, zeros(1,N)];
pp = lsode("kolm", pp0, tt);
plot(tt,pp); ## распределение вероятностей
plot(tt,pp*(0:N)'); ## среднее число клиентов
\end{Verbatim}


Как мы можем проверить этот результат и, главное, объяснить его <<заказчику>>? 
Ключевой момент здесь --- связать вероятность с частотой и заодно увидеть
собственными глазами, как выглядят \emph{траектории случайного процесса}.

Итак, в оставшейся части Введения мы продемонстрируем один важный метод анализа
процессов обслуживания: метод имитационного моделирования --- и больше про него
не будем вспоминать, так как это отдельная большая наука. В качестве рабочего
определения примем, что имитационное моделирование состоит в выделении некоторых
существенных событий, происходящих в сложной системе, и в <<розыгрыше>>
возможной последовательности наступления этих событий с учётом известных
распределений вероятностей для <<входных управляющих событий>>. 

Во-первых, давайте разберёмся в том, как же всё-таки разворачивается поступление
клиентов во времени.

Надо определить моменты поступления требований в систему. Введём вспомогательную
функцию $\Lambda(t)=\int\limits_0^t \lambda(s)\,ds$. Она равна
\[
\Lambda(t)=\begin{cases}
  6t+t^2/3,& 0\leq t\leq 6\\
  14t-t^2/3-24,& 6< t \leq 9.
\end{cases}
\]
Пусть $T_0=0$, а величины $T_1$, $T_2$, \ldots~--- независимые случайные
величины с экспоненциальным распределением с параметром $1$, $\Lambda(t)$ ---
вспомогательная функция, определённая выше. Для момента $t\ge0$ введём величину
\[
\eta(t)=\sup\{n\colon T_0+T_1+\ldots+T_n<\Lambda(t)\}.
\]
Можно показать, что как функция от $t$, семейство случайных величин $\{\eta(t);
t\ge0\}$ ведёт себя как \emph{счётчик числа пришедших клиентов} в нестационарном
ординарном потоке без последействия с мгновенной интенсивностью $\lambda(t)$,
$t\ge0$. Пусть $V(t)$~--- функция, обратная к $\Lambda(t)$. Тогда моменты
поступления клиентов (моменты скачков считающей функции $\eta(t)$) суть 
\[
\tau_1=V(T_1), \; \tau_2=V(T_1+T_2),\; \tau_3=V(T_1+T_2+T_3),\; \ldots
\]
В нашем случае:
\[
V(t)=
\begin{cases}
  \sqrt{3(t+27)}-9,& 0\le t\le 48,\\
  \sqrt{21-3(123-t)},& 48< t\leq 75.
\end{cases}
\]
Теперь определим моменты поступления клиентов на всём промежутке наблюдения $[0,
9]$ и нарисуем вид функции $\eta(t)$ (а точнее, её \emph{выборчную реализацию}).
\begin{Verbatim}[frame=single,xleftmargin=2em,numbers=left]
function v = Vfunc(tt)
	 whr = (tt>48);
	 v = zeros(size(tt));
	 v = sqrt(3*(tt+27))-9;
	 v(whr) = 21-sqrt(3*(123-tt(whr)));
endfunction;

function taus = ClientsIn()
  taus = [];
  Tn = -log( rand() );
  y = Vfunc(Tn);
  while(y<=9)
    taus(end+1)=y;
    Tn = Tn - log( rand() );
    y = Vfunc(Tn);
  endwhile
endfunction

taus = ClientsIn();
stairs( taus, 0:(length(taus)-1) );
\end{Verbatim}

Обозначим $W_{j,i}$ время, через которое в кафе освободится не менее $j$ мест в
момент прихода $i$-го клиента (мы следуем классической работе Кифера и
Вольфовица, в которой число мест в кафе было не ограничено). Объединим эти
величины с одинаковым индексом $i$ в вектор $W_i=(W_{1,i}, \ldots, W_{N,i})$. Из
определения устанавливаем справедливость неравенств $0\le W_{1,i}\le W_{2,i}\le
\ldots \le W_{N,i}$. Этот вектор несёт в себе много интересной
информации. Например, если ровно $k$ его первых элементов равны нулю, это
означает, что в момент прихода $i$-го клиента есть $k$ свободных мест. В
частности, первый клиент за день застаёт все места свободными, так что $W_1=(0,
0, \ldots, 0)$. Пусть теперь для $i$-го клиента вектор
$0=W_{k,i}<W_{k+1,i}$. Этот клиент, очевидно, сразу займёт свободное
место. Каким тогда будет вектор $W_{i+1}$? Следующий клиент придёт через
промежуток $\alpha_{i+1}=\tau_{i+1}-\tau_i$, время обслуживания $i$-го клиента обозначим
$S_i$. Значит, в момент прихода $(i+1)$-го клиента оставшееся время до
ухода $i$-го клиента равно $(S_i-\alpha_{i+1})^+=\max\{0, S_i-\alpha_{i+1}\}$. Обозначим через
$R(\cdot)$ оператор упорядочивания по возрастанию элементов вектора,
подставленного на место точки в качестве его аргумента. Тогда будем иметь,
очевидно,
\[
W_{i+1}=
R\bigl(0, \ldots, 0,
(S_i-\alpha_i)^+,
(W_{k+1,i}-\alpha_{i+1})^+,\ldots,
(W_{N,i}-\alpha_{i+1})^+\bigr).
\]
Здесь на первых местах стоят $(k-1)$ нуль. Если же в момент прихода $i$-клиента
все места заняты, $W_{1,i}>0$, то этот клиент просто теряется, и 
\[
W_{i+1}=\bigl((W_{1,i}-\alpha_{i+1})^+, \ldots, (W_{N,i}-\alpha_{i+1})^+\bigr).
\]
Алгоритм имитации будет следующий: 1) определить моменты прихода клиентов; 2)
для каждого клиента вычислить его вектор остаточных длительностей; 3) если
клиент не видит свободных мест, помещаем его в поток потерянных клиентов; если
места есть, то определяем момент выхода этого клиента и помещаем в выходящий
поток; 4) соединяем с сортировкой список моментов начала обслуживания и моментов
выхода клиентов с учётом изменения числа клиентов ($+1$, $-1$); 5) вычисляем
актуальное число клиентов в каждый момент скачка.

\begin{Verbatim}[frame=single,xleftmargin=2em,numbers=left]
function [jmps qs taus lost srvd] = RunSim(mu, NN)
	 taus = ClientsIn;
	 jmps_temp = [];
	 lost = [];
	 W = zeros(1, NN);
	 tprev=0;
	 for tau = taus
	     if W(1)>0 
		lost(end+1)=tau;
		W = W+tprev-tau;
		W( W<0 ) = 0;
	     else
		 jmps_temp(end+1)=tau;
		 W = W+tprev-tau;
		 S = -log(rand())/mu;
		 srvd(end+1) = tau+S;
		 W(1) = max([0, W(1)-log(rand())/mu]);
		 W = sort(W);
	     endif
	     tprev=tau;
	 endfor
	 [jmps idx] = sort([0 jmps_temp srvd]);
	 qs = cumsum([0 ones(1, length(jmps_temp)), ...
               -ones(1, length(srvd))](idx));
endfunction
\end{Verbatim}

\newpage
\addcontentsline{toc}{section}{Список литературы}

\begin{thebibliography}{99}
\bibitem{Shyr}
Дружкин~А.В., Капичникова~О.Б., Капичников~А.И. Педагогика высшей школы : учебное пособие. Саратов : Наука, 2013. -- 124 с. \bibitem{Kemeni:Snell}
Голованова, Н. Ф. Педагогика : учебник для студ. проф. вузов. 2-е изд., стер. М. : Академия, 2013. -- 240 с.
\bibitem{Hamilton}
  Столяренко~Л.Д., Столяренко~В.Е. Психология и педагогика [Электронный ресурс] : учебное пособие
для вузов. СГАУ. - 4-е изд. - Электрон. текстовые
дан. - М. : Юрайт, 2011. - 1 эл. опт. диск (CD-ROM). - (Учебник для вузов. Электронная версия).
\end{thebibliography}

\end{document}